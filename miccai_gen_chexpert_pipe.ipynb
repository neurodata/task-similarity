{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from graspologic.cluster import GaussianCluster as GMM\n",
    "from collections import defaultdict\n",
    "from proglearn.forest import UncertaintyForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kate's script to get auc/95\n",
    "%run -i evaluate.py \n",
    "acorn = 1234\n",
    "torch.manual_seed(acorn)\n",
    "np.random.seed(acorn)\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "    \n",
    "device = torch.device(dev)  \n",
    "\n",
    "n_iter = 10\n",
    "seeds = np.random.randint(10000, size=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process data, filter out only frontal, ap, fillter out uncertainty in classes we care and fill in rest data\n",
    "def process_data(df):\n",
    "    \n",
    "    print('starting size %s' %len(df))\n",
    "    data = df\n",
    "    #only use frontal/AP data\n",
    "    data = data.loc[data['Frontal/Lateral'] == 'Frontal']\n",
    "    data = data.loc[data['AP/PA'] == 'AP']\n",
    "\n",
    "    \n",
    "    category_names = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "    \n",
    "    #filter out all uncertainty labels in classes we care about\n",
    "    data = data[category_names]\n",
    "    #tread all empty values in these selected cols as 0\n",
    "    data = data.fillna(0)\n",
    "    #filter out -1 (uncertain labels)\n",
    "    data = data.loc[(data.iloc[:, :] !=-1).all(axis=1)]\n",
    "    #row-idx of the data we care to keep\n",
    "    fly_list = data.index\n",
    "    #reselect from orginal of kept rows\n",
    "    data = df.iloc[fly_list]\n",
    "\n",
    "    #select the cols we care about\n",
    "    wanted_cols = [\"Path\", 'No Finding'] + category_names\n",
    "    data = data[wanted_cols]\n",
    "    \n",
    "    #filter out rows with no label values\n",
    "    data['sum']  = data.iloc[:, 1:].sum(axis=1)\n",
    "    fly_list = data.loc[data['sum']>0].index\n",
    "\n",
    "    \n",
    "    data = df[wanted_cols].iloc[fly_list]\n",
    "    # fill all NA and uncertainty as 0     \n",
    "    data = data.fillna(0)\n",
    "    data = data.replace(-1,0)\n",
    "\n",
    "    print(\"final size %s\" %len(data))\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting size 234\n",
      "final size 132\n",
      "starting size 223414\n",
      "final size 92771\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00006/study1/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study2/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Path  No Finding  \\\n",
       "0   CheXpert-v1.0-small/train/patient00001/study1/...         1.0   \n",
       "4   CheXpert-v1.0-small/train/patient00003/study1/...         0.0   \n",
       "11  CheXpert-v1.0-small/train/patient00006/study1/...         1.0   \n",
       "12  CheXpert-v1.0-small/train/patient00007/study1/...         0.0   \n",
       "13  CheXpert-v1.0-small/train/patient00007/study2/...         0.0   \n",
       "\n",
       "    Atelectasis  Cardiomegaly  Consolidation  Edema  Pleural Effusion  \n",
       "0           0.0           0.0            0.0    0.0               0.0  \n",
       "4           0.0           0.0            0.0    1.0               0.0  \n",
       "11          0.0           0.0            0.0    0.0               0.0  \n",
       "12          1.0           1.0            0.0    0.0               0.0  \n",
       "13          1.0           0.0            0.0    0.0               0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chexpert data\n",
    "data_root = '/home/weiwya/teamdrive_bak/weiwei_temp_data'\n",
    "test_df = pd.read_csv('%s/CheXpert-v1.0-small/valid.csv' %data_root)\n",
    "test_df = process_data(test_df)\n",
    "\n",
    "train_full = pd.read_csv('%s/CheXpert-v1.0-small/train.csv' %data_root)\n",
    "train_full = process_data(train_full)\n",
    "\n",
    "train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting size 702\n",
      "final size 396\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXphoto-v1.0/valid/synthetic/digital/patient...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CheXphoto-v1.0/valid/synthetic/digital/patient...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheXphoto-v1.0/valid/synthetic/digital/patient...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CheXphoto-v1.0/valid/synthetic/digital/patient...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CheXphoto-v1.0/valid/synthetic/digital/patient...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  No Finding  Atelectasis  \\\n",
       "0  CheXphoto-v1.0/valid/synthetic/digital/patient...         0.0          0.0   \n",
       "3  CheXphoto-v1.0/valid/synthetic/digital/patient...         0.0          0.0   \n",
       "4  CheXphoto-v1.0/valid/synthetic/digital/patient...         1.0          0.0   \n",
       "5  CheXphoto-v1.0/valid/synthetic/digital/patient...         0.0          1.0   \n",
       "6  CheXphoto-v1.0/valid/synthetic/digital/patient...         0.0          1.0   \n",
       "\n",
       "   Cardiomegaly  Consolidation  Edema  Pleural Effusion  \n",
       "0           1.0            0.0    0.0               0.0  \n",
       "3           0.0            0.0    1.0               0.0  \n",
       "4           0.0            0.0    0.0               0.0  \n",
       "5           0.0            0.0    0.0               1.0  \n",
       "6           1.0            0.0    0.0               0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chexphoto\n",
    "data_root_photo = '/home/weiwya/teamdrive_bak/weiwei_temp_data/CheXphoto/'\n",
    "photo_test_df = pd.read_csv('%s/CheXphoto-v1.0/valid.csv' %data_root_photo)\n",
    "photo_test_df = process_data(photo_test_df)\n",
    "\n",
    "photo_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform, data_root):\n",
    "        #TODO::put something here that perserves aspect ratio\n",
    "        self.class_names = ['No Finding', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "        self.image_dir = data_root\n",
    "        self.transform = transform\n",
    "        self.total = len(df)\n",
    "        self.image_names = df['Path'].to_list()\n",
    "        self.labels = df[self.class_names].to_numpy()\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_names[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = self.transform(Image.open(image_path).convert('RGB'))\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "#load data, and convert into features to inferr finelabels, coarse_label\n",
    "class ChestXRayHierarchyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform, data_root, embd_model, fine_clfs, fine_to_org, coarse_clf, coarse_to_fine):\n",
    "        \n",
    "        def _load_data(image_name, image_dir, transform):\n",
    "            image_path = os.path.join(image_dir, image_name)\n",
    "            image = transform(Image.open(image_path).convert('RGB'))\n",
    "            return image\n",
    "        \n",
    "        self.fine_to_org = fine_to_org\n",
    "        self.coarse_to_fine = coarse_to_fine\n",
    "        self.n_fine_classes = len(fine_to_org)\n",
    "        self.total = len(df)\n",
    "\n",
    "        self.class_names = ['No Finding', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "        self.org_labels = df[self.class_names].to_numpy()\n",
    "        self.images = torch.stack([_load_data(p, data_root, transform) for p in df['Path'].to_list()])\n",
    "        \n",
    "        #get fine_coarse labels based on features\n",
    "        features = extract_features(embd_model, self.images)\n",
    "        self.fine_labels = make_fine_labels(features, self.org_labels, fine_clfs, n_fine_classes)\n",
    "        self.coarse_labels = make_coarse_labels(self.fine_labels, self.coarse_to_fine)\n",
    "\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], (self.coarse_labels[idx], self.fine_labels[idx], self.org_labels[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation part  \n",
    "# image_size = (320, 320)\n",
    "\n",
    "image_size = (224, 224)\n",
    "resnet_mean = [0.485, 0.456, 0.406]\n",
    "resnet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "#Creating a Transformation Object\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    torchvision.transforms.Resize(size=image_size),\n",
    "    torchvision.transforms.RandomHorizontalFlip(), #A RandomHorizontalFlip to augment our data\n",
    "    torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "    #Normalizing the data to the data that the ResNet18 was trained on\n",
    "    torchvision.transforms.Normalize(mean = resnet_mean ,\n",
    "                                    std = resnet_std) \n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "#Creating a Transformation Object\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    torchvision.transforms.Resize(size=image_size),\n",
    "    # We don't do data augmentation in the test/val set    \n",
    "    torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "    torchvision.transforms.Normalize(mean = resnet_mean,\n",
    "                                    std = resnet_std) \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fine_labels(features, org_labels, fine_clfs,  n_fine_classes):\n",
    "    n_samples = len(features)\n",
    "    fine_labels = np.zeros( (n_samples, n_fine_classes))\n",
    "    print(n_samples, n_fine_classes)\n",
    "    curr = 0\n",
    "    for idx , clf in enumerate(fine_clfs):\n",
    "        truth = org_labels[:, idx]\n",
    "        for row, v in enumerate(truth):\n",
    "            if v == 1.:\n",
    "                p = clf.predict(features[row].reshape(1,-1)) + curr\n",
    "                fine_labels[row, p] = 1.\n",
    "        \n",
    "        curr +=clf.n_components_              \n",
    "    return fine_labels\n",
    "\n",
    "def make_coarse_labels(fine_labels, coarse_to_fine):\n",
    "    n_samples = len(fine_labels)\n",
    "    n_labels = len(coarse_to_fine)\n",
    "    labels = np.zeros((n_samples, n_labels))\n",
    "    fine_to_coarse = defaultdict(list)\n",
    "    #get all coarse labels for a fine label\n",
    "    for k, v in coarse_to_fine.items():\n",
    "        for vv in v:\n",
    "            fine_to_coarse[vv].append(k)\n",
    "\n",
    "    #map each fine label to a coarse label\n",
    "    for row, f in enumerate(fine_labels):\n",
    "        for col, v in enumerate(f):\n",
    "            if v == 1.:\n",
    "                cc  = fine_to_coarse[col]\n",
    "                for c in cc:\n",
    "                    labels[row, c] = 1.0\n",
    " \n",
    "    return labels\n",
    "    \n",
    "#extract feature from image tensors    \n",
    "def extract_features(feature_extractor, tensors, batch = 72):\n",
    "\n",
    "    curr = 0\n",
    "    total = len(tensors)\n",
    "    res = []\n",
    "    while curr < total:\n",
    "        curr_batch = tensors[curr: curr+batch]\n",
    "        tensor_gpu = curr_batch.to(device)\n",
    "        outputs = feature_extractor(tensor_gpu)        \n",
    "        outputs = torch.Tensor.cpu(outputs)\n",
    "        outputs = outputs.detach().numpy()\n",
    "        n_samples = outputs.shape[0]\n",
    "        n_features = outputs.shape[1]\n",
    "        outputs.resize(n_samples, n_features)\n",
    "        res.append(outputs)\n",
    "        curr+= batch\n",
    "    res = np.vstack(res)\n",
    "    print(res.shape)\n",
    "    return res\n",
    "\n",
    "#take any model, use its penultimate layer as output features\n",
    "def extract_fetures_targets(feature_extractor, dl):    \n",
    "    features = []\n",
    "    targets = []\n",
    "    for val_step, (images, labels) in enumerate(dl):\n",
    "        imagesGPU = images.to(device)      \n",
    "        outputs = feature_extractor(imagesGPU)        \n",
    "        outputs = torch.Tensor.cpu(outputs)\n",
    "        outputs = outputs.detach().numpy()\n",
    "        features.append(outputs)\n",
    "        targets.append(labels)\n",
    "        \n",
    "    features = np.vstack(features)\n",
    "    targets = np.vstack(targets)\n",
    "    dim = features.shape[1]\n",
    "    features= features.reshape(len(dl.dataset), dim)\n",
    "    torch.cuda.empty_cache()\n",
    "    return features, targets\n",
    "\n",
    "\n",
    "#build model using Resnet50 as backbone\n",
    "class Resnet50Base(torch.nn.Module):\n",
    "    def __init__(self, n_classes, name, starter_model=None):\n",
    "        super().__init__()\n",
    "        #no basemodel, used pre-train resnet\n",
    "        if starter_model is None:\n",
    "            resnet = torchvision.models.resnet18(pretrained=True)\n",
    "            resnet.fc = torch.nn.Sequential(\n",
    "                torch.nn.Dropout(p=0.25),\n",
    "                torch.nn.Linear(in_features=512, out_features=n_classes)\n",
    "            )\n",
    "            self.base_model = resnet\n",
    "        else:\n",
    "            base_model = starter_model.base_model\n",
    "            base_model.fc = torch.nn.Sequential(\n",
    "                torch.nn.Dropout(p=0.25),\n",
    "                torch.nn.Linear(in_features=512, out_features=n_classes)\n",
    "            )\n",
    "            self.base_model = base_model\n",
    "            \n",
    "        self.sigm = torch.nn.Sigmoid()\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigm(self.base_model(x))\n",
    "    \n",
    "#build model using Resnet50 as backbone\n",
    "class Resnet50Multi(torch.nn.Module):\n",
    "    def __init__(self, n_coarse_classes, n_fine_classes, name, starter_model=None):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        if starter_model is None:\n",
    "            tt = torchvision.models.resnet18(pretrained=True)\n",
    "            modules = list(tt.children())[:-1]\n",
    "            self.feature_extractor = torch.nn.Sequential(*modules)\n",
    "        else:\n",
    "            modules = list(starter_model.base_model.children())[:-1]\n",
    "            self.feature_extractor = torch.nn.Sequential(*modules)\n",
    "            \n",
    "    \n",
    "        self.coarse = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.25),\n",
    "            torch.nn.Linear(in_features=512, out_features=n_coarse_classes)\n",
    "        )\n",
    "        \n",
    "        self.fine = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.25),\n",
    "            torch.nn.Linear(in_features=512, out_features=n_fine_classes)\n",
    "        )\n",
    "        \n",
    "        self.activation_coarse = torch.nn.Sigmoid()\n",
    "        self.activation_fine = torch.nn.Sigmoid()\n",
    "        self.loss_coarse = torch.nn.BCELoss().to(device)\n",
    "        self.loss_fine   = torch.nn.BCELoss().to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.reshape(x, (-1, 512))\n",
    "        return self.activation_coarse(self.coarse(x)) , self.activation_fine(self.fine(x))\n",
    "        #return self.sigm_coarse(self.coarse(x)), self.sigm_fine(self.fine(x))\n",
    "\n",
    "def get_feature_extractor(model):    \n",
    "    tt = model.base_model\n",
    "    modules=list(tt.children())[:-1]\n",
    "    feature_extractor = torch.nn.Sequential(*modules)\n",
    "    for p in feature_extractor.parameters():\n",
    "        p.requires_grad = False\n",
    "    feature_extractor.to(device)\n",
    "    return feature_extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_auc_weiwei(targets, predicts, class_names):\n",
    "    res = {}\n",
    "    total_auc = 0\n",
    "    total_counts = 0\n",
    "    for idx, name in enumerate(class_names):\n",
    "        truth  = targets[:, idx]\n",
    "        pp = predicts[:,idx]\n",
    "        fpr, tpr, thresholds = roc_curve(truth, pp)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        res[name] = auc_score\n",
    "        if idx != 0:\n",
    "            counts = np.sum(truth)\n",
    "            total_auc += auc_score * counts\n",
    "            total_counts += counts\n",
    "    avg_auc = total_auc / total_counts\n",
    "    return avg_auc, res\n",
    "\n",
    "def eval_auc_kate(targets, predicts, class_names, alpha= 0.95):\n",
    "    return eval_auc(targets, predicts, class_names, alpha)\n",
    "    \n",
    "    \n",
    "def eval_model (model,  dl, verbose=True):\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    total_loss = 0\n",
    "    class_lookup = dl.dataset.class_names\n",
    "    n_class = len(class_lookup)\n",
    "\n",
    "    for val_step, (images, labels) in enumerate(dl):\n",
    "\n",
    "        imagesGPU, labelsGPU = images.to(device), labels.to(device)        \n",
    "        outputs = model(imagesGPU)\n",
    "        outputs = torch.Tensor.cpu(outputs)\n",
    "        predicts.append(outputs.detach().numpy())\n",
    "        targets.append(labels)\n",
    "\n",
    "    predicts = np.vstack(predicts)\n",
    "    targets = np.vstack(targets)\n",
    "    loss = total_loss/len(dl)\n",
    "    \n",
    "    auc_dict = eval_auc_kate(targets, predicts, dl.dataset.class_names)\n",
    "    avg_auc = auc_dict['Average']['AUC']\n",
    "    \n",
    "    if verbose:\n",
    "        for k, v in auc_dict.items():\n",
    "            print(k, v)\n",
    "        \n",
    "    return auc_dict\n",
    "\n",
    "\n",
    "def eval_model_hierarchy(train_model, dl, verbose = True):\n",
    "    \n",
    "    class_lookup = dl.dataset.class_names\n",
    "    fine_to_org = dl.dataset.fine_to_org\n",
    "    coarse_to_fine = dl.dataset.coarse_to_fine\n",
    "    \n",
    "    predicts_coarse, predicts_fine, targets = [], [], []\n",
    "    \n",
    "    with tqdm(dl, unit=\"batch\") as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            imagesGPU = images.to(device)\n",
    "            out0, out1 = train_model(imagesGPU)\n",
    "            out0 = torch.Tensor.cpu(out0)\n",
    "            out1 = torch.Tensor.cpu(out1)\n",
    "            predicts_coarse.append(out0.detach().numpy())\n",
    "            predicts_fine.append(out1.detach().numpy())\n",
    "            targets.append(labels[-1])\n",
    "\n",
    "    predicts_coarse = np.vstack(predicts_coarse)\n",
    "    predicts_fine = np.vstack(predicts_fine)\n",
    "    targets = np.vstack(targets)\n",
    "    \n",
    "    #conditional multiply\n",
    "    for coarse_idx, fines in coarse_to_fine.items():\n",
    "        p = predicts_coarse[:, coarse_idx]\n",
    "        for fine_idx in fines:\n",
    "            predicts_fine[:, fine_idx] *= p\n",
    "            \n",
    "    #aggreage fine predict into coarse\n",
    "    n_samples = targets.shape[0]\n",
    "    n_actual_classes = targets.shape[1]\n",
    "    predicts = np.zeros((n_samples, n_actual_classes))\n",
    "    lookup = dl.dataset.fine_to_org\n",
    "    n_fine_classes = predicts_fine.shape[1]\n",
    "    \n",
    "    actual_counts = defaultdict(int)\n",
    "    for idx in range(n_fine_classes):\n",
    "        actual_idx = lookup[idx]\n",
    "        predicts[:, actual_idx] += predicts_fine[:, idx]\n",
    "        actual_counts[actual_idx] += 1\n",
    "        \n",
    "    for idx in range(n_actual_classes):\n",
    "        predicts[:, idx] /=actual_counts[idx]\n",
    "        \n",
    "    auc_dict = eval_auc_kate(targets, predicts, dl.dataset.class_names)\n",
    "    avg_auc = auc_dict['Average']['AUC']\n",
    "        \n",
    "    if verbose:\n",
    "        for k, v in auc_dict.items():\n",
    "            print(k, v)\n",
    "        print('avg_auc:%s' %avg_auc)\n",
    "        \n",
    "    return auc_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fine_clf(features, labels, n_cluster_min=3, n_cluster_max=5, return_cond_mean=False):\n",
    "    fine_clfs = []\n",
    "    n_features = labels.shape[1]\n",
    "    curr = 0\n",
    "    fine_to_org ={}\n",
    "    \n",
    "    conditional_means = []\n",
    "    for i in range(n_features):\n",
    "        ll = labels[:, i]\n",
    "        selected_idx = np.where(ll==1.0)[0]\n",
    "        xx = features[selected_idx]\n",
    "           \n",
    "        clf = GMM(min_components=n_cluster_min, max_components=n_cluster_max, reg_covar=1e-3).fit(xx) \n",
    "        pp = clf.predict(xx) + curr\n",
    "        curr += clf.n_components_\n",
    "\n",
    "        unique_y = np.unique(pp)\n",
    "        for y in unique_y:\n",
    "            fine_to_org[y] = i\n",
    "            \n",
    "        fine_clfs.append(clf) \n",
    "        if return_cond_mean:\n",
    "            means = np.array([\n",
    "                np.mean(features[np.where(pp == c)[0]], axis=0) for c in unique_y])\n",
    "            conditional_means.append(means)\n",
    "            \n",
    "    if not return_cond_mean:\n",
    "        return fine_clfs, fine_to_org, curr\n",
    "    else:\n",
    "        conditional_means = np.vstack(conditional_means)\n",
    "        return fine_clfs, fine_to_org, curr, conditional_means\n",
    "\n",
    "    \n",
    "#1st cluster within a label\n",
    "#then cluster means of each cluster to generate coarse label\n",
    "def gen_coarse_fine_clfs(features, labels, n_cluster_min=3, n_cluster_max=5):\n",
    "    \n",
    "    fine_clf, fine_to_org, n_fine_clusters, conditional_means =  gen_fine_clf(features, labels, n_cluster_min, \n",
    "                                                           n_cluster_max, return_cond_mean=True)\n",
    "    coarse_clf  = GMM(min_components= 7, max_components= 12, reg_covar=1e-3, tol=1e-5)\n",
    "    coarse_clf.fit(conditional_means)\n",
    "    total_coarse_labels = coarse_clf.n_components_\n",
    "    \n",
    "    coarse_to_fine = defaultdict(list)\n",
    "    pp = coarse_clf.predict(conditional_means)\n",
    "    \n",
    "    for i, p in enumerate(pp):\n",
    "        coarse_to_fine[p].append(i)\n",
    "    \n",
    "    return fine_clf, fine_to_org, coarse_clf, coarse_to_fine   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, train_model, train_loss_fn, train_optimizer, dl_train, dl_valid, eval_fn):\n",
    "    best_auc_dic = None\n",
    "\n",
    "    for e in range(epochs):\n",
    "        print(e)\n",
    "        train_loss = 0.        \n",
    "        train_model.train() \n",
    "        with tqdm(dl_train, unit=\"batch\") as tepoch:\n",
    "            for images, labels in tepoch:\n",
    "                images, targets = images.to(device), labels.to(device)\n",
    "                train_optimizer.zero_grad()\n",
    "                outputs = train_model(images)\n",
    "                loss = train_loss_fn(outputs, targets.type(torch.float))\n",
    "                #Once we get the loss we need to take a gradient step\n",
    "                loss.backward() #Back propogation\n",
    "                train_optimizer.step() #Completes the gradient step by updating all the parameter values(We are using all parameters)\n",
    "                train_loss += loss.item() #Loss is a tensor which can't be added to train_loss so .item() converts it to float                \n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "        \n",
    "        print('train_loss %s ' %(train_loss / len(dl_train)))\n",
    "        \n",
    "        curr_auc_dic = eval_fn(train_model, dl_valid, verbose=False)\n",
    "        if (best_auc_dic is None)  or  (best_auc_dic['Average']['AUC'] < curr_auc_dic['Average']['AUC']):\n",
    "            best_auc_dic = curr_auc_dic\n",
    "            torch.save(train_model.state_dict(), 'CheXpert_%s_resnet50' %(train_model.name) )\n",
    "            print('curr best %s' %best_auc_dic['Average']['AUC'])\n",
    "\n",
    "\n",
    "    return 'CheXpert_%s_resnet50' %(train_model.name)\n",
    "\n",
    "\n",
    "\n",
    "def train_hierarchy_model(epochs, train_model, train_optimizer, dl_train, dl_valid, eval_fn):\n",
    "    best_auc_dic = None\n",
    "    for e in range(epochs):\n",
    "        print(e)\n",
    "        train_loss = 0.        \n",
    "        train_model.train() \n",
    "        with tqdm(dl_train, unit=\"batch\") as tepoch:\n",
    "            for images, labels in tepoch:\n",
    "                t0 = labels[0].to(device)\n",
    "                t1 = labels[1].to(device)\n",
    "                t0 = t0.type(torch.float)\n",
    "                t1 = t1.type(torch.float)\n",
    "                \n",
    "                images = images.to(device)\n",
    "                train_optimizer.zero_grad()\n",
    "                out0, out1 = train_model(images)\n",
    "                loss = train_model.loss_coarse(out0, t0) * train_model.loss_fine(out1, t1)\n",
    "                \n",
    "                #Once we get the loss we need to take a gradient step\n",
    "                loss.backward() #Back propogation\n",
    "                train_optimizer.step() #Completes the gradient step by updating all the parameter values(We are using all parameters)\n",
    "                train_loss += loss.item() #Loss is a tensor which can't be added to train_loss so .item() converts it to float                \n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "            \n",
    "        print('train_loss %s ' %(train_loss / len(dl_train)))\n",
    "        \n",
    "        auc_dict = eval_fn(train_model, dl_valid, verbose=False)\n",
    "        if (best_auc_dic is None) or (best_auc_dic['Average']['AUC'] < auc_dict['Average']['AUC']):\n",
    "            best_auc_dic = auc_dict\n",
    "            torch.save(train_model.state_dict(), 'CheXpert_%s_resnet50' %(train_model.name) )\n",
    "            print('curr best %s' %best_auc_dic['Average']['AUC'])\n",
    "\n",
    "        \n",
    "    return 'CheXpert_%s_resnet50' %(train_model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acorn = 1234\n",
    "torch.manual_seed(acorn)\n",
    "np.random.seed(acorn)\n",
    "\n",
    "\n",
    "seeds = np.random.randint(10000, size=1000)\n",
    "batch_size = 16\n",
    "train_size = 0.01\n",
    "\n",
    "#generate n_iter times of train/validate split\n",
    "trains, validates = [],[]\n",
    "for i in range(100):\n",
    "    train, validate = train_test_split(train_full, test_size=1-train_size, random_state=seeds[i], shuffle=True)\n",
    "    trains.append(train)\n",
    "    validates.append(validate)\n",
    "        \n",
    "\n",
    "#acutal test df for chexperd\n",
    "test_dataset = ChestXRayDataset(test_df, test_transform, data_root)\n",
    "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "#actual test df for \n",
    "test_photo_dataset = ChestXRayDataset(photo_test_df, test_transform, data_root_photo)\n",
    "dl_test_photo = torch.utils.data.DataLoader(test_photo_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/58 [00:00<00:05, 10.69batch/s, loss=0.653]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:05<00:00, 10.88batch/s, loss=0.523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.5081645568896984 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/58 [00:00<00:04, 11.58batch/s, loss=0.373]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr best 0.7731754453113728\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:05<00:00, 11.09batch/s, loss=0.428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.45127762083349554 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/58 [00:00<00:04, 11.68batch/s, loss=0.388]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr best 0.7786421816533676\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:05<00:00, 10.78batch/s, loss=0.49] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.4313626880275792 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/58 [00:00<00:04, 11.63batch/s, loss=0.345]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr best 0.7807097212812105\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:05<00:00, 10.99batch/s, loss=0.495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.4192362340359852 \n"
     ]
    }
   ],
   "source": [
    "base_test_auc = []\n",
    "hierachy_test_auc = []\n",
    "\n",
    "base_test_auc_photo = []\n",
    "hierachy_test_auc_photo = []\n",
    "\n",
    "debug_auc =[]\n",
    "debug_auc_photo = []\n",
    "\n",
    "debug_hierachy_auc = []\n",
    "debug_hierachy_auc_photo = []\n",
    "\n",
    "n_iter = 20\n",
    "train_epoch= 10\n",
    "for iteration in range(n_iter):\n",
    "    print(iteration)\n",
    "    torch.cuda.empty_cache()\n",
    "    train_df, validate_df = trains[iteration], validates[iteration][:1000]\n",
    "    train_dataset = ChestXRayDataset(train_df, train_transform, data_root)\n",
    "    valid_dataset = ChestXRayDataset(validate_df, test_transform, data_root)\n",
    "\n",
    "    dl_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dl_valid = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize the model\n",
    "    c_model = Resnet50Base(len(train_dataset.class_names), 'base_model_%s_%s' %(train_size, iteration))\n",
    "    c_model.to(device)\n",
    "    c_loss_fn = torch.nn.BCELoss().to(device)\n",
    "    c_optimizer = torch.optim.Adam(c_model.parameters(), lr=5e-4)\n",
    "    \n",
    "    best_model_name = train_model(train_epoch, c_model, c_loss_fn, c_optimizer, dl_train, dl_valid, eval_model)\n",
    "    print('done eval base model ')\n",
    "    \n",
    "    #reload best model for embedding\n",
    "    print('using model %s' %best_model_name)\n",
    "    c_model = Resnet50Base(len(train_dataset.class_names), '')\n",
    "    c_model.load_state_dict(torch.load(best_model_name))\n",
    "    c_model.to(device)\n",
    "\n",
    "    #evalute test sets at per formance\n",
    "    test_auc = eval_model(c_model, dl_test, verbose=False)\n",
    "    test_photo_auc = eval_model(c_model, dl_test_photo, verbose=False)\n",
    "    base_test_auc.append(test_auc)\n",
    "    base_test_auc_photo.append(test_photo_auc)\n",
    "    print('auc at best base model %s %s' %(test_auc['Average']['AUC'], test_photo_auc['Average']['AUC'] ))\n",
    "    debug_auc.append(test_auc['Average']['AUC'])\n",
    "    debug_auc_photo.append(test_photo_auc['Average']['AUC'] )\n",
    "    \n",
    "    \n",
    "    \n",
    "    embd_model = get_feature_extractor(c_model)\n",
    "    embd_model.to(device)\n",
    "    train_features, train_targets = extract_fetures_targets(embd_model, dl_train)\n",
    "    \n",
    "    fine_clfs, fine_to_org, coarse_clf, coarse_to_fine = gen_coarse_fine_clfs(train_features, train_targets, n_cluster_min=1, n_cluster_max=12 )\n",
    "    n_fine_classes = len(fine_to_org)\n",
    "    n_coarse_classes = len(coarse_to_fine)\n",
    "    print('done generating clfs: n_fine_clf: %s n_coarse: %s' %(n_fine_classes, n_coarse_classes))\n",
    "\n",
    "    train_hierachy_dataset = ChestXRayHierarchyDataset(train_df, train_transform, data_root, embd_model, fine_clfs, fine_to_org, coarse_clf, coarse_to_fine)\n",
    "    valid_hierachy_dataset = ChestXRayHierarchyDataset(validate_df, test_transform, data_root, embd_model, fine_clfs, fine_to_org, coarse_clf, coarse_to_fine)\n",
    "    test_hierachy_dataset   = ChestXRayHierarchyDataset(test_df, test_transform, data_root, embd_model, fine_clfs, fine_to_org, coarse_clf, coarse_to_fine)\n",
    "    test_hierachy_photo_dataset = ChestXRayHierarchyDataset(photo_test_df, test_transform, data_root_photo, embd_model, fine_clfs, fine_to_org, coarse_clf, coarse_to_fine)\n",
    "    dl_hierachy_train = torch.utils.data.DataLoader(train_hierachy_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dl_hierachy_valid = torch.utils.data.DataLoader(valid_hierachy_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dl_hierachy_test = torch.utils.data.DataLoader(test_hierachy_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dl_hierachy_test_photo = torch.utils.data.DataLoader(test_hierachy_photo_dataset, batch_size=batch_size, shuffle=True)\n",
    "    print('done making new dls')\n",
    "    \n",
    "    hierachy_model = Resnet50Multi(n_coarse_classes, n_fine_classes, 'hierachy_model_%s_%s'%(train_size, iteration), c_model)\n",
    "    hierachy_model.to(device)\n",
    "    \n",
    "    hierachy_optimizer = torch.optim.Adam(hierachy_model.parameters(), lr=5e-3)\n",
    "    best_hierachy_name = train_hierarchy_model(train_epoch*5, hierachy_model, hierachy_optimizer, \n",
    "                                                 dl_hierachy_train, dl_hierachy_valid, eval_model_hierarchy)\n",
    "    #reload best model for embedding\n",
    "    print('using model %s' %best_model_name)\n",
    "    hierachy_model = Resnet50Multi(n_coarse_classes, n_fine_classes, '')\n",
    "    hierachy_model.load_state_dict(torch.load(best_hierachy_name))\n",
    "    hierachy_model.to(device)\n",
    "    test_auc = eval_model_hierarchy(hierachy_model, dl_hierachy_test, verbose=False)\n",
    "    test_photo_auc = eval_model_hierarchy(hierachy_model, dl_hierachy_test_photo, verbose=False)\n",
    "    print('auc at best hierachy model %s %s' %(test_auc['Average']['AUC'], test_photo_auc['Average']['AUC'] ))\n",
    "    debug_hierachy_auc.append(test_auc['Average']['AUC'])\n",
    "    debug_hierachy_auc_photo.append(test_photo_auc['Average']['AUC'])\n",
    "    \n",
    "    hierachy_test_auc.append(test_auc)\n",
    "    hierachy_test_auc_photo.append(test_photo_auc)\n",
    "    \n",
    "    print(np.average(debug_auc), np.average(debug_auc_photo))\n",
    "    print(np.average(debug_hierachy_auc), np.average(debug_hierachy_auc_photo))\n",
    "    print('!!!!!!!!!!!')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(base_test_auc),  np.average(hierachy_test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(base_test_auc_photo),  np.average(hierachy_test_auc_photo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
