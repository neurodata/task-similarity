{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization,Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.datasets import cifar100\n",
    "from tensorflow.random import set_seed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "20\n",
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#convert fine label to course label\n",
    "(fx, fy), (fxx, fyy) = cifar100.load_data()\n",
    "(cx, cy), (cxx, cyy) = cifar100.load_data(label_mode='coarse') \n",
    "\n",
    "fine_to_coarse = {}\n",
    "for f,c in zip( fy, cy):\n",
    "    fine_to_coarse[f[0]] = c[0]\n",
    "\n",
    "x_train = fx\n",
    "y_train = fy\n",
    "x_test = fxx\n",
    "y_test = fyy\n",
    "\n",
    "print(len(fine_to_coarse))\n",
    "print(len(set(fine_to_coarse.values())))\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "del fx, fy, fxx, fyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 224, 224, 3) (10000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array( [ preprocess_input(cv2.resize(x,(224,224))) for x in x_train])\n",
    "x_test =  np.array( [ preprocess_input(cv2.resize(x,(224,224))) for x in x_test])\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1000) (10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "#get resnet model, use that for embedding \n",
    "resnet_model = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "# remove the output layer\n",
    "resnet_model.layers.pop()\n",
    "resnet_embd_model  = Model(inputs=resnet_model.inputs, outputs=resnet_model.layers[-1].output)\n",
    "\n",
    "x_train = resnet_embd_model.predict(x_train)\n",
    "x_test = resnet_embd_model.predict(x_test)\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_positive_class(tx, ty, txx, tyy, wanted_class, fine_to_coarse):\n",
    "    kept_labels = []\n",
    "    for k, v, in fine_to_coarse.items():\n",
    "        if v == wanted_class:\n",
    "            kept_labels.append(k)\n",
    "        \n",
    "    train_data, train_labels = [], []\n",
    "    test_data,  test_labels =  [], []\n",
    "    \n",
    "    for x, y in zip(tx, ty):\n",
    "        y=y[0]\n",
    "        if y in kept_labels:\n",
    "            train_data.append(x)\n",
    "            \n",
    "    for x, y  in zip (txx, tyy):\n",
    "        y=y[0]\n",
    "        if y in kept_labels:\n",
    "            test_data.append(x)\n",
    "    \n",
    "    return  np.array(train_data), \\\n",
    "            np.repeat(np.array([0,1]).reshape(1,2), len(train_data), axis=0 ),\\\n",
    "            np.array(test_data),\\\n",
    "            np.repeat(np.array([0,1]).reshape(1,2), len(test_data), axis=0 )\n",
    "\n",
    "\n",
    "\n",
    "def get_data_negative_class (all_data, all_labels, all_test_data, all_test_lables, exclude_classes, fine_to_coarse):\n",
    "    exclude_labels = []\n",
    "    for k, v, in fine_to_coarse.items():\n",
    "        if v in exclude_classes:\n",
    "            exclude_labels.append(k)\n",
    "        \n",
    "    train_data, test_data = [], []\n",
    "    \n",
    "    for x, y in zip(all_data, all_labels):\n",
    "        y = y[0]\n",
    "        if y not in exclude_labels:\n",
    "            train_data.append(x)\n",
    "            \n",
    "    for x, y  in zip (all_test_data, all_test_lables):\n",
    "        y = y[0]\n",
    "        if y not in exclude_labels:\n",
    "            test_data.append(x)\n",
    "            \n",
    "    return  np.array(train_data), \\\n",
    "            np.repeat(np.array([1,0]).reshape(1,2), len(train_data), axis=0 ),\\\n",
    "            np.array(test_data),\\\n",
    "            np.repeat(np.array([1,0]).reshape(1,2), len(test_data), axis=0 )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(data, label, model):\n",
    "    pp = np.argmax(model.predict(data), axis=1)\n",
    "    return accuracy_score(label, pp)\n",
    "\n",
    "\n",
    "def model_baseline(x_train, y_train, batch_size=32, epochs=20, verbose=False):\n",
    "    input_dim = x_train.shape[1]\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    \n",
    "    x  = Dense(128, activation='relu',name='shared')(input_layer)\n",
    "    \n",
    "    x    = BatchNormalization()(x)\n",
    "    y = Dense(y_train.shape[-1], activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=y)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=verbose)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_transfer(x_train, y_train, x_transfer, y_transfer, batch_size=48, epochs=20, verbose=False):\n",
    "    input_dim =x_train.shape[1]\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    \n",
    "    x  = Dense(128,  activation='relu',name='shared')(input_layer)\n",
    "    \n",
    "    x    = BatchNormalization()(x)\n",
    "    y = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=y)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    #training\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=verbose)\n",
    "    \n",
    "    #transfering\n",
    "    model.fit(x_transfer, y_transfer, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=verbose)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_transfer(x_train, y_train, x_test, y_test, \n",
    "                       transfer_class_idx, used_idx, transfer_percent, fine_to_coarse,  \n",
    "                       train_percent=1.0, batch_size= 48, epochs=20, n_iter=25):\n",
    "    curr_accuracy = []\n",
    "    \n",
    "    \n",
    "    transfer_data, transfer_labels, transfer_test_data, transfer_test_labels = \\\n",
    "        get_data_positive_class(x_train , y_train, x_test, y_test, transfer_class_idx, fine_to_coarse)\n",
    "\n",
    "    #negative data are all classes that's no in transfer class and used class\n",
    "    train_neg_data, train_neg_labels, test_neg_data, test_neg_label \\\n",
    "                = get_data_negative_class(x_train , y_train, x_test, y_test, used_idx + [transfer_class_idx], fine_to_coarse)\n",
    "        \n",
    "    \n",
    "    \n",
    "    transfer_full_data = np.vstack([transfer_data, train_neg_data])\n",
    "    transfer_full_labels = np.vstack([transfer_labels, train_neg_labels])\n",
    "\n",
    "    transfer_full_test  = np.vstack([transfer_test_data, test_neg_data])\n",
    "    transfer_full_test_lables = np.vstack([transfer_test_labels, test_neg_label])\n",
    "    \n",
    "\n",
    "    #for other in wanted_task_idx:\n",
    "    for other in used_idx:\n",
    "        \n",
    "        train_pos_data, train_pos_labels, test_pos_data, test_pos_labels = \\\n",
    "            get_data_positive_class(x_train , y_train, x_test, y_test, other, fine_to_coarse)\n",
    "        \n",
    "        \n",
    "        train_data = np.vstack([train_pos_data, train_neg_data])\n",
    "        train_labels = np.vstack([train_pos_labels, train_neg_labels])\n",
    "\n",
    "        test_data = np.vstack([test_pos_data, test_neg_data])\n",
    "        test_labels = np.vstack([test_pos_labels, test_neg_label])\n",
    "\n",
    "        transfer_accuracy = []\n",
    "\n",
    "        for i in range(n_iter):\n",
    "            if i % 5 == 0:\n",
    "                print(i,  transfer_percent, coarse_names[other], np.average(transfer_accuracy) )\n",
    "            \n",
    "\n",
    "            #base_case data\n",
    "            total = train_data.shape[0]\n",
    "            train_size = int( total * train_percent)\n",
    "\n",
    "\n",
    "            idx = np.random.choice(total, train_size, replace=False)\n",
    "            d0 = train_data[idx]\n",
    "            l0 = train_labels[idx]\n",
    "\n",
    "\n",
    "            #transfer data!!!\n",
    "            total = transfer_full_data.shape[0]\n",
    "            transfer_size = int( total * transfer_percent)\n",
    "            \n",
    "            idx = np.random.choice(total, transfer_size, replace=False)\n",
    "            d1 = transfer_full_data[idx]\n",
    "            l1 = transfer_full_labels[idx]\n",
    "                        \n",
    "#             print(d0.shape, d1.shape)\n",
    "            \n",
    "            model = model_transfer(d0, l0, d1, l1, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "            p = model.predict(transfer_full_test).argmax(axis=1)\n",
    "            t = transfer_full_test_lables.argmax(axis=1)\n",
    "\n",
    "            f1 = f1_score(p, t, labels=[1])            \n",
    "            transfer_accuracy.append(f1)\n",
    "\n",
    "        curr_accuracy.append( (coarse_names[other], transfer_accuracy ) )\n",
    "    \n",
    "    return curr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_baseline(x_train, y_train, x_test, y_text, transfer_class, used_idx, use_percent, fine_to_coarse,  \n",
    "                train_percent=1.0, batch_size= 48, epochs=20, n_iter=25):\n",
    "    \n",
    "    transfer_data, transfer_labels, transfer_test_data, transfer_test_labels = \\\n",
    "        get_data_positive_class(x_train , y_train, x_test, y_test, transfer_class, fine_to_coarse)\n",
    "\n",
    "    #negative data are all classes that's no in transfer class and used class\n",
    "    train_neg_data, train_neg_labels, test_neg_data, test_neg_label \\\n",
    "                = get_data_negative_class(x_train , y_train, x_test, y_test, used_idx + [transfer_class], fine_to_coarse)\n",
    "        \n",
    "    \n",
    "    \n",
    "    transfer_full_data = np.vstack([transfer_data, train_neg_data])\n",
    "    transfer_full_labels = np.vstack([transfer_labels, train_neg_labels])\n",
    "\n",
    "    transfer_full_test  = np.vstack([transfer_test_data, test_neg_data])\n",
    "    transfer_full_test_lables = np.vstack([transfer_test_labels, test_neg_label])\n",
    "    \n",
    "    accuracies  = []\n",
    "    for i in range(n_iter):\n",
    "        if i % 5 == 0:\n",
    "            print(i,  use_percent, np.average(accuracies) )\n",
    "\n",
    "        total = transfer_full_data.shape[0]\n",
    "        transfer_size = int( total * use_percent)\n",
    "\n",
    "        idx = np.random.choice(total, transfer_size, replace=False)\n",
    "        d = transfer_full_data[idx]\n",
    "        l = transfer_full_labels[idx]\n",
    "        model = model_baseline(d, l, batch_size=batch_size, epochs=epochs)\n",
    "        \n",
    "        p = model.predict(transfer_full_test).argmax(axis=1)\n",
    "        t = transfer_full_test_lables.argmax(axis=1)\n",
    "        \n",
    "        f1  = f1_score(p ,t, labels=[1])\n",
    "        accuracies.append(f1)\n",
    "    return accuracies\n",
    "                        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted = 8 #'large carnivores'\n",
    "\n",
    "coarse_names = [\n",
    "'aquatic_mammals',  'fish', 'flowers', 'food_containers', \n",
    "'fruit_and_vegetables', 'household_electrical_devices', \n",
    "'household_furniture', 'insects', 'large_carnivores',\n",
    "'large_man-made_outdoor_things', 'large_natural_outdoor_scenes',\n",
    "'large_omnivores_and_herbivores', 'medium-sized_mammals',\n",
    "'non-insect_invertebrates', 'people', 'reptiles',\n",
    "'small mammals', 'trees', 'vehicles_1','vehicles_2'\n",
    "]\n",
    "\n",
    "\n",
    "used_set  = ['small mammals',  'vehicles_1', ]\n",
    "used_idx = [i for i, x in enumerate(coarse_names) if x  in used_set ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 nan\n",
      "5 0.1 0.6197617460178546\n",
      "10 0.1 0.6244536298960021\n",
      "15 0.1 0.6227700096703949\n",
      "20 0.1 0.620197472036649\n",
      "Percentage 0.1 : accuracy 0.6208906403066979\n",
      "0 0.2 nan\n",
      "5 0.2 0.6468298095722014\n",
      "10 0.2 0.640583293867922\n",
      "15 0.2 0.6421785603921671\n",
      "20 0.2 0.6449555998486084\n",
      "Percentage 0.2 : accuracy 0.6456671853576239\n",
      "0 0.3 nan\n",
      "5 0.3 0.6670212722384782\n",
      "10 0.3 0.6641367479491318\n",
      "15 0.3 0.6628303198691989\n",
      "20 0.3 0.6629155369549433\n",
      "Percentage 0.3 : accuracy 0.6626568296923332\n",
      "0 0.4 nan\n",
      "5 0.4 0.670400679852899\n",
      "10 0.4 0.6702919855831613\n",
      "15 0.4 0.6657883962177366\n",
      "20 0.4 0.6648480220982453\n",
      "Percentage 0.4 : accuracy 0.6663950002258191\n",
      "0 0.5 nan\n",
      "5 0.5 0.6751580717305992\n",
      "10 0.5 0.6725167406195655\n",
      "15 0.5 0.6738519400015626\n",
      "20 0.5 0.676659263874361\n",
      "Percentage 0.5 : accuracy 0.678557516392326\n",
      "0 0.6 nan\n",
      "5 0.6 0.6882917164788004\n",
      "10 0.6 0.6861566233244129\n",
      "15 0.6 0.6867393569142843\n",
      "20 0.6 0.6854714174902556\n",
      "Percentage 0.6 : accuracy 0.6861142300826293\n",
      "0 0.7 nan\n",
      "5 0.7 0.6919288979770658\n",
      "10 0.7 0.6923305240001995\n",
      "15 0.7 0.6927118284574231\n",
      "20 0.7 0.6923797258137951\n",
      "Percentage 0.7 : accuracy 0.6915565034100457\n",
      "0 0.8 nan\n",
      "5 0.8 0.6865330837676047\n",
      "10 0.8 0.691186669796853\n",
      "15 0.8 0.6924592494177413\n",
      "20 0.8 0.6915617303763797\n",
      "Percentage 0.8 : accuracy 0.6906901808273836\n",
      "0 0.9 nan\n",
      "5 0.9 0.6940927083297916\n",
      "10 0.9 0.6915985331242329\n",
      "15 0.9 0.6917651498168327\n",
      "20 0.9 0.6929422179375084\n",
      "Percentage 0.9 : accuracy 0.6944540117106881\n",
      "0 1.0 nan\n",
      "5 1.0 0.6913352604802729\n",
      "10 1.0 0.6925796666845684\n",
      "15 1.0 0.693614665169225\n",
      "20 1.0 0.6931381084279716\n",
      "Percentage 1.0 : accuracy 0.6943523652829304\n"
     ]
    }
   ],
   "source": [
    "seed = 9876\n",
    "np.random.seed(seed)\n",
    "set_seed(seed)\n",
    "\n",
    "#measure baseline (non_transfer) accuracy \n",
    "ranges = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "n_iter = 25\n",
    "baseline_acc = {}\n",
    "for percentage in ranges:\n",
    "    baseline_acc[percentage] = do_baseline(x_train, y_train, x_test, y_test, wanted, used_idx, percentage, fine_to_coarse, n_iter=n_iter)\n",
    "    print('Percentage %s : accuracy %s' %(percentage, np.average(baseline_acc[percentage])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 small mammals nan\n"
     ]
    }
   ],
   "source": [
    "seed = 9876\n",
    "np.random.seed(seed)\n",
    "set_seed(seed)\n",
    "\n",
    "ranges = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "n_iter = 25\n",
    "transfer_acc = {}\n",
    "for percentage in ranges:\n",
    "    res = do_transfer(x_train, y_train, x_test, y_test, \n",
    "                       wanted, used_idx, percentage, fine_to_coarse, n_iter=n_iter)\n",
    "    tmp = res\n",
    "    tmp = sorted(tmp, key=lambda x : np.average(x[1]))\n",
    "    transfer_acc[percentage] = res\n",
    "    print(percentage)\n",
    "    for t in tmp:\n",
    "        print (t[0], np.average(t[1]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: [('small mammals', [0.614572333685322]),\n",
       "  ('vehicles_1', [0.6019007391763463])],\n",
       " 0.2: [('small mammals', [0.6372745490981964]),\n",
       "  ('vehicles_1', [0.6335797254487857])]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./baseline_acc.p', 'wb') as handle:\n",
    "    pickle.dump(baseline_acc, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tranfer_acc.p', 'wb') as handle:\n",
    "    pickle.dume(transfer_acc, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
