{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "celtic-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve, auc\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.utils.data as data_utils\n",
    "from collections import defaultdict\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils for cluster generation\n",
    "class Dataset:\n",
    "    def __init__(self, file='data/icons_embd.p', train=True, classes=[]):\n",
    "\n",
    "        self.data = pickle.load(open(file, 'rb'))[0] \n",
    "        self.targets = pickle.load(open(file, 'rb'))[1]       \n",
    "        self.classes = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1234,6265, 2403, 941,2225]\n",
    "label_noises = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "#please, change accordingly to the machine\n",
    "n_cores = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "###generate clusters using not permutted(not noisy) data \n",
    "for run, seed in enumerate(seeds):\n",
    "    print(\"Generating clusters...\")\n",
    "    file = pickle.load(open('../../../teamdrive/transmediasp/kate/hierarchy/icons_embd_%s.p' %run, 'rb'))\n",
    "    trainset = Dataset(file)\n",
    "    n_props = 1\n",
    "\n",
    "    generate_dist_matrix_kwargs = {'metric':'tasksim', \n",
    "                                   'metric_kwargs':{'n_neg_classes': 10, \n",
    "                                                    'task_similarity_kwargs': {'transformer_kwargsx': \n",
    "                                                                                   {'max_depth':4},\n",
    "                                                                              'transformer_kwargsz':\n",
    "                                                                                  {'max_depth':4}}}, \n",
    "                                   'function_tuples':None, \n",
    "                                   'n_cores':n_cores, \n",
    "                                   'acorn':seed\n",
    "                                  }\n",
    "\n",
    "\n",
    "    process_dist_matrix_kwargs = {'make_symmetric': True,\n",
    "                                  'scale':True,\n",
    "                                 'aug_diag':True,\n",
    "                                 }\n",
    "\n",
    "    embedding=ASE\n",
    "    embedding_kwargs={'n_components':16}\n",
    "    cluster=GMM\n",
    "    cluster_kwargs = {'min_components': 20, 'max_components': 20, 'reg_covar': 1e-03}\n",
    "\n",
    "    cluster_dists_kwargs = {'embedding':embedding, \n",
    "                            'embedding_kwargs':embedding_kwargs, \n",
    "                            'cluster':cluster, \n",
    "                            'cluster_kwargs':cluster_kwargs\n",
    "                           }\n",
    "\n",
    "    n_mc=1\n",
    "    master_seed = seed\n",
    "    np.random.seed(master_seed)\n",
    "\n",
    "    data_dimension=2048\n",
    "\n",
    "    generate_tasksim=True\n",
    "\n",
    "    if generate_tasksim:\n",
    "        tasksim_clusters = []\n",
    "\n",
    "    #- Generate clusters\n",
    "    for iteration in tqdm(range(n_mc)):\n",
    "        start = time.time()\n",
    "        X_train, _, y_train, _ = train_test_split(trainset.data, trainset.targets, test_size=0.1, random_state=seed)\n",
    "        print(len(X_train), len(y_train))\n",
    "        if generate_tasksim:\n",
    "            temp_tasksim = generate_hierarchy(X_train, y_train, generate_dist_matrix_kwargs, process_dist_matrix_kwargs, cluster_dists_kwargs)\n",
    "            tasksim_clusters.append(temp_tasksim)\n",
    "\n",
    "            pickle.dump(tasksim_clusters, open('../../../teamdrive/transmediasp/kate/hierarchy/icons_tasksim_clusters_%s.p' %run, 'wb'))\n",
    "    print(\"Clusters are generated for run %s\" %run)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "###generate clusters using permutted(noisy) data \n",
    "\n",
    "df = pd.read_csv('../../../teamdrive/transmediasp/kate/icons_df.csv')\n",
    "\n",
    "for run, seed in enumerate(seeds):\n",
    "    for label_noise in label_noises:\n",
    "        label_str = str(int(label_noise*100))\n",
    "        \n",
    "        print(\"Generating clusters...\")\n",
    "        file = pickle.load(open('../../../teamdrive/transmediasp/kate/hierarchy/icons_embd_%s.p' %run, 'rb'))\n",
    "        trainset = Dataset(file)\n",
    "        trainset.targets = np.array(df[df['run_%s' %run] == 'main']['label_%s_%s' %(run, label_str)])\n",
    "        n_props = 1\n",
    "\n",
    "        generate_dist_matrix_kwargs = {'metric':'tasksim', \n",
    "                                       'metric_kwargs':{'n_neg_classes': 10, \n",
    "                                                        'task_similarity_kwargs': {'transformer_kwargsx': \n",
    "                                                                                       {'max_depth':4},\n",
    "                                                                                  'transformer_kwargsz':\n",
    "                                                                                      {'max_depth':4}}}, \n",
    "                                       'function_tuples':None, \n",
    "                                       'n_cores':n_cores, \n",
    "                                       'acorn':seed\n",
    "                                      }\n",
    "\n",
    "\n",
    "        process_dist_matrix_kwargs = {'make_symmetric': True,\n",
    "                                      'scale':True,\n",
    "                                     'aug_diag':True,\n",
    "                                     }\n",
    "\n",
    "        embedding=ASE\n",
    "        embedding_kwargs={'n_components':16}\n",
    "        cluster=GMM\n",
    "        cluster_kwargs = {'min_components': 20, 'max_components': 20, 'reg_covar': 1e-03}\n",
    "\n",
    "        cluster_dists_kwargs = {'embedding':embedding, \n",
    "                                'embedding_kwargs':embedding_kwargs, \n",
    "                                'cluster':cluster, \n",
    "                                'cluster_kwargs':cluster_kwargs\n",
    "                               }\n",
    "\n",
    "        n_mc=1\n",
    "        master_seed = seed\n",
    "        np.random.seed(master_seed)\n",
    "\n",
    "        data_dimension=2048\n",
    "\n",
    "        generate_tasksim=True\n",
    "\n",
    "        if generate_tasksim:\n",
    "            tasksim_clusters = []\n",
    "\n",
    "        #- Generate clusters\n",
    "        for iteration in tqdm(range(n_mc)):\n",
    "            start = time.time()\n",
    "            X_train, _, y_train, _ = train_test_split(trainset.data, trainset.targets, test_size=0.1, random_state=seed)\n",
    "            print(len(X_train), len(y_train))\n",
    "            if generate_tasksim:\n",
    "                temp_tasksim = generate_hierarchy(X_train, y_train, generate_dist_matrix_kwargs, process_dist_matrix_kwargs, cluster_dists_kwargs)\n",
    "                tasksim_clusters.append(temp_tasksim)\n",
    "\n",
    "                pickle.dump(tasksim_clusters, open('../../../teamdrive/transmediasp/kate/hierarchy/icons_tasksim_clusters_%s_%s.p' %(run, label_str), 'wb'))\n",
    "        print(\"Clusters are generated for run %s, label noise %s\" %(run, label_noise))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-company",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-scanner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-commissioner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
