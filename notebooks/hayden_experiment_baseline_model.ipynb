{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook establishes baseline auc for CheXpert -to cheXphoto transfer rate\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve, auc\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acorn = 1234\n",
    "torch.manual_seed(acorn)\n",
    "np.random.seed(acorn)\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "    \n",
    "device = torch.device(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.CIFAR100(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.CIFAR100(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    "#    target_transform=Lambda(lambda y: torch.zeros(100, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")\n",
    "\n",
    "\n",
    "test_data = datasets.CIFAR100(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    "#    target_transform=Lambda(lambda y: torch.zeros(100, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4273629a58>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train.__getitem__(0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/cifar-100-python/meta\", 'rb') as fo:\n",
    "    labels = pickle.load(fo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fine_label_names': ['apple',\n",
       "  'aquarium_fish',\n",
       "  'baby',\n",
       "  'bear',\n",
       "  'beaver',\n",
       "  'bed',\n",
       "  'bee',\n",
       "  'beetle',\n",
       "  'bicycle',\n",
       "  'bottle',\n",
       "  'bowl',\n",
       "  'boy',\n",
       "  'bridge',\n",
       "  'bus',\n",
       "  'butterfly',\n",
       "  'camel',\n",
       "  'can',\n",
       "  'castle',\n",
       "  'caterpillar',\n",
       "  'cattle',\n",
       "  'chair',\n",
       "  'chimpanzee',\n",
       "  'clock',\n",
       "  'cloud',\n",
       "  'cockroach',\n",
       "  'couch',\n",
       "  'crab',\n",
       "  'crocodile',\n",
       "  'cup',\n",
       "  'dinosaur',\n",
       "  'dolphin',\n",
       "  'elephant',\n",
       "  'flatfish',\n",
       "  'forest',\n",
       "  'fox',\n",
       "  'girl',\n",
       "  'hamster',\n",
       "  'house',\n",
       "  'kangaroo',\n",
       "  'keyboard',\n",
       "  'lamp',\n",
       "  'lawn_mower',\n",
       "  'leopard',\n",
       "  'lion',\n",
       "  'lizard',\n",
       "  'lobster',\n",
       "  'man',\n",
       "  'maple_tree',\n",
       "  'motorcycle',\n",
       "  'mountain',\n",
       "  'mouse',\n",
       "  'mushroom',\n",
       "  'oak_tree',\n",
       "  'orange',\n",
       "  'orchid',\n",
       "  'otter',\n",
       "  'palm_tree',\n",
       "  'pear',\n",
       "  'pickup_truck',\n",
       "  'pine_tree',\n",
       "  'plain',\n",
       "  'plate',\n",
       "  'poppy',\n",
       "  'porcupine',\n",
       "  'possum',\n",
       "  'rabbit',\n",
       "  'raccoon',\n",
       "  'ray',\n",
       "  'road',\n",
       "  'rocket',\n",
       "  'rose',\n",
       "  'sea',\n",
       "  'seal',\n",
       "  'shark',\n",
       "  'shrew',\n",
       "  'skunk',\n",
       "  'skyscraper',\n",
       "  'snail',\n",
       "  'snake',\n",
       "  'spider',\n",
       "  'squirrel',\n",
       "  'streetcar',\n",
       "  'sunflower',\n",
       "  'sweet_pepper',\n",
       "  'table',\n",
       "  'tank',\n",
       "  'telephone',\n",
       "  'television',\n",
       "  'tiger',\n",
       "  'tractor',\n",
       "  'train',\n",
       "  'trout',\n",
       "  'tulip',\n",
       "  'turtle',\n",
       "  'wardrobe',\n",
       "  'whale',\n",
       "  'willow_tree',\n",
       "  'wolf',\n",
       "  'woman',\n",
       "  'worm'],\n",
       " 'coarse_label_names': ['aquatic_mammals',\n",
       "  'fish',\n",
       "  'flowers',\n",
       "  'food_containers',\n",
       "  'fruit_and_vegetables',\n",
       "  'household_electrical_devices',\n",
       "  'household_furniture',\n",
       "  'insects',\n",
       "  'large_carnivores',\n",
       "  'large_man-made_outdoor_things',\n",
       "  'large_natural_outdoor_scenes',\n",
       "  'large_omnivores_and_herbivores',\n",
       "  'medium_mammals',\n",
       "  'non-insect_invertebrates',\n",
       "  'people',\n",
       "  'reptiles',\n",
       "  'small_mammals',\n",
       "  'trees',\n",
       "  'vehicles_1',\n",
       "  'vehicles_2']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnext50(torch.nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        resnet = torchvision.models.resnext50_32x4d(pretrained=True, progress=True)\n",
    "        resnet.fc = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(in_features=resnet.fc.in_features, out_features=n_classes)\n",
    "        )\n",
    "        self.base_model = resnet\n",
    "#         self.soft = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Initialize the model\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "model = Resnext50(100)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# checkpt = torch.load('CheXpert_0_resnet50')\n",
    "# chexpert_model.load_state_dict(checkpt['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpt['optimizer_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            correct = (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}] acc: {(100*correct/64):>0.1f}%\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.834321  [    0/50000]\n",
      "loss: 3.762840  [ 6400/50000]\n",
      "loss: 3.170149  [12800/50000]\n",
      "loss: 2.648679  [19200/50000]\n",
      "loss: 2.153364  [25600/50000]\n",
      "loss: 2.086865  [32000/50000]\n",
      "loss: 2.736150  [38400/50000]\n",
      "loss: 2.166894  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 0.030783 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.260587  [    0/50000]\n",
      "loss: 1.771301  [ 6400/50000]\n",
      "loss: 1.614566  [12800/50000]\n",
      "loss: 1.303818  [19200/50000]\n",
      "loss: 2.156773  [25600/50000]\n",
      "loss: 1.702928  [32000/50000]\n",
      "loss: 1.625726  [38400/50000]\n",
      "loss: 1.567609  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.026828 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.995247  [    0/50000]\n",
      "loss: 1.124683  [ 6400/50000]\n",
      "loss: 1.508117  [12800/50000]\n",
      "loss: 1.199805  [19200/50000]\n",
      "loss: 1.141508  [25600/50000]\n",
      "loss: 1.378473  [32000/50000]\n",
      "loss: 1.188814  [38400/50000]\n",
      "loss: 1.098660  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 0.026225 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.863726  [    0/50000]\n",
      "loss: 0.467269  [ 6400/50000]\n",
      "loss: 0.660532  [12800/50000]\n",
      "loss: 0.696839  [19200/50000]\n",
      "loss: 0.966101  [25600/50000]\n",
      "loss: 0.775251  [32000/50000]\n",
      "loss: 0.780557  [38400/50000]\n",
      "loss: 1.215103  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 0.027012 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.453120  [    0/50000]\n",
      "loss: 0.532036  [ 6400/50000]\n",
      "loss: 0.436046  [12800/50000]\n",
      "loss: 0.644915  [19200/50000]\n",
      "loss: 0.561230  [25600/50000]\n",
      "loss: 0.608619  [32000/50000]\n",
      "loss: 0.432363  [38400/50000]\n",
      "loss: 0.504645  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.027606 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.313027  [    0/50000]\n",
      "loss: 0.288801  [ 6400/50000]\n",
      "loss: 0.607758  [12800/50000]\n",
      "loss: 0.368777  [19200/50000]\n",
      "loss: 0.449367  [25600/50000]\n",
      "loss: 0.555004  [32000/50000]\n",
      "loss: 0.535795  [38400/50000]\n",
      "loss: 0.487502  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.1%, Avg loss: 0.029094 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.288610  [    0/50000]\n",
      "loss: 0.261898  [ 6400/50000]\n",
      "loss: 0.392432  [12800/50000]\n",
      "loss: 0.410470  [19200/50000]\n",
      "loss: 0.269524  [25600/50000]\n",
      "loss: 0.280779  [32000/50000]\n",
      "loss: 0.170981  [38400/50000]\n",
      "loss: 0.421646  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.030172 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.305001  [    0/50000]\n",
      "loss: 0.415011  [ 6400/50000]\n",
      "loss: 0.171613  [12800/50000]\n",
      "loss: 0.201707  [19200/50000]\n",
      "loss: 0.285762  [25600/50000]\n",
      "loss: 0.410844  [32000/50000]\n",
      "loss: 0.534289  [38400/50000]\n",
      "loss: 0.257418  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.1%, Avg loss: 0.031840 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.187892  [    0/50000]\n",
      "loss: 0.206485  [ 6400/50000]\n",
      "loss: 0.138072  [12800/50000]\n",
      "loss: 0.314625  [19200/50000]\n",
      "loss: 0.312485  [25600/50000]\n",
      "loss: 0.244389  [32000/50000]\n",
      "loss: 0.192548  [38400/50000]\n",
      "loss: 0.427178  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.032708 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.150270  [    0/50000]\n",
      "loss: 0.074052  [ 6400/50000]\n",
      "loss: 0.244127  [12800/50000]\n",
      "loss: 0.087608  [19200/50000]\n",
      "loss: 0.200885  [25600/50000]\n",
      "loss: 0.160499  [32000/50000]\n",
      "loss: 0.255015  [38400/50000]\n",
      "loss: 0.247839  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.032904 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.189936  [    0/50000]\n",
      "loss: 0.246382  [ 6400/50000]\n",
      "loss: 0.130525  [12800/50000]\n",
      "loss: 0.206921  [19200/50000]\n",
      "loss: 0.178904  [25600/50000]\n",
      "loss: 0.242875  [32000/50000]\n",
      "loss: 0.121114  [38400/50000]\n",
      "loss: 0.105334  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 0.033400 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.149046  [    0/50000]\n",
      "loss: 0.180003  [ 6400/50000]\n",
      "loss: 0.126426  [12800/50000]\n",
      "loss: 0.157108  [19200/50000]\n",
      "loss: 0.206573  [25600/50000]\n",
      "loss: 0.331396  [32000/50000]\n",
      "loss: 0.094265  [38400/50000]\n",
      "loss: 0.217105  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 0.033706 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.176828  [    0/50000]\n",
      "loss: 0.080975  [ 6400/50000]\n",
      "loss: 0.179018  [12800/50000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-7718ecf97cd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-d191cedd6906>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-38951f2f7e81>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         x = self.flatten(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Initialize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_env/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_env/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_env/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_env/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_env/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_env/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# resnext lr=1e-4 epochs=20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.693388  [    0/50000]\n",
      "loss: 3.782035  [ 6400/50000]\n",
      "loss: 3.437772  [12800/50000]\n",
      "loss: 3.404156  [19200/50000]\n",
      "loss: 3.073623  [25600/50000]\n",
      "loss: 3.112524  [32000/50000]\n",
      "loss: 2.557342  [38400/50000]\n",
      "loss: 2.224792  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.2%, Avg loss: 0.039299 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.505208  [    0/50000]\n",
      "loss: 2.259551  [ 6400/50000]\n",
      "loss: 2.560164  [12800/50000]\n",
      "loss: 1.987200  [19200/50000]\n",
      "loss: 2.619271  [25600/50000]\n",
      "loss: 2.892432  [32000/50000]\n",
      "loss: 2.317332  [38400/50000]\n",
      "loss: 2.237772  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.1%, Avg loss: 0.036478 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.989111  [    0/50000]\n",
      "loss: 2.036504  [ 6400/50000]\n",
      "loss: 2.505474  [12800/50000]\n",
      "loss: 1.934663  [19200/50000]\n",
      "loss: 2.304322  [25600/50000]\n",
      "loss: 2.233503  [32000/50000]\n",
      "loss: 1.998961  [38400/50000]\n",
      "loss: 1.859582  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 0.032707 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.746798  [    0/50000]\n",
      "loss: 1.813614  [ 6400/50000]\n",
      "loss: 1.800059  [12800/50000]\n",
      "loss: 1.757800  [19200/50000]\n",
      "loss: 2.130205  [25600/50000]\n",
      "loss: 1.839100  [32000/50000]\n",
      "loss: 2.008951  [38400/50000]\n",
      "loss: 1.594854  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 0.029998 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.229251  [    0/50000]\n",
      "loss: 1.708489  [ 6400/50000]\n",
      "loss: 1.390678  [12800/50000]\n",
      "loss: 1.185037  [19200/50000]\n",
      "loss: 1.512991  [25600/50000]\n",
      "loss: 1.994234  [32000/50000]\n",
      "loss: 1.523020  [38400/50000]\n",
      "loss: 1.515224  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 0.033331 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.726358  [    0/50000]\n",
      "loss: 1.098731  [ 6400/50000]\n",
      "loss: 1.444335  [12800/50000]\n",
      "loss: 1.003277  [19200/50000]\n",
      "loss: 1.166152  [25600/50000]\n",
      "loss: 1.404792  [32000/50000]\n",
      "loss: 1.365066  [38400/50000]\n",
      "loss: 1.309663  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.6%, Avg loss: 0.031366 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.810292  [    0/50000]\n",
      "loss: 1.083379  [ 6400/50000]\n",
      "loss: 1.259021  [12800/50000]\n",
      "loss: 1.030538  [19200/50000]\n",
      "loss: 1.454871  [25600/50000]\n",
      "loss: 1.496466  [32000/50000]\n",
      "loss: 0.873766  [38400/50000]\n",
      "loss: 1.231498  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.3%, Avg loss: 0.030285 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.985868  [    0/50000]\n",
      "loss: 0.642773  [ 6400/50000]\n",
      "loss: 0.881144  [12800/50000]\n",
      "loss: 0.745589  [19200/50000]\n",
      "loss: 1.101390  [25600/50000]\n",
      "loss: 0.799049  [32000/50000]\n",
      "loss: 0.877843  [38400/50000]\n",
      "loss: 1.355842  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: 0.031906 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.562682  [    0/50000]\n",
      "loss: 0.761003  [ 6400/50000]\n",
      "loss: 0.701203  [12800/50000]\n",
      "loss: 0.564036  [19200/50000]\n",
      "loss: 0.711138  [25600/50000]\n",
      "loss: 0.753738  [32000/50000]\n",
      "loss: 0.744787  [38400/50000]\n",
      "loss: 0.820210  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 0.033912 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.458678  [    0/50000]\n",
      "loss: 0.629327  [ 6400/50000]\n",
      "loss: 0.523318  [12800/50000]\n",
      "loss: 0.500218  [19200/50000]\n",
      "loss: 0.555898  [25600/50000]\n",
      "loss: 0.462691  [32000/50000]\n",
      "loss: 0.554584  [38400/50000]\n",
      "loss: 0.695616  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.6%, Avg loss: 0.035898 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# lr 1e-3\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.725864  [    0/50000]\n",
      "loss: 3.968250  [ 6400/50000]\n",
      "loss: 3.236192  [12800/50000]\n",
      "loss: 2.500150  [19200/50000]\n",
      "loss: 2.470026  [25600/50000]\n",
      "loss: 2.090750  [32000/50000]\n",
      "loss: 2.027941  [38400/50000]\n",
      "loss: 2.247874  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 0.030655 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.401441  [    0/50000]\n",
      "loss: 1.576713  [ 6400/50000]\n",
      "loss: 1.269603  [12800/50000]\n",
      "loss: 1.776221  [19200/50000]\n",
      "loss: 1.313246  [25600/50000]\n",
      "loss: 1.702384  [32000/50000]\n",
      "loss: 1.785173  [38400/50000]\n",
      "loss: 1.838932  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.027126 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.111194  [    0/50000]\n",
      "loss: 1.058957  [ 6400/50000]\n",
      "loss: 0.935262  [12800/50000]\n",
      "loss: 1.211025  [19200/50000]\n",
      "loss: 1.189626  [25600/50000]\n",
      "loss: 1.122601  [32000/50000]\n",
      "loss: 1.070213  [38400/50000]\n",
      "loss: 1.125145  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 0.026264 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.681940  [    0/50000]\n",
      "loss: 0.471877  [ 6400/50000]\n",
      "loss: 0.873480  [12800/50000]\n",
      "loss: 0.814136  [19200/50000]\n",
      "loss: 0.976319  [25600/50000]\n",
      "loss: 1.027487  [32000/50000]\n",
      "loss: 0.876438  [38400/50000]\n",
      "loss: 0.873233  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 0.027242 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.666297  [    0/50000]\n",
      "loss: 0.661701  [ 6400/50000]\n",
      "loss: 0.418134  [12800/50000]\n",
      "loss: 0.588701  [19200/50000]\n",
      "loss: 0.605445  [25600/50000]\n",
      "loss: 0.652369  [32000/50000]\n",
      "loss: 0.699063  [38400/50000]\n",
      "loss: 0.668566  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.028175 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.467295  [    0/50000]\n",
      "loss: 0.378779  [ 6400/50000]\n",
      "loss: 0.379440  [12800/50000]\n",
      "loss: 0.338082  [19200/50000]\n",
      "loss: 0.498554  [25600/50000]\n",
      "loss: 0.343096  [32000/50000]\n",
      "loss: 0.465527  [38400/50000]\n",
      "loss: 0.483915  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.3%, Avg loss: 0.029442 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.202919  [    0/50000]\n",
      "loss: 0.321917  [ 6400/50000]\n",
      "loss: 0.375522  [12800/50000]\n",
      "loss: 0.334998  [19200/50000]\n",
      "loss: 0.268334  [25600/50000]\n",
      "loss: 0.585015  [32000/50000]\n",
      "loss: 0.365257  [38400/50000]\n",
      "loss: 0.521210  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.031108 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.236059  [    0/50000]\n",
      "loss: 0.221224  [ 6400/50000]\n",
      "loss: 0.212923  [12800/50000]\n",
      "loss: 0.176052  [19200/50000]\n",
      "loss: 0.258665  [25600/50000]\n",
      "loss: 0.338484  [32000/50000]\n",
      "loss: 0.208264  [38400/50000]\n",
      "loss: 0.517151  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.032550 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.258537  [    0/50000]\n",
      "loss: 0.216239  [ 6400/50000]\n",
      "loss: 0.186920  [12800/50000]\n",
      "loss: 0.271814  [19200/50000]\n",
      "loss: 0.247913  [25600/50000]\n",
      "loss: 0.348587  [32000/50000]\n",
      "loss: 0.363196  [38400/50000]\n",
      "loss: 0.300153  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 0.033619 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.152254  [    0/50000]\n",
      "loss: 0.144056  [ 6400/50000]\n",
      "loss: 0.135652  [12800/50000]\n",
      "loss: 0.142670  [19200/50000]\n",
      "loss: 0.135084  [25600/50000]\n",
      "loss: 0.040455  [32000/50000]\n",
      "loss: 0.169470  [38400/50000]\n",
      "loss: 0.175023  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.034775 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#learning rate 1e-4\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.762182  [    0/50000]\n",
      "loss: 4.616714  [ 6400/50000]\n",
      "loss: 4.678048  [12800/50000]\n",
      "loss: 4.498742  [19200/50000]\n",
      "loss: 4.314584  [25600/50000]\n",
      "loss: 4.222754  [32000/50000]\n",
      "loss: 4.113218  [38400/50000]\n",
      "loss: 3.986754  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 16.0%, Avg loss: 0.060626 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.684052  [    0/50000]\n",
      "loss: 3.521301  [ 6400/50000]\n",
      "loss: 3.484402  [12800/50000]\n",
      "loss: 3.745250  [19200/50000]\n",
      "loss: 3.327995  [25600/50000]\n",
      "loss: 3.081394  [32000/50000]\n",
      "loss: 3.188000  [38400/50000]\n",
      "loss: 3.033539  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 28.5%, Avg loss: 0.048097 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.056717  [    0/50000]\n",
      "loss: 2.882919  [ 6400/50000]\n",
      "loss: 2.907444  [12800/50000]\n",
      "loss: 2.728101  [19200/50000]\n",
      "loss: 2.825492  [25600/50000]\n",
      "loss: 2.738197  [32000/50000]\n",
      "loss: 2.913055  [38400/50000]\n",
      "loss: 2.484855  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.4%, Avg loss: 0.040310 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.339524  [    0/50000]\n",
      "loss: 2.307432  [ 6400/50000]\n",
      "loss: 2.145032  [12800/50000]\n",
      "loss: 2.200401  [19200/50000]\n",
      "loss: 2.438294  [25600/50000]\n",
      "loss: 2.107182  [32000/50000]\n",
      "loss: 2.671240  [38400/50000]\n",
      "loss: 2.455863  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 41.4%, Avg loss: 0.035736 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.009305  [    0/50000]\n",
      "loss: 1.925189  [ 6400/50000]\n",
      "loss: 1.763524  [12800/50000]\n",
      "loss: 1.702868  [19200/50000]\n",
      "loss: 1.868284  [25600/50000]\n",
      "loss: 1.901543  [32000/50000]\n",
      "loss: 1.732781  [38400/50000]\n",
      "loss: 2.020187  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 0.033222 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.713309  [    0/50000]\n",
      "loss: 1.717362  [ 6400/50000]\n",
      "loss: 1.976978  [12800/50000]\n",
      "loss: 1.817634  [19200/50000]\n",
      "loss: 1.793657  [25600/50000]\n",
      "loss: 1.792938  [32000/50000]\n",
      "loss: 1.489659  [38400/50000]\n",
      "loss: 1.999417  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 0.031546 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.383684  [    0/50000]\n",
      "loss: 1.505896  [ 6400/50000]\n",
      "loss: 1.327651  [12800/50000]\n",
      "loss: 1.454487  [19200/50000]\n",
      "loss: 1.319606  [25600/50000]\n",
      "loss: 1.940500  [32000/50000]\n",
      "loss: 1.449364  [38400/50000]\n",
      "loss: 1.154099  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 0.030852 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.265983  [    0/50000]\n",
      "loss: 1.375602  [ 6400/50000]\n",
      "loss: 1.379579  [12800/50000]\n",
      "loss: 1.600872  [19200/50000]\n",
      "loss: 1.356034  [25600/50000]\n",
      "loss: 1.249997  [32000/50000]\n",
      "loss: 1.172951  [38400/50000]\n",
      "loss: 1.247714  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 0.029771 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.411198  [    0/50000]\n",
      "loss: 1.233052  [ 6400/50000]\n",
      "loss: 1.213734  [12800/50000]\n",
      "loss: 1.147760  [19200/50000]\n",
      "loss: 1.220796  [25600/50000]\n",
      "loss: 1.311362  [32000/50000]\n",
      "loss: 1.154856  [38400/50000]\n",
      "loss: 1.102314  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.029670 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.069636  [    0/50000]\n",
      "loss: 1.045206  [ 6400/50000]\n",
      "loss: 1.024549  [12800/50000]\n",
      "loss: 0.933574  [19200/50000]\n",
      "loss: 0.683628  [25600/50000]\n",
      "loss: 0.968273  [32000/50000]\n",
      "loss: 1.037777  [38400/50000]\n",
      "loss: 1.014359  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 0.029530 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#learnig rate 1e-5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.920314  [    0/50000] acc: 10.9%\n",
      "loss: 2.968153  [ 6400/50000] acc: 26.6%\n",
      "loss: 2.818209  [12800/50000] acc: 32.8%\n",
      "loss: 2.598699  [19200/50000] acc: 37.5%\n",
      "loss: 2.347325  [25600/50000] acc: 40.6%\n",
      "loss: 2.103778  [32000/50000] acc: 45.3%\n",
      "loss: 1.743212  [38400/50000] acc: 56.2%\n",
      "loss: 1.823738  [44800/50000] acc: 45.3%\n",
      "Test Error: \n",
      " Accuracy: 48.3%, Avg loss: 0.030546 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.653116  [    0/50000] acc: 53.1%\n",
      "loss: 1.503385  [ 6400/50000] acc: 57.8%\n",
      "loss: 1.667892  [12800/50000] acc: 54.7%\n",
      "loss: 1.950733  [19200/50000] acc: 46.9%\n",
      "loss: 1.258519  [25600/50000] acc: 71.9%\n",
      "loss: 1.529648  [32000/50000] acc: 59.4%\n",
      "loss: 1.586209  [38400/50000] acc: 59.4%\n",
      "loss: 1.320103  [44800/50000] acc: 59.4%\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 0.027887 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.154357  [    0/50000] acc: 65.6%\n",
      "loss: 0.875173  [ 6400/50000] acc: 71.9%\n",
      "loss: 1.036814  [12800/50000] acc: 71.9%\n",
      "loss: 1.097775  [19200/50000] acc: 68.8%\n",
      "loss: 0.906749  [25600/50000] acc: 75.0%\n",
      "loss: 1.290837  [32000/50000] acc: 65.6%\n",
      "loss: 1.082470  [38400/50000] acc: 73.4%\n",
      "loss: 1.572184  [44800/50000] acc: 54.7%\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 0.027188 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.897269  [    0/50000] acc: 76.6%\n",
      "loss: 0.726322  [ 6400/50000] acc: 79.7%\n",
      "loss: 0.656525  [12800/50000] acc: 82.8%\n",
      "loss: 0.591372  [19200/50000] acc: 81.2%\n",
      "loss: 0.599755  [25600/50000] acc: 82.8%\n",
      "loss: 0.632823  [32000/50000] acc: 79.7%\n",
      "loss: 0.932986  [38400/50000] acc: 71.9%\n",
      "loss: 0.928511  [44800/50000] acc: 73.4%\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.027380 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.730019  [    0/50000] acc: 84.4%\n",
      "loss: 0.605524  [ 6400/50000] acc: 85.9%\n",
      "loss: 0.448281  [12800/50000] acc: 82.8%\n",
      "loss: 0.425625  [19200/50000] acc: 84.4%\n",
      "loss: 0.678783  [25600/50000] acc: 84.4%\n",
      "loss: 0.889794  [32000/50000] acc: 71.9%\n",
      "loss: 0.824145  [38400/50000] acc: 82.8%\n",
      "loss: 0.496328  [44800/50000] acc: 82.8%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.028014 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.476235  [    0/50000] acc: 79.7%\n",
      "loss: 0.355861  [ 6400/50000] acc: 90.6%\n",
      "loss: 0.428641  [12800/50000] acc: 87.5%\n",
      "loss: 0.588924  [19200/50000] acc: 79.7%\n",
      "loss: 0.352656  [25600/50000] acc: 90.6%\n",
      "loss: 0.562250  [32000/50000] acc: 87.5%\n",
      "loss: 0.599458  [38400/50000] acc: 81.2%\n",
      "loss: 0.570000  [44800/50000] acc: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 0.028938 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.193451  [    0/50000] acc: 93.8%\n",
      "loss: 0.363054  [ 6400/50000] acc: 89.1%\n",
      "loss: 0.298370  [12800/50000] acc: 92.2%\n",
      "loss: 0.109075  [19200/50000] acc: 100.0%\n",
      "loss: 0.226081  [25600/50000] acc: 96.9%\n",
      "loss: 0.201452  [32000/50000] acc: 93.8%\n",
      "loss: 0.165313  [38400/50000] acc: 92.2%\n",
      "loss: 0.156631  [44800/50000] acc: 96.9%\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 0.031083 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.269908  [    0/50000] acc: 89.1%\n",
      "loss: 0.247820  [ 6400/50000] acc: 92.2%\n",
      "loss: 0.285865  [12800/50000] acc: 89.1%\n",
      "loss: 0.336048  [19200/50000] acc: 87.5%\n",
      "loss: 0.351174  [25600/50000] acc: 89.1%\n",
      "loss: 0.387285  [32000/50000] acc: 87.5%\n",
      "loss: 0.347513  [38400/50000] acc: 89.1%\n",
      "loss: 0.333705  [44800/50000] acc: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 0.031991 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.167743  [    0/50000] acc: 95.3%\n",
      "loss: 0.365169  [ 6400/50000] acc: 89.1%\n",
      "loss: 0.194984  [12800/50000] acc: 93.8%\n",
      "loss: 0.130419  [19200/50000] acc: 95.3%\n",
      "loss: 0.200016  [25600/50000] acc: 93.8%\n",
      "loss: 0.205966  [32000/50000] acc: 90.6%\n",
      "loss: 0.258631  [38400/50000] acc: 92.2%\n",
      "loss: 0.235615  [44800/50000] acc: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 0.032820 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.211545  [    0/50000] acc: 93.8%\n",
      "loss: 0.231684  [ 6400/50000] acc: 95.3%\n",
      "loss: 0.208044  [12800/50000] acc: 93.8%\n",
      "loss: 0.336682  [19200/50000] acc: 90.6%\n",
      "loss: 0.242390  [25600/50000] acc: 90.6%\n",
      "loss: 0.179343  [32000/50000] acc: 95.3%\n",
      "loss: 0.207889  [38400/50000] acc: 93.8%\n",
      "loss: 0.131767  [44800/50000] acc: 96.9%\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 0.033524 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#wide \n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
