{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization,Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.datasets import cifar100\n",
    "from tensorflow.random import set_seed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "# from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "20\n",
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#convert fine label to course label\n",
    "(fx, fy), (fxx, fyy) = cifar100.load_data()\n",
    "(cx, cy), (cxx, cyy) = cifar100.load_data(label_mode='coarse') \n",
    "\n",
    "fine_to_coarse = {}\n",
    "for f,c in zip( fy, cy):\n",
    "    fine_to_coarse[f[0]] = c[0]\n",
    "\n",
    "x_train = fx\n",
    "y_train = fy\n",
    "x_test = fxx\n",
    "y_test = fyy\n",
    "\n",
    "print(len(fine_to_coarse))\n",
    "print(len(set(fine_to_coarse.values())))\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "del fx, fy, fxx, fyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 224, 224, 3) (10000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "target_size = (224,224)\n",
    "\n",
    "x_train = np.array( [ preprocess_input(cv2.resize(x,target_size)) for x in x_train])\n",
    "x_test =  np.array( [ preprocess_input(cv2.resize(x,target_size)) for x in x_test])\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "x_train_resnet = x_train[:25000]\n",
    "y_train_resnet = to_categorical(y_train[:25000])\n",
    "x_train_reserve = x_train[25000:]\n",
    "y_train_reserve = to_categorical(y_train[25000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "521/521 [==============================] - 753s 1s/step - loss: 4.2508 - accuracy: 0.0514 - val_loss: 3.6793 - val_accuracy: 0.1273\n",
      "Epoch 2/10\n",
      "521/521 [==============================] - 453s 869ms/step - loss: 3.0877 - accuracy: 0.2031 - val_loss: 2.9250 - val_accuracy: 0.2470\n",
      "Epoch 3/10\n",
      "521/521 [==============================] - 452s 869ms/step - loss: 2.4740 - accuracy: 0.3264 - val_loss: 2.5322 - val_accuracy: 0.3336\n",
      "Epoch 4/10\n",
      "521/521 [==============================] - 453s 869ms/step - loss: 2.0305 - accuracy: 0.4326 - val_loss: 2.2060 - val_accuracy: 0.4122\n",
      "Epoch 5/10\n",
      "521/521 [==============================] - 453s 869ms/step - loss: 1.7003 - accuracy: 0.5077 - val_loss: 2.0747 - val_accuracy: 0.4446\n",
      "Epoch 6/10\n",
      "521/521 [==============================] - 452s 869ms/step - loss: 1.3873 - accuracy: 0.5905 - val_loss: 2.1271 - val_accuracy: 0.4568\n",
      "Epoch 7/10\n",
      "521/521 [==============================] - 453s 869ms/step - loss: 1.1447 - accuracy: 0.6525 - val_loss: 2.0121 - val_accuracy: 0.4825\n",
      "Epoch 8/10\n",
      "521/521 [==============================] - 453s 870ms/step - loss: 0.8942 - accuracy: 0.7224 - val_loss: 1.9511 - val_accuracy: 0.5043\n",
      "Epoch 9/10\n",
      "521/521 [==============================] - 452s 869ms/step - loss: 0.6952 - accuracy: 0.7817 - val_loss: 1.9188 - val_accuracy: 0.5219\n",
      "Epoch 10/10\n",
      "521/521 [==============================] - 452s 868ms/step - loss: 0.5248 - accuracy: 0.8300 - val_loss: 2.0721 - val_accuracy: 0.5160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa82739580>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get resnet model, use that for embedding \n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# for layer in resnet_model.layers:\n",
    "#     layer.trainable = False\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "y = Dense(100, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "embd_model  = Model(inputs=base_model.inputs, outputs=y)\n",
    "embd_model.compile(optimizer='adam',\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "embd_model.fit(x_train_resnet, y_train_resnet, epochs=10, batch_size=48, \n",
    "               verbose=True, shuffle=True, validation_data=(x_train_reserve, y_train_reserve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 512) (25000,) (10000, 512)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trained_embed_model = Model(inputs=embd_model.input, outputs = embd_model.layers[-3].output)\n",
    "\n",
    "x_train_reserve = trained_embed_model.predict(x_train_reserve)\n",
    "x_test = trained_embed_model.predict(x_test)\n",
    "\n",
    "y_train_reserve = y_train_reserve.argmax(axis=1)\n",
    "print(x_train_reserve.shape, y_train_reserve.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_positive_class(tx, ty, txx, tyy, wanted_class, fine_to_coarse):\n",
    "    kept_labels = []\n",
    "    for k, v, in fine_to_coarse.items():\n",
    "        if v == wanted_class:\n",
    "            kept_labels.append(k)\n",
    "        \n",
    "    train_data, train_labels = [], []\n",
    "    test_data,  test_labels =  [], []\n",
    "    \n",
    "    for x, y in zip(tx, ty):\n",
    "        #y=y[0]\n",
    "        if y in kept_labels:\n",
    "            train_data.append(x)\n",
    "            \n",
    "    for x, y  in zip (txx, tyy):\n",
    "        #y=y[0]\n",
    "        if y in kept_labels:\n",
    "            test_data.append(x)\n",
    "    \n",
    "    return  np.array(train_data), \\\n",
    "            np.repeat(np.array([0,1]).reshape(1,2), len(train_data), axis=0 ),\\\n",
    "            np.array(test_data),\\\n",
    "            np.repeat(np.array([0,1]).reshape(1,2), len(test_data), axis=0 )\n",
    "\n",
    "\n",
    "\n",
    "def get_data_negative_class (all_data, all_labels, all_test_data, all_test_lables, exclude_classes, fine_to_coarse):\n",
    "    exclude_labels = []\n",
    "    for k, v, in fine_to_coarse.items():\n",
    "        if v in exclude_classes:\n",
    "            exclude_labels.append(k)\n",
    "        \n",
    "    train_data, test_data = [], []\n",
    "    \n",
    "    for x, y in zip(all_data, all_labels):\n",
    "        #y = y[0]\n",
    "        if y not in exclude_labels:\n",
    "            train_data.append(x)\n",
    "            \n",
    "    for x, y  in zip (all_test_data, all_test_lables):\n",
    "        #y = y[0]\n",
    "        if y not in exclude_labels:\n",
    "            test_data.append(x)\n",
    "            \n",
    "    return  np.array(train_data), \\\n",
    "            np.repeat(np.array([1,0]).reshape(1,2), len(train_data), axis=0 ),\\\n",
    "            np.array(test_data),\\\n",
    "            np.repeat(np.array([1,0]).reshape(1,2), len(test_data), axis=0 )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(data, label, model):\n",
    "    pp = np.argmax(model.predict(data), axis=1)\n",
    "    return accuracy_score(label, pp)\n",
    "\n",
    "\n",
    "def model_baseline(x_train, y_train, batch_size=32, epochs=20, verbose=False):\n",
    "    input_dim = x_train.shape[1]\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    \n",
    "    x  = Dense(256, activation='relu',name='shared')(input_layer)\n",
    "    \n",
    "    x    = BatchNormalization()(x)\n",
    "    y = Dense(y_train.shape[-1], activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=y)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=verbose)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_transfer(x_train, y_train, x_transfer, y_transfer, batch_size=48, epochs=20, verbose=False):\n",
    "    input_dim =x_train.shape[1]\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    \n",
    "    x  = Dense(256,  activation='relu',name='shared')(input_layer)\n",
    "    \n",
    "    x    = BatchNormalization()(x)\n",
    "    y = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "    \n",
    "    model_base = Model(inputs=input_layer, outputs=y)\n",
    "    model_base.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    yy = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "    model_transfer = Model(inputs=input_layer, outputs=yy)\n",
    "    model_transfer.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    for _ in range(epochs):\n",
    "    \n",
    "        #training\n",
    "        model_base.fit(x_train, y_train, batch_size=batch_size, epochs=1, shuffle=True, verbose=verbose)\n",
    "    \n",
    "        #transfering\n",
    "        model_transfer.fit(x_transfer, y_transfer, batch_size=batch_size, epochs=1, shuffle=True, verbose=verbose)\n",
    "\n",
    "    return model_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_transfer(x_train, y_train, x_test, y_test, \n",
    "                       transfer_class_idx, used_idx, transfer_percent, fine_to_coarse,  \n",
    "                       train_percent=1.0, batch_size= 48, epochs=20, n_iter=25):\n",
    "    curr_accuracy = []\n",
    "    \n",
    "    \n",
    "    transfer_data, transfer_labels, transfer_test_data, transfer_test_labels = \\\n",
    "        get_data_positive_class(x_train , y_train, x_test, y_test, transfer_class_idx, fine_to_coarse)\n",
    "\n",
    "    #negative data are all classes that's no in transfer class and used class\n",
    "    train_neg_data, train_neg_labels, test_neg_data, test_neg_label \\\n",
    "                = get_data_negative_class(x_train , y_train, x_test, y_test, used_idx + [transfer_class_idx], fine_to_coarse)\n",
    "        \n",
    "    \n",
    "    \n",
    "    transfer_full_data = np.vstack([transfer_data, train_neg_data])\n",
    "    transfer_full_labels = np.vstack([transfer_labels, train_neg_labels])\n",
    "\n",
    "    transfer_full_test  = np.vstack([transfer_test_data, test_neg_data])\n",
    "    transfer_full_test_lables = np.vstack([transfer_test_labels, test_neg_label])\n",
    "    \n",
    "\n",
    "    #for other in wanted_task_idx:\n",
    "    for other in used_idx:\n",
    "        \n",
    "        train_pos_data, train_pos_labels, test_pos_data, test_pos_labels = \\\n",
    "            get_data_positive_class(x_train , y_train, x_test, y_test, other, fine_to_coarse)\n",
    "        \n",
    "        \n",
    "        train_data = np.vstack([train_pos_data, train_neg_data])\n",
    "        train_labels = np.vstack([train_pos_labels, train_neg_labels])\n",
    "\n",
    "        test_data = np.vstack([test_pos_data, test_neg_data])\n",
    "        test_labels = np.vstack([test_pos_labels, test_neg_label])\n",
    "\n",
    "        transfer_accuracy = []\n",
    "\n",
    "        for i in range(n_iter):\n",
    "            if i % 5 == 0:\n",
    "                print(i,  transfer_percent, coarse_names[other], np.average(transfer_accuracy) )\n",
    "            \n",
    "\n",
    "            #base_case data\n",
    "            total = train_data.shape[0]\n",
    "            train_size = int( total * train_percent)\n",
    "\n",
    "\n",
    "            idx = np.random.choice(total, train_size, replace=False)\n",
    "            d0 = train_data[idx]\n",
    "            l0 = train_labels[idx]\n",
    "\n",
    "\n",
    "            #transfer data!!!\n",
    "            total = transfer_full_data.shape[0]\n",
    "            transfer_size = int( total * transfer_percent)\n",
    "            \n",
    "            idx = np.random.choice(total, transfer_size, replace=False)\n",
    "            d1 = transfer_full_data[idx]\n",
    "            l1 = transfer_full_labels[idx]\n",
    "                        \n",
    "#             print(d0.shape, d1.shape)\n",
    "            \n",
    "            model = model_transfer(d0, l0, d1, l1, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "            p = model.predict(transfer_full_test).argmax(axis=1)\n",
    "            t = transfer_full_test_lables.argmax(axis=1)\n",
    "\n",
    "            f1 = f1_score(p, t, labels=[1])            \n",
    "            transfer_accuracy.append(f1)\n",
    "\n",
    "        curr_accuracy.append( (coarse_names[other], transfer_accuracy ) )\n",
    "    \n",
    "    return curr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_baseline(x_train, y_train, x_test, y_text, transfer_class, used_idx, use_percent, fine_to_coarse,  \n",
    "                train_percent=1.0, batch_size= 48, epochs=20, n_iter=25):\n",
    "    \n",
    "    transfer_data, transfer_labels, transfer_test_data, transfer_test_labels = \\\n",
    "        get_data_positive_class(x_train , y_train, x_test, y_test, transfer_class, fine_to_coarse)\n",
    "\n",
    "    #negative data are all classes that's no in transfer class and used class\n",
    "    train_neg_data, train_neg_labels, test_neg_data, test_neg_label \\\n",
    "                = get_data_negative_class(x_train , y_train, x_test, y_test, used_idx + [transfer_class], fine_to_coarse)\n",
    "        \n",
    "    \n",
    "    \n",
    "    transfer_full_data = np.vstack([transfer_data, train_neg_data])\n",
    "    transfer_full_labels = np.vstack([transfer_labels, train_neg_labels])\n",
    "\n",
    "    transfer_full_test  = np.vstack([transfer_test_data, test_neg_data])\n",
    "    transfer_full_test_lables = np.vstack([transfer_test_labels, test_neg_label])\n",
    "    \n",
    "    accuracies  = []\n",
    "    for i in range(n_iter):\n",
    "        if i % 5 == 0:\n",
    "            print(i,  use_percent, np.average(accuracies) )\n",
    "\n",
    "        total = transfer_full_data.shape[0]\n",
    "        transfer_size = int( total * use_percent)\n",
    "\n",
    "        idx = np.random.choice(total, transfer_size, replace=False)\n",
    "        d = transfer_full_data[idx]\n",
    "        l = transfer_full_labels[idx]\n",
    "        model = model_baseline(d, l, batch_size=batch_size, epochs=epochs)\n",
    "        \n",
    "        p = model.predict(transfer_full_test).argmax(axis=1)\n",
    "        t = transfer_full_test_lables.argmax(axis=1)\n",
    "        \n",
    "        f1  = f1_score(p ,t, labels=[1])\n",
    "        accuracies.append(f1)\n",
    "    return accuracies\n",
    "                        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted = 8 #'large carnivores'\n",
    "\n",
    "coarse_names = [\n",
    "'aquatic_mammals',  'fish', 'flowers', 'food_containers', \n",
    "'fruit_and_vegetables', 'household_electrical_devices', \n",
    "'household_furniture', 'insects', 'large_carnivores',\n",
    "'large_man-made_outdoor_things', 'large_natural_outdoor_scenes',\n",
    "'large_omnivores_and_herbivores', 'medium-sized_mammals',\n",
    "'non-insect_invertebrates', 'people', 'reptiles',\n",
    "'small mammals', 'trees', 'vehicles_1','vehicles_2'\n",
    "]\n",
    "\n",
    "\n",
    "used_set  = ['small mammals',  'vehicles_1', ]\n",
    "used_idx = [i for i, x in enumerate(coarse_names) if x  in used_set ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwei/ml_env/lib/python3.8/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/weiwei/ml_env/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 nan\n",
      "5 0.1 0.5833200540864529\n",
      "10 0.1 0.5882104622570906\n",
      "15 0.1 0.5817722779460561\n",
      "20 0.1 0.5805927811392501\n",
      "Percentage 0.1 : accuracy 0.5779231092139058\n",
      "0 0.2 nan\n",
      "5 0.2 0.5831765777340314\n",
      "10 0.2 0.5852203386175137\n",
      "15 0.2 0.5873487849563528\n",
      "20 0.2 0.5839643365929736\n",
      "Percentage 0.2 : accuracy 0.587206958070933\n",
      "0 0.3 nan\n",
      "5 0.3 0.5884895342392727\n",
      "10 0.3 0.5878288579168749\n",
      "15 0.3 0.5897116817477481\n",
      "20 0.3 0.5925029576096912\n",
      "Percentage 0.3 : accuracy 0.5904663160197445\n",
      "0 0.4 nan\n",
      "5 0.4 0.5913997905180631\n",
      "10 0.4 0.5996197312195328\n",
      "15 0.4 0.6058512323087767\n",
      "20 0.4 0.6056806403579251\n",
      "Percentage 0.4 : accuracy 0.6045195984386522\n",
      "0 0.5 nan\n",
      "5 0.5 0.5967296617536554\n",
      "10 0.5 0.6047542533649725\n",
      "15 0.5 0.6118040493801435\n",
      "20 0.5 0.6091509205990582\n",
      "Percentage 0.5 : accuracy 0.6106531744412788\n",
      "0 0.6 nan\n",
      "5 0.6 0.6105998061654446\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1378d8dcddf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbaseline_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpercentage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mranges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbaseline_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpercentage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_reserve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_reserve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwanted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfine_to_coarse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Percentage %s : accuracy %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpercentage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a04bdc5067b1>\u001b[0m in \u001b[0;36mdo_baseline\u001b[0;34m(x_train, y_train, x_test, y_text, transfer_class, used_idx, use_percent, fine_to_coarse, train_percent, batch_size, epochs, n_iter)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer_full_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer_full_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_full_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-87276cc1fcc2>\u001b[0m in \u001b[0;36mmodel_baseline\u001b[0;34m(x_train, y_train, batch_size, epochs, verbose)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 _r=1):\n\u001b[1;32m   1075\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    792\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    819\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2944\u001b[0m       (graph_function,\n\u001b[1;32m   2945\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2946\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2947\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1924\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1925\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1927\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1928\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    554\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    557\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 9876\n",
    "np.random.seed(seed)\n",
    "set_seed(seed)\n",
    "\n",
    "#measure baseline (non_transfer) accuracy \n",
    "ranges = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "n_iter = 25\n",
    "baseline_acc = {}\n",
    "for percentage in ranges:\n",
    "    baseline_acc[percentage] = do_baseline(x_train_reserve, y_train_reserve, x_test, y_test, wanted, used_idx, percentage, fine_to_coarse, n_iter=n_iter)\n",
    "    print('Percentage %s : accuracy %s' %(percentage, np.average(baseline_acc[percentage])))\n",
    "    \n",
    "with open ('./baseline_acc.p', 'wb') as handle:\n",
    "    pickle.dump(baseline_acc, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 small mammals nan\n",
      "5 0.1 small mammals 0.5758650731912508\n",
      "10 0.1 small mammals 0.5778252131808317\n",
      "15 0.1 small mammals 0.5840642027516203\n",
      "20 0.1 small mammals 0.5841911147022418\n",
      "0 0.1 vehicles_1 nan\n",
      "5 0.1 vehicles_1 0.5800150697837716\n",
      "10 0.1 vehicles_1 0.5790797187006838\n",
      "15 0.1 vehicles_1 0.5755517244898108\n",
      "20 0.1 vehicles_1 0.5761736278795349\n",
      "0.1\n",
      "vehicles_1 0.577932763925673\n",
      "small mammals 0.5837421075041361\n",
      "0 0.2 small mammals nan\n",
      "5 0.2 small mammals 0.5882837194498094\n",
      "10 0.2 small mammals 0.5816505158301527\n",
      "15 0.2 small mammals 0.5827185613198453\n",
      "20 0.2 small mammals 0.5886333060778492\n",
      "0 0.2 vehicles_1 nan\n",
      "5 0.2 vehicles_1 0.5868050443682566\n",
      "10 0.2 vehicles_1 0.5930740222933435\n",
      "15 0.2 vehicles_1 0.5875062272447421\n",
      "20 0.2 vehicles_1 0.589593681404151\n",
      "0.2\n",
      "small mammals 0.5888094056563864\n",
      "vehicles_1 0.5897750160082237\n",
      "0 0.3 small mammals nan\n",
      "5 0.3 small mammals 0.5767301532862078\n",
      "10 0.3 small mammals 0.5865988347074802\n",
      "15 0.3 small mammals 0.5903290306047431\n",
      "20 0.3 small mammals 0.5929001597128563\n",
      "0 0.3 vehicles_1 nan\n",
      "5 0.3 vehicles_1 0.601424547328915\n",
      "10 0.3 vehicles_1 0.5872194966114683\n",
      "15 0.3 vehicles_1 0.5930155206661121\n",
      "20 0.3 vehicles_1 0.5939211116813261\n",
      "0.3\n",
      "small mammals 0.5946596974268828\n",
      "vehicles_1 0.5956633862945104\n",
      "0 0.4 small mammals nan\n",
      "5 0.4 small mammals 0.6056314547150488\n",
      "10 0.4 small mammals 0.6067977222646366\n",
      "15 0.4 small mammals 0.6046479627284468\n",
      "20 0.4 small mammals 0.6049931032495777\n",
      "0 0.4 vehicles_1 nan\n",
      "5 0.4 vehicles_1 0.5977323094362116\n",
      "10 0.4 vehicles_1 0.5998084690786031\n",
      "15 0.4 vehicles_1 0.5912143815009635\n",
      "20 0.4 vehicles_1 0.5930967685583869\n",
      "0.4\n",
      "vehicles_1 0.5951434148887206\n",
      "small mammals 0.6028935285158389\n",
      "0 0.5 small mammals nan\n",
      "5 0.5 small mammals 0.5877086139267876\n",
      "10 0.5 small mammals 0.5964475498949457\n",
      "15 0.5 small mammals 0.5986806576283649\n",
      "20 0.5 small mammals 0.5954410972471678\n",
      "0 0.5 vehicles_1 nan\n",
      "5 0.5 vehicles_1 0.6112199509731644\n",
      "10 0.5 vehicles_1 0.6008898694332924\n",
      "15 0.5 vehicles_1 0.6028401260679394\n",
      "20 0.5 vehicles_1 0.6038820274929884\n",
      "0.5\n",
      "small mammals 0.5951913507217002\n",
      "vehicles_1 0.6043649934374138\n",
      "0 0.6 small mammals nan\n",
      "5 0.6 small mammals 0.5998876284438992\n",
      "10 0.6 small mammals 0.6093587824763915\n",
      "15 0.6 small mammals 0.6087367957346717\n",
      "20 0.6 small mammals 0.6024983895674387\n",
      "0 0.6 vehicles_1 nan\n",
      "5 0.6 vehicles_1 0.5981554126797922\n",
      "10 0.6 vehicles_1 0.5987050335669609\n",
      "15 0.6 vehicles_1 0.604672223566231\n",
      "20 0.6 vehicles_1 0.6056494507523326\n",
      "0.6\n",
      "small mammals 0.60295253919035\n",
      "vehicles_1 0.6063959660276137\n",
      "0 0.7 small mammals nan\n",
      "5 0.7 small mammals 0.6058184701924313\n",
      "10 0.7 small mammals 0.6051420196042172\n",
      "15 0.7 small mammals 0.6101906610029235\n",
      "20 0.7 small mammals 0.6099174383444238\n",
      "0 0.7 vehicles_1 nan\n",
      "5 0.7 vehicles_1 0.6097376028933674\n",
      "10 0.7 vehicles_1 0.6038459961418262\n",
      "15 0.7 vehicles_1 0.603075744583429\n",
      "20 0.7 vehicles_1 0.6066392032856335\n",
      "0.7\n",
      "small mammals 0.608711225495581\n",
      "vehicles_1 0.6091583178032818\n",
      "0 0.8 small mammals nan\n",
      "5 0.8 small mammals 0.6237496792765753\n",
      "10 0.8 small mammals 0.6129275393793244\n",
      "15 0.8 small mammals 0.6108584801971211\n",
      "20 0.8 small mammals 0.6114677651799716\n",
      "0 0.8 vehicles_1 nan\n",
      "5 0.8 vehicles_1 0.6008097857109385\n",
      "10 0.8 vehicles_1 0.6035299999090881\n",
      "15 0.8 vehicles_1 0.6087323013630955\n",
      "20 0.8 vehicles_1 0.6097710634106439\n",
      "0.8\n",
      "small mammals 0.6077234979620286\n",
      "vehicles_1 0.6112514009404832\n",
      "0 0.9 small mammals nan\n",
      "5 0.9 small mammals 0.6212724567667978\n",
      "10 0.9 small mammals 0.611476158142895\n",
      "15 0.9 small mammals 0.605371293504173\n",
      "20 0.9 small mammals 0.6090663876316024\n",
      "0 0.9 vehicles_1 nan\n",
      "5 0.9 vehicles_1 0.6084126399586859\n",
      "10 0.9 vehicles_1 0.6118240193817199\n",
      "15 0.9 vehicles_1 0.6124627793325927\n",
      "20 0.9 vehicles_1 0.6104503522445693\n",
      "0.9\n",
      "small mammals 0.6071801731284924\n",
      "vehicles_1 0.6106719159188366\n",
      "0 1.0 small mammals nan\n",
      "5 1.0 small mammals 0.6154694796620307\n",
      "10 1.0 small mammals 0.6115453499919701\n",
      "15 1.0 small mammals 0.6163263528368993\n",
      "20 1.0 small mammals 0.6109761769646477\n",
      "0 1.0 vehicles_1 nan\n",
      "5 1.0 vehicles_1 0.616918608747105\n",
      "10 1.0 vehicles_1 0.6165739725154438\n",
      "15 1.0 vehicles_1 0.6135818182346046\n",
      "20 1.0 vehicles_1 0.6165317153094148\n",
      "1.0\n",
      "small mammals 0.6078050150278093\n",
      "vehicles_1 0.6148444477169632\n"
     ]
    }
   ],
   "source": [
    "seed = 9876\n",
    "np.random.seed(seed)\n",
    "set_seed(seed)\n",
    "\n",
    "ranges = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "n_iter = 25\n",
    "transfer_acc = {}\n",
    "for percentage in ranges:\n",
    "    res = do_transfer(x_train_reserve, y_train_reserve, x_test, y_test, \n",
    "                       wanted, used_idx, percentage, fine_to_coarse, n_iter=n_iter)\n",
    "    tmp = res\n",
    "    tmp = sorted(tmp, key=lambda x : np.average(x[1]))\n",
    "    transfer_acc[percentage] = res\n",
    "    print(percentage)\n",
    "    for t in tmp:\n",
    "        print (t[0], np.average(t[1]))\n",
    "    \n",
    "with open('./tranfer_acc.p', 'wb') as handle:\n",
    "    pickle.dump(transfer_acc, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "vehicles_1 0.577932763925673 0.5861344537815126\n",
      "small mammals 0.5837421075041361 0.585308056872038\n",
      "0.2\n",
      "small mammals 0.5888094056563864 0.59392575928009\n",
      "vehicles_1 0.5897750160082237 0.5906499429874572\n",
      "0.3\n",
      "small mammals 0.5946596974268828 0.5972093023255814\n",
      "vehicles_1 0.5956633862945104 0.6027713625866051\n",
      "0.4\n",
      "vehicles_1 0.5951434148887206 0.5979843225083987\n",
      "small mammals 0.6028935285158389 0.6078665077473182\n",
      "0.5\n",
      "small mammals 0.5951913507217002 0.5988950276243095\n",
      "vehicles_1 0.6043649934374138 0.6096256684491977\n",
      "0.6\n",
      "small mammals 0.60295253919035 0.6068660022148394\n",
      "vehicles_1 0.6063959660276137 0.6098439375750301\n",
      "0.7\n",
      "small mammals 0.608711225495581 0.6180257510729613\n",
      "vehicles_1 0.6091583178032818 0.6105263157894737\n",
      "0.8\n",
      "small mammals 0.6077234979620286 0.6086956521739131\n",
      "vehicles_1 0.6112514009404832 0.6121546961325967\n",
      "0.9\n",
      "small mammals 0.6071801731284924 0.6155580608793686\n",
      "vehicles_1 0.6106719159188366 0.6106696935300795\n",
      "1.0\n",
      "small mammals 0.6078050150278093 0.6124497991967871\n",
      "vehicles_1 0.6148444477169632 0.6164948453608247\n"
     ]
    }
   ],
   "source": [
    "for k,v in transfer_acc.items():\n",
    "    print (k)\n",
    "    tt = sorted(v, key = lambda x : np.mean(x[1]))\n",
    "    print(tt[0][0], np.mean(tt[0][1]), np.median(tt[0][1]))\n",
    "    print(tt[1][0], np.mean(tt[1][1]), np.median(tt[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.05555556, 0.11111111, 0.16666667, 0.22222222,\n",
       "       0.27777778, 0.33333333, 0.38888889, 0.44444444, 0.5       ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,0.5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
