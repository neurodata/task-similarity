{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from proglearn.forest import UncertaintyForest\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2048) (10000, 2048)\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(X, Y), (X_test_org, Y_test_org) = pickle.load(open('/home/weiwya/cifar_100_Bit_m-r101x1_embd.p', 'rb'))\n",
    "print(X.shape, X_test_org.shape)\n",
    "\n",
    "print (len(np.unique(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(5000, 2048) (5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.42      0.70      0.53       100\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.00      0.00      0.00       100\n",
      "           5       0.48      0.61      0.54       100\n",
      "           6       0.72      0.56      0.63       100\n",
      "           7       0.00      0.00      0.00       100\n",
      "           8       0.73      0.62      0.67       100\n",
      "           9       0.00      0.00      0.00       100\n",
      "          10       0.00      0.00      0.00       100\n",
      "          11       0.76      0.16      0.26       100\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13       0.54      0.54      0.54       100\n",
      "          14       1.00      0.17      0.29       100\n",
      "          15       0.00      0.00      0.00       100\n",
      "          16       0.00      0.00      0.00       100\n",
      "          17       0.00      0.00      0.00       100\n",
      "          18       0.50      0.01      0.02       100\n",
      "          19       0.00      0.00      0.00       100\n",
      "          20       0.79      0.88      0.83       100\n",
      "          21       0.79      0.70      0.74       100\n",
      "          22       0.74      0.73      0.73       100\n",
      "          23       0.00      0.00      0.00       100\n",
      "          24       0.79      0.78      0.78       100\n",
      "          25       1.00      0.02      0.04       100\n",
      "          26       0.00      0.00      0.00       100\n",
      "          27       0.00      0.00      0.00       100\n",
      "          28       0.75      0.48      0.59       100\n",
      "          29       0.65      0.41      0.50       100\n",
      "          30       0.95      0.36      0.52       100\n",
      "          31       0.78      0.58      0.67       100\n",
      "          32       0.00      0.00      0.00       100\n",
      "          33       0.00      0.00      0.00       100\n",
      "          34       0.63      0.58      0.60       100\n",
      "          35       0.74      0.37      0.49       100\n",
      "          36       0.00      0.00      0.00       100\n",
      "          37       0.00      0.00      0.00       100\n",
      "          38       0.00      0.00      0.00       100\n",
      "          39       0.84      0.73      0.78       100\n",
      "          40       0.02      0.90      0.03       100\n",
      "          41       0.00      0.00      0.00       100\n",
      "          42       0.25      0.01      0.02       100\n",
      "          43       0.00      0.00      0.00       100\n",
      "          44       0.00      0.00      0.00       100\n",
      "          45       0.29      0.02      0.04       100\n",
      "          46       0.00      0.00      0.00       100\n",
      "          47       0.00      0.00      0.00       100\n",
      "          48       0.80      0.82      0.81       100\n",
      "          49       0.81      0.13      0.22       100\n",
      "          50       0.00      0.00      0.00       100\n",
      "          51       0.71      0.80      0.75       100\n",
      "          52       0.00      0.00      0.00       100\n",
      "          53       0.79      0.96      0.86       100\n",
      "          54       0.70      0.81      0.75       100\n",
      "          55       0.00      0.00      0.00       100\n",
      "          56       0.76      0.78      0.77       100\n",
      "          57       0.74      0.60      0.66       100\n",
      "          58       0.65      0.60      0.62       100\n",
      "          59       0.00      0.00      0.00       100\n",
      "          60       0.00      0.00      0.00       100\n",
      "          61       0.00      0.00      0.00       100\n",
      "          62       0.55      0.78      0.64       100\n",
      "          63       0.00      0.00      0.00       100\n",
      "          64       0.00      0.00      0.00       100\n",
      "          65       0.00      0.00      0.00       100\n",
      "          66       0.00      0.00      0.00       100\n",
      "          67       0.00      0.00      0.00       100\n",
      "          68       0.61      0.20      0.30       100\n",
      "          69       0.78      0.64      0.70       100\n",
      "          70       0.27      0.55      0.36       100\n",
      "          71       0.00      0.00      0.00       100\n",
      "          72       0.00      0.00      0.00       100\n",
      "          73       0.43      0.66      0.52       100\n",
      "          74       0.00      0.00      0.00       100\n",
      "          75       0.00      0.00      0.00       100\n",
      "          76       0.00      0.00      0.00       100\n",
      "          77       0.00      0.00      0.00       100\n",
      "          78       0.61      0.65      0.63       100\n",
      "          79       0.00      0.00      0.00       100\n",
      "          80       0.00      0.00      0.00       100\n",
      "          81       0.12      0.02      0.03       100\n",
      "          82       0.76      0.89      0.82       100\n",
      "          83       0.48      0.72      0.57       100\n",
      "          84       0.00      0.00      0.00       100\n",
      "          85       0.50      0.57      0.53       100\n",
      "          86       0.59      0.73      0.65       100\n",
      "          87       0.00      0.00      0.00       100\n",
      "          88       0.00      0.00      0.00       100\n",
      "          89       0.27      0.03      0.05       100\n",
      "          90       0.00      0.00      0.00       100\n",
      "          91       0.00      0.00      0.00       100\n",
      "          92       0.83      0.55      0.66       100\n",
      "          93       0.83      0.05      0.09       100\n",
      "          94       0.80      0.43      0.56       100\n",
      "          95       0.48      0.70      0.57       100\n",
      "          96       0.00      0.00      0.00       100\n",
      "          97       0.47      0.54      0.50       100\n",
      "          98       0.00      0.00      0.00       100\n",
      "          99       1.00      0.02      0.04       100\n",
      "\n",
      "    accuracy                           0.26     10000\n",
      "   macro avg       0.32      0.26      0.25     10000\n",
      "weighted avg       0.32      0.26      0.25     10000\n",
      "\n",
      "0.2604\n",
      "took 4441.985990524292\n",
      "\n",
      "1\n",
      "(5000, 2048) (5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81       100\n",
      "           1       0.65      0.71      0.68       100\n",
      "           2       0.38      0.73      0.50       100\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.00      0.00      0.00       100\n",
      "           5       0.46      0.63      0.53       100\n",
      "           6       0.65      0.70      0.67       100\n",
      "           7       0.50      0.02      0.04       100\n",
      "           8       0.65      0.65      0.65       100\n",
      "           9       0.00      0.00      0.00       100\n",
      "          10       0.00      0.00      0.00       100\n",
      "          11       0.46      0.21      0.29       100\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13       0.52      0.58      0.55       100\n",
      "          14       0.33      0.01      0.02       100\n",
      "          15       0.00      0.00      0.00       100\n",
      "          16       0.00      0.00      0.00       100\n",
      "          17       0.00      0.00      0.00       100\n",
      "          18       0.00      0.00      0.00       100\n",
      "          19       0.61      0.75      0.67       100\n",
      "          20       0.69      0.91      0.78       100\n",
      "          21       0.74      0.78      0.76       100\n",
      "          22       0.84      0.78      0.81       100\n",
      "          23       0.81      0.17      0.28       100\n",
      "          24       0.84      0.76      0.80       100\n",
      "          25       0.67      0.02      0.04       100\n",
      "          26       0.00      0.00      0.00       100\n",
      "          27       1.00      0.01      0.02       100\n",
      "          28       0.00      0.00      0.00       100\n",
      "          29       0.00      0.00      0.00       100\n",
      "          30       0.39      0.66      0.49       100\n",
      "          31       1.00      0.05      0.10       100\n",
      "          32       1.00      0.04      0.08       100\n",
      "          33       0.00      0.00      0.00       100\n",
      "          34       0.00      0.00      0.00       100\n",
      "          35       0.67      0.06      0.11       100\n",
      "          36       0.67      0.67      0.67       100\n",
      "          37       0.00      0.00      0.00       100\n",
      "          38       0.00      0.00      0.00       100\n",
      "          39       0.00      0.00      0.00       100\n",
      "          40       0.59      0.48      0.53       100\n",
      "          41       0.00      0.00      0.00       100\n",
      "          42       0.00      0.00      0.00       100\n",
      "          43       0.00      0.00      0.00       100\n",
      "          44       0.01      0.85      0.03       100\n",
      "          45       0.00      0.00      0.00       100\n",
      "          46       0.56      0.38      0.45       100\n",
      "          47       0.00      0.00      0.00       100\n",
      "          48       0.73      0.82      0.77       100\n",
      "          49       0.53      0.83      0.65       100\n",
      "          50       0.56      0.05      0.09       100\n",
      "          51       0.74      0.80      0.77       100\n",
      "          52       0.00      0.00      0.00       100\n",
      "          53       0.84      0.97      0.90       100\n",
      "          54       0.74      0.79      0.76       100\n",
      "          55       0.00      0.00      0.00       100\n",
      "          56       0.91      0.63      0.75       100\n",
      "          57       0.71      0.63      0.67       100\n",
      "          58       0.50      0.80      0.62       100\n",
      "          59       0.00      0.00      0.00       100\n",
      "          60       0.00      0.00      0.00       100\n",
      "          61       0.00      0.00      0.00       100\n",
      "          62       0.78      0.76      0.77       100\n",
      "          63       0.00      0.00      0.00       100\n",
      "          64       0.00      0.00      0.00       100\n",
      "          65       0.27      0.03      0.05       100\n",
      "          66       0.00      0.00      0.00       100\n",
      "          67       0.00      0.00      0.00       100\n",
      "          68       0.73      0.08      0.14       100\n",
      "          69       0.00      0.00      0.00       100\n",
      "          70       0.66      0.83      0.73       100\n",
      "          71       0.00      0.00      0.00       100\n",
      "          72       0.00      0.00      0.00       100\n",
      "          73       0.56      0.54      0.55       100\n",
      "          74       0.00      0.00      0.00       100\n",
      "          75       0.00      0.00      0.00       100\n",
      "          76       0.00      0.00      0.00       100\n",
      "          77       1.00      0.01      0.02       100\n",
      "          78       0.55      0.71      0.62       100\n",
      "          79       0.00      0.00      0.00       100\n",
      "          80       0.00      0.00      0.00       100\n",
      "          81       0.25      0.02      0.04       100\n",
      "          82       0.83      0.87      0.85       100\n",
      "          83       0.87      0.60      0.71       100\n",
      "          84       0.00      0.00      0.00       100\n",
      "          85       0.76      0.39      0.52       100\n",
      "          86       0.93      0.69      0.79       100\n",
      "          87       0.00      0.00      0.00       100\n",
      "          88       0.00      0.00      0.00       100\n",
      "          89       0.00      0.00      0.00       100\n",
      "          90       0.00      0.00      0.00       100\n",
      "          91       0.79      0.65      0.71       100\n",
      "          92       0.39      0.68      0.50       100\n",
      "          93       0.38      0.06      0.10       100\n",
      "          94       0.00      0.00      0.00       100\n",
      "          95       0.49      0.29      0.36       100\n",
      "          96       0.00      0.00      0.00       100\n",
      "          97       0.00      0.00      0.00       100\n",
      "          98       0.00      0.00      0.00       100\n",
      "          99       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.26     10000\n",
      "   macro avg       0.33      0.26      0.25     10000\n",
      "weighted avg       0.33      0.26      0.25     10000\n",
      "\n",
      "0.2604\n",
      "took 4473.487855911255\n",
      "\n",
      "2\n",
      "(5000, 2048) (5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.64      0.67       100\n",
      "           2       0.70      0.52      0.60       100\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.00      0.00      0.00       100\n",
      "           5       0.00      0.00      0.00       100\n",
      "           6       0.74      0.49      0.59       100\n",
      "           7       0.25      0.01      0.02       100\n",
      "           8       0.58      0.67      0.62       100\n",
      "           9       0.67      0.34      0.45       100\n",
      "          10       0.00      0.00      0.00       100\n",
      "          11       0.34      0.61      0.44       100\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13       0.48      0.57      0.52       100\n",
      "          14       1.00      0.11      0.20       100\n",
      "          15       0.00      0.00      0.00       100\n",
      "          16       0.00      0.00      0.00       100\n",
      "          17       0.00      0.00      0.00       100\n",
      "          18       0.00      0.00      0.00       100\n",
      "          19       0.78      0.68      0.73       100\n",
      "          20       0.74      0.87      0.80       100\n",
      "          21       0.00      0.00      0.00       100\n",
      "          22       0.78      0.85      0.81       100\n",
      "          23       0.00      0.00      0.00       100\n",
      "          24       0.95      0.57      0.71       100\n",
      "          25       0.71      0.10      0.18       100\n",
      "          26       0.00      0.00      0.00       100\n",
      "          27       0.00      0.00      0.00       100\n",
      "          28       0.62      0.05      0.09       100\n",
      "          29       0.51      0.55      0.53       100\n",
      "          30       0.00      0.00      0.00       100\n",
      "          31       0.82      0.62      0.70       100\n",
      "          32       0.00      0.00      0.00       100\n",
      "          33       0.00      0.00      0.00       100\n",
      "          34       0.50      0.69      0.58       100\n",
      "          35       0.60      0.28      0.38       100\n",
      "          36       0.47      0.70      0.56       100\n",
      "          37       1.00      0.01      0.02       100\n",
      "          38       0.59      0.30      0.40       100\n",
      "          39       0.90      0.56      0.69       100\n",
      "          40       0.00      0.00      0.00       100\n",
      "          41       0.65      0.73      0.69       100\n",
      "          42       0.00      0.00      0.00       100\n",
      "          43       0.00      0.00      0.00       100\n",
      "          44       0.00      0.00      0.00       100\n",
      "          45       0.00      0.00      0.00       100\n",
      "          46       0.00      0.00      0.00       100\n",
      "          47       0.00      0.00      0.00       100\n",
      "          48       0.83      0.80      0.82       100\n",
      "          49       0.90      0.19      0.31       100\n",
      "          50       0.00      0.00      0.00       100\n",
      "          51       0.79      0.78      0.78       100\n",
      "          52       0.00      0.00      0.00       100\n",
      "          53       0.67      0.97      0.80       100\n",
      "          54       0.69      0.80      0.74       100\n",
      "          55       0.00      0.00      0.00       100\n",
      "          56       0.70      0.80      0.74       100\n",
      "          57       0.60      0.64      0.62       100\n",
      "          58       0.56      0.76      0.65       100\n",
      "          59       0.00      0.00      0.00       100\n",
      "          60       0.00      0.00      0.00       100\n",
      "          61       0.00      0.00      0.00       100\n",
      "          62       0.64      0.76      0.69       100\n",
      "          63       1.00      0.04      0.08       100\n",
      "          64       0.00      0.00      0.00       100\n",
      "          65       0.17      0.03      0.05       100\n",
      "          66       0.00      0.00      0.00       100\n",
      "          67       0.00      0.00      0.00       100\n",
      "          68       0.92      0.11      0.20       100\n",
      "          69       0.70      0.68      0.69       100\n",
      "          70       0.48      0.56      0.52       100\n",
      "          71       0.00      0.00      0.00       100\n",
      "          72       0.00      0.00      0.00       100\n",
      "          73       0.40      0.02      0.04       100\n",
      "          74       0.00      0.00      0.00       100\n",
      "          75       0.00      0.00      0.00       100\n",
      "          76       0.02      0.94      0.03       100\n",
      "          77       0.00      0.00      0.00       100\n",
      "          78       0.70      0.62      0.66       100\n",
      "          79       0.00      0.00      0.00       100\n",
      "          80       0.00      0.00      0.00       100\n",
      "          81       0.83      0.10      0.18       100\n",
      "          82       0.75      0.91      0.82       100\n",
      "          83       0.96      0.45      0.61       100\n",
      "          84       0.00      0.00      0.00       100\n",
      "          85       0.00      0.00      0.00       100\n",
      "          86       0.74      0.64      0.68       100\n",
      "          87       0.00      0.00      0.00       100\n",
      "          88       0.00      0.00      0.00       100\n",
      "          89       0.62      0.15      0.24       100\n",
      "          90       0.00      0.00      0.00       100\n",
      "          91       0.74      0.67      0.70       100\n",
      "          92       0.31      0.54      0.39       100\n",
      "          93       1.00      0.04      0.08       100\n",
      "          94       0.00      0.00      0.00       100\n",
      "          95       0.00      0.00      0.00       100\n",
      "          96       0.00      0.00      0.00       100\n",
      "          97       0.70      0.35      0.47       100\n",
      "          98       0.00      0.00      0.00       100\n",
      "          99       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.26     10000\n",
      "   macro avg       0.34      0.26      0.25     10000\n",
      "weighted avg       0.34      0.26      0.25     10000\n",
      "\n",
      "0.2573\n",
      "took 4583.998624801636\n",
      "\n",
      "3\n",
      "(5000, 2048) (5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.92      0.73       100\n",
      "           1       0.80      0.66      0.72       100\n",
      "           2       0.65      0.59      0.62       100\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.00      0.00      0.00       100\n",
      "           5       0.44      0.68      0.53       100\n",
      "           6       1.00      0.17      0.29       100\n",
      "           7       0.43      0.69      0.53       100\n",
      "           8       0.63      0.67      0.65       100\n",
      "           9       0.66      0.40      0.50       100\n",
      "          10       0.20      0.01      0.02       100\n",
      "          11       0.54      0.13      0.21       100\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13       0.00      0.00      0.00       100\n",
      "          14       0.81      0.48      0.60       100\n",
      "          15       0.11      0.01      0.02       100\n",
      "          16       0.00      0.00      0.00       100\n",
      "          17       0.22      0.02      0.04       100\n",
      "          18       0.00      0.00      0.00       100\n",
      "          19       0.78      0.72      0.75       100\n",
      "          20       0.77      0.89      0.82       100\n",
      "          21       0.87      0.62      0.73       100\n",
      "          22       0.84      0.84      0.84       100\n",
      "          23       0.91      0.20      0.33       100\n",
      "          24       0.93      0.67      0.78       100\n",
      "          25       0.55      0.42      0.47       100\n",
      "          26       0.00      0.00      0.00       100\n",
      "          27       0.14      0.01      0.02       100\n",
      "          28       0.47      0.56      0.51       100\n",
      "          29       0.57      0.50      0.53       100\n",
      "          30       0.37      0.68      0.48       100\n",
      "          31       0.00      0.00      0.00       100\n",
      "          32       0.80      0.04      0.08       100\n",
      "          33       0.80      0.04      0.08       100\n",
      "          34       0.68      0.68      0.68       100\n",
      "          35       0.39      0.30      0.34       100\n",
      "          36       0.51      0.75      0.61       100\n",
      "          37       0.00      0.00      0.00       100\n",
      "          38       0.00      0.00      0.00       100\n",
      "          39       0.85      0.71      0.77       100\n",
      "          40       0.00      0.00      0.00       100\n",
      "          41       0.60      0.77      0.68       100\n",
      "          42       0.00      0.00      0.00       100\n",
      "          43       0.00      0.00      0.00       100\n",
      "          44       0.00      0.00      0.00       100\n",
      "          45       0.00      0.00      0.00       100\n",
      "          46       0.00      0.00      0.00       100\n",
      "          47       0.02      0.89      0.03       100\n",
      "          48       0.81      0.79      0.80       100\n",
      "          49       0.44      0.91      0.59       100\n",
      "          50       0.67      0.02      0.04       100\n",
      "          51       0.68      0.80      0.73       100\n",
      "          52       0.00      0.00      0.00       100\n",
      "          53       0.87      0.88      0.88       100\n",
      "          54       0.70      0.81      0.75       100\n",
      "          55       0.00      0.00      0.00       100\n",
      "          56       0.82      0.75      0.79       100\n",
      "          57       0.92      0.55      0.69       100\n",
      "          58       1.00      0.01      0.02       100\n",
      "          59       0.00      0.00      0.00       100\n",
      "          60       0.00      0.00      0.00       100\n",
      "          61       0.00      0.00      0.00       100\n",
      "          62       0.55      0.81      0.66       100\n",
      "          63       0.00      0.00      0.00       100\n",
      "          64       0.00      0.00      0.00       100\n",
      "          65       0.00      0.00      0.00       100\n",
      "          66       0.00      0.00      0.00       100\n",
      "          67       0.00      0.00      0.00       100\n",
      "          68       0.43      0.12      0.19       100\n",
      "          69       0.67      0.68      0.68       100\n",
      "          70       0.00      0.00      0.00       100\n",
      "          71       0.50      0.01      0.02       100\n",
      "          72       0.00      0.00      0.00       100\n",
      "          73       0.81      0.46      0.59       100\n",
      "          74       0.00      0.00      0.00       100\n",
      "          75       0.00      0.00      0.00       100\n",
      "          76       0.00      0.00      0.00       100\n",
      "          77       0.00      0.00      0.00       100\n",
      "          78       0.85      0.11      0.19       100\n",
      "          79       0.00      0.00      0.00       100\n",
      "          80       0.00      0.00      0.00       100\n",
      "          81       0.00      0.00      0.00       100\n",
      "          82       0.72      0.92      0.81       100\n",
      "          83       0.82      0.51      0.63       100\n",
      "          84       0.74      0.51      0.60       100\n",
      "          85       0.42      0.52      0.46       100\n",
      "          86       0.80      0.59      0.68       100\n",
      "          87       0.50      0.01      0.02       100\n",
      "          88       0.00      0.00      0.00       100\n",
      "          89       0.50      0.30      0.37       100\n",
      "          90       0.00      0.00      0.00       100\n",
      "          91       0.89      0.40      0.55       100\n",
      "          92       0.30      0.52      0.38       100\n",
      "          93       0.49      0.50      0.49       100\n",
      "          94       0.88      0.42      0.57       100\n",
      "          95       0.59      0.48      0.53       100\n",
      "          96       0.00      0.00      0.00       100\n",
      "          97       0.72      0.38      0.50       100\n",
      "          98       0.00      0.00      0.00       100\n",
      "          99       0.48      0.51      0.49       100\n",
      "\n",
      "    accuracy                           0.30     10000\n",
      "   macro avg       0.38      0.30      0.30     10000\n",
      "weighted avg       0.38      0.30      0.30     10000\n",
      "\n",
      "0.3\n",
      "took 4657.468722581863\n",
      "\n",
      "4\n",
      "(5000, 2048) (5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.92      0.78       100\n",
      "           1       0.68      0.74      0.71       100\n",
      "           2       0.62      0.56      0.59       100\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.00      0.00      0.00       100\n",
      "           5       0.54      0.51      0.53       100\n",
      "           6       0.77      0.58      0.66       100\n",
      "           7       1.00      0.01      0.02       100\n",
      "           8       0.67      0.64      0.65       100\n",
      "           9       0.00      0.00      0.00       100\n",
      "          10       0.00      0.00      0.00       100\n",
      "          11       0.50      0.01      0.02       100\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13       0.55      0.38      0.45       100\n",
      "          14       0.00      0.00      0.00       100\n",
      "          15       0.00      0.00      0.00       100\n",
      "          16       0.00      0.00      0.00       100\n",
      "          17       0.00      0.00      0.00       100\n",
      "          18       0.00      0.00      0.00       100\n",
      "          19       0.69      0.75      0.72       100\n",
      "          20       0.74      0.89      0.81       100\n",
      "          21       0.97      0.62      0.76       100\n",
      "          22       0.85      0.82      0.83       100\n",
      "          23       1.00      0.05      0.10       100\n",
      "          24       0.85      0.76      0.80       100\n",
      "          25       0.74      0.37      0.49       100\n",
      "          26       0.00      0.00      0.00       100\n",
      "          27       0.00      0.00      0.00       100\n",
      "          28       0.67      0.04      0.08       100\n",
      "          29       0.00      0.00      0.00       100\n",
      "          30       0.55      0.60      0.57       100\n",
      "          31       0.90      0.43      0.58       100\n",
      "          32       0.00      0.00      0.00       100\n",
      "          33       0.12      0.01      0.02       100\n",
      "          34       0.00      0.00      0.00       100\n",
      "          35       0.77      0.24      0.37       100\n",
      "          36       0.00      0.00      0.00       100\n",
      "          37       0.00      0.00      0.00       100\n",
      "          38       0.84      0.36      0.50       100\n",
      "          39       0.66      0.75      0.70       100\n",
      "          40       0.00      0.00      0.00       100\n",
      "          41       0.81      0.60      0.69       100\n",
      "          42       0.00      0.00      0.00       100\n",
      "          43       0.00      0.00      0.00       100\n",
      "          44       0.00      0.00      0.00       100\n",
      "          45       0.00      0.00      0.00       100\n",
      "          46       0.00      0.00      0.00       100\n",
      "          47       0.00      0.00      0.00       100\n",
      "          48       0.70      0.82      0.76       100\n",
      "          49       0.55      0.82      0.66       100\n",
      "          50       0.00      0.00      0.00       100\n",
      "          51       0.75      0.80      0.78       100\n",
      "          52       0.00      0.00      0.00       100\n",
      "          53       0.74      0.88      0.80       100\n",
      "          54       0.67      0.82      0.74       100\n",
      "          55       0.33      0.01      0.02       100\n",
      "          56       0.72      0.79      0.75       100\n",
      "          57       0.89      0.33      0.48       100\n",
      "          58       0.50      0.70      0.58       100\n",
      "          59       0.20      0.01      0.02       100\n",
      "          60       0.00      0.00      0.00       100\n",
      "          61       0.00      0.00      0.00       100\n",
      "          62       0.51      0.82      0.63       100\n",
      "          63       0.00      0.00      0.00       100\n",
      "          64       0.00      0.00      0.00       100\n",
      "          65       0.00      0.00      0.00       100\n",
      "          66       0.00      0.00      0.00       100\n",
      "          67       0.00      0.00      0.00       100\n",
      "          68       0.00      0.00      0.00       100\n",
      "          69       0.73      0.68      0.70       100\n",
      "          70       0.54      0.65      0.59       100\n",
      "          71       0.00      0.00      0.00       100\n",
      "          72       0.00      0.00      0.00       100\n",
      "          73       0.49      0.52      0.50       100\n",
      "          74       0.00      0.00      0.00       100\n",
      "          75       0.00      0.00      0.00       100\n",
      "          76       0.00      0.00      0.00       100\n",
      "          77       0.00      0.00      0.00       100\n",
      "          78       0.66      0.60      0.63       100\n",
      "          79       0.00      0.00      0.00       100\n",
      "          80       0.00      0.00      0.00       100\n",
      "          81       0.00      0.00      0.00       100\n",
      "          82       0.84      0.87      0.85       100\n",
      "          83       0.39      0.43      0.41       100\n",
      "          84       0.00      0.00      0.00       100\n",
      "          85       0.57      0.51      0.54       100\n",
      "          86       0.68      0.78      0.73       100\n",
      "          87       0.46      0.57      0.51       100\n",
      "          88       0.00      0.00      0.00       100\n",
      "          89       1.00      0.01      0.02       100\n",
      "          90       0.00      0.00      0.00       100\n",
      "          91       0.77      0.56      0.65       100\n",
      "          92       0.00      0.00      0.00       100\n",
      "          93       0.48      0.52      0.50       100\n",
      "          94       0.00      0.00      0.00       100\n",
      "          95       0.58      0.55      0.56       100\n",
      "          96       0.02      0.93      0.03       100\n",
      "          97       0.00      0.00      0.00       100\n",
      "          98       0.00      0.00      0.00       100\n",
      "          99       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.27     10000\n",
      "   macro avg       0.32      0.27      0.26     10000\n",
      "weighted avg       0.32      0.27      0.26     10000\n",
      "\n",
      "0.2662\n",
      "took 4803.7950184345245\n",
      "\n",
      "5\n",
      "(5000, 2048) (5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84       100\n",
      "           1       0.83      0.10      0.18       100\n",
      "           2       0.57      0.59      0.58       100\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.00      0.00      0.00       100\n",
      "           5       0.55      0.57      0.56       100\n",
      "           6       0.60      0.75      0.67       100\n",
      "           7       0.00      0.00      0.00       100\n",
      "           8       0.58      0.66      0.62       100\n",
      "           9       0.00      0.00      0.00       100\n",
      "          10       0.00      0.00      0.00       100\n",
      "          11       0.69      0.24      0.36       100\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13       0.50      0.57      0.54       100\n",
      "          14       0.00      0.00      0.00       100\n",
      "          15       0.00      0.00      0.00       100\n",
      "          16       0.00      0.00      0.00       100\n",
      "          17       0.00      0.00      0.00       100\n",
      "          18       0.00      0.00      0.00       100\n",
      "          19       0.73      0.74      0.74       100\n",
      "          20       0.74      0.89      0.81       100\n",
      "          21       0.65      0.82      0.73       100\n",
      "          22       0.00      0.00      0.00       100\n",
      "          23       0.00      0.00      0.00       100\n",
      "          24       0.00      0.00      0.00       100\n",
      "          25       0.37      0.54      0.44       100\n",
      "          26       0.00      0.00      0.00       100\n",
      "          27       0.00      0.00      0.00       100\n",
      "          28       0.54      0.53      0.54       100\n",
      "          29       0.00      0.00      0.00       100\n",
      "          30       0.51      0.61      0.56       100\n",
      "          31       1.00      0.01      0.02       100\n",
      "          32       0.00      0.00      0.00       100\n",
      "          33       0.00      0.00      0.00       100\n",
      "          34       0.68      0.58      0.63       100\n",
      "          35       0.41      0.53      0.46       100\n",
      "          36       0.84      0.16      0.27       100\n",
      "          37       0.00      0.00      0.00       100\n",
      "          38       0.00      0.00      0.00       100\n",
      "          39       0.00      0.00      0.00       100\n",
      "          40       1.00      0.02      0.04       100\n",
      "          41       0.81      0.70      0.75       100\n",
      "          42       0.00      0.00      0.00       100\n",
      "          43       0.00      0.00      0.00       100\n",
      "          44       0.00      0.00      0.00       100\n",
      "          45       0.00      0.00      0.00       100\n",
      "          46       0.00      0.00      0.00       100\n",
      "          47       0.00      0.00      0.00       100\n",
      "          48       0.85      0.79      0.82       100\n",
      "          49       0.60      0.68      0.64       100\n",
      "          50       0.00      0.00      0.00       100\n",
      "          51       0.80      0.76      0.78       100\n",
      "          52       0.00      0.00      0.00       100\n",
      "          53       0.58      0.92      0.71       100\n",
      "          54       0.73      0.79      0.76       100\n",
      "          55       0.00      0.00      0.00       100\n",
      "          56       0.72      0.81      0.76       100\n",
      "          57       0.65      0.53      0.59       100\n",
      "          58       0.75      0.50      0.60       100\n",
      "          59       0.00      0.00      0.00       100\n",
      "          60       0.00      0.00      0.00       100\n",
      "          61       0.00      0.00      0.00       100\n",
      "          62       0.61      0.82      0.70       100\n",
      "          63       0.00      0.00      0.00       100\n",
      "          64       0.00      0.00      0.00       100\n",
      "          65       0.00      0.00      0.00       100\n",
      "          66       0.00      0.00      0.00       100\n",
      "          67       0.00      0.00      0.00       100\n",
      "          68       0.00      0.00      0.00       100\n",
      "          69       0.00      0.00      0.00       100\n",
      "          70       0.47      0.76      0.58       100\n",
      "          71       0.00      0.00      0.00       100\n",
      "          72       0.00      0.00      0.00       100\n",
      "          73       0.46      0.56      0.50       100\n",
      "          74       0.00      0.00      0.00       100\n",
      "          75       0.00      0.00      0.00       100\n",
      "          76       0.00      0.00      0.00       100\n",
      "          77       0.00      0.00      0.00       100\n",
      "          78       1.00      0.01      0.02       100\n",
      "          79       0.00      0.00      0.00       100\n",
      "          80       0.00      0.00      0.00       100\n",
      "          81       0.00      0.00      0.00       100\n",
      "          82       0.84      0.86      0.85       100\n",
      "          83       1.00      0.02      0.04       100\n",
      "          84       0.51      0.57      0.54       100\n",
      "          85       0.00      0.00      0.00       100\n",
      "          86       0.59      0.66      0.62       100\n",
      "          87       0.11      0.16      0.13       100\n",
      "          88       0.00      0.00      0.00       100\n",
      "          89       0.01      0.88      0.03       100\n",
      "          90       0.00      0.00      0.00       100\n",
      "          91       0.00      0.00      0.00       100\n",
      "          92       0.21      0.42      0.28       100\n",
      "          93       0.29      0.02      0.04       100\n",
      "          94       0.81      0.44      0.57       100\n",
      "          95       0.52      0.51      0.52       100\n",
      "          96       0.00      0.00      0.00       100\n",
      "          97       1.00      0.14      0.25       100\n",
      "          98       0.00      0.00      0.00       100\n",
      "          99       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.23     10000\n",
      "   macro avg       0.28      0.23      0.22     10000\n",
      "weighted avg       0.28      0.23      0.22     10000\n",
      "\n",
      "0.2303\n",
      "took 4489.648636102676\n",
      "\n",
      "6\n",
      "(5000, 2048) (5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       100\n",
      "           1       0.70      0.71      0.70       100\n",
      "           2       0.56      0.42      0.48       100\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.00      0.00      0.00       100\n",
      "           5       0.65      0.52      0.58       100\n",
      "           6       0.66      0.59      0.62       100\n",
      "           7       0.25      0.02      0.04       100\n",
      "           8       0.90      0.64      0.75       100\n",
      "           9       0.00      0.00      0.00       100\n",
      "          10       0.00      0.00      0.00       100\n",
      "          11       0.68      0.27      0.39       100\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13       0.54      0.48      0.51       100\n",
      "          14       0.00      0.00      0.00       100\n",
      "          15       0.00      0.00      0.00       100\n",
      "          16       0.00      0.00      0.00       100\n",
      "          17       0.00      0.00      0.00       100\n",
      "          18       0.00      0.00      0.00       100\n",
      "          19       0.84      0.67      0.74       100\n",
      "          20       0.76      0.90      0.82       100\n",
      "          21       0.76      0.74      0.75       100\n",
      "          22       0.92      0.59      0.72       100\n",
      "          23       0.00      0.00      0.00       100\n",
      "          24       0.87      0.75      0.81       100\n",
      "          25       0.00      0.00      0.00       100\n",
      "          26       0.00      0.00      0.00       100\n",
      "          27       0.00      0.00      0.00       100\n",
      "          28       0.00      0.00      0.00       100\n",
      "          29       0.00      0.00      0.00       100\n",
      "          30       0.47      0.64      0.54       100\n",
      "          31       0.00      0.00      0.00       100\n",
      "          32       0.60      0.06      0.11       100\n",
      "          33       0.00      0.00      0.00       100\n",
      "          34       0.87      0.55      0.67       100\n",
      "          35       0.46      0.37      0.41       100\n",
      "          36       0.00      0.00      0.00       100\n",
      "          37       0.00      0.00      0.00       100\n",
      "          38       0.00      0.00      0.00       100\n",
      "          39       0.88      0.58      0.70       100\n",
      "          40       0.75      0.03      0.06       100\n",
      "          41       0.62      0.67      0.64       100\n",
      "          42       0.00      0.00      0.00       100\n",
      "          43       0.00      0.00      0.00       100\n",
      "          44       0.00      0.00      0.00       100\n",
      "          45       0.00      0.00      0.00       100\n",
      "          46       0.00      0.00      0.00       100\n",
      "          47       0.00      0.00      0.00       100\n",
      "          48       0.89      0.74      0.81       100\n",
      "          49       0.00      0.00      0.00       100\n",
      "          50       0.00      0.00      0.00       100\n",
      "          51       0.81      0.76      0.78       100\n",
      "          52       0.00      0.00      0.00       100\n",
      "          53       0.79      0.89      0.84       100\n",
      "          54       0.70      0.80      0.75       100\n",
      "          55       0.00      0.00      0.00       100\n",
      "          56       0.74      0.79      0.76       100\n",
      "          57       0.48      0.69      0.57       100\n",
      "          58       0.68      0.60      0.64       100\n",
      "          59       0.00      0.00      0.00       100\n",
      "          60       0.00      0.00      0.00       100\n",
      "          61       0.00      0.00      0.00       100\n",
      "          62       0.65      0.77      0.70       100\n",
      "          63       0.00      0.00      0.00       100\n",
      "          64       0.00      0.00      0.00       100\n",
      "          65       0.02      0.93      0.03       100\n",
      "          66       0.00      0.00      0.00       100\n",
      "          67       0.80      0.04      0.08       100\n",
      "          68       0.00      0.00      0.00       100\n",
      "          69       0.51      0.74      0.60       100\n",
      "          70       0.00      0.00      0.00       100\n",
      "          71       0.00      0.00      0.00       100\n",
      "          72       0.00      0.00      0.00       100\n",
      "          73       0.52      0.60      0.56       100\n",
      "          74       0.00      0.00      0.00       100\n",
      "          75       0.00      0.00      0.00       100\n",
      "          76       0.00      0.00      0.00       100\n",
      "          77       0.00      0.00      0.00       100\n",
      "          78       0.71      0.64      0.67       100\n",
      "          79       0.00      0.00      0.00       100\n",
      "          80       0.00      0.00      0.00       100\n",
      "          81       0.40      0.02      0.04       100\n",
      "          82       0.79      0.85      0.82       100\n",
      "          83       0.86      0.44      0.58       100\n",
      "          84       0.26      0.71      0.38       100\n",
      "          85       0.66      0.45      0.54       100\n",
      "          86       0.67      0.77      0.72       100\n",
      "          87       0.53      0.41      0.46       100\n",
      "          88       0.00      0.00      0.00       100\n",
      "          89       0.50      0.02      0.04       100\n",
      "          90       0.00      0.00      0.00       100\n",
      "          91       0.80      0.59      0.68       100\n",
      "          92       0.00      0.00      0.00       100\n",
      "          93       0.71      0.10      0.18       100\n",
      "          94       0.50      0.58      0.53       100\n",
      "          95       0.56      0.58      0.57       100\n",
      "          96       0.00      0.00      0.00       100\n",
      "          97       0.82      0.18      0.30       100\n",
      "          98       0.00      0.00      0.00       100\n",
      "          99       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.26     10000\n",
      "   macro avg       0.31      0.26      0.25     10000\n",
      "weighted avg       0.31      0.26      0.25     10000\n",
      "\n",
      "0.2575\n",
      "took 4492.654950618744\n",
      "\n",
      "7\n",
      "(5000, 2048) (5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78       100\n",
      "           1       0.93      0.63      0.75       100\n",
      "           2       0.49      0.68      0.57       100\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.00      0.00      0.00       100\n",
      "           5       0.71      0.40      0.51       100\n",
      "           6       0.75      0.56      0.64       100\n",
      "           7       0.50      0.58      0.54       100\n",
      "           8       0.79      0.66      0.72       100\n",
      "           9       0.00      0.00      0.00       100\n",
      "          10       0.00      0.00      0.00       100\n",
      "          11       0.75      0.03      0.06       100\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13       0.54      0.63      0.58       100\n",
      "          14       0.00      0.00      0.00       100\n",
      "          15       0.00      0.00      0.00       100\n",
      "          16       0.00      0.00      0.00       100\n",
      "          17       0.00      0.00      0.00       100\n",
      "          18       0.00      0.00      0.00       100\n",
      "          19       0.71      0.75      0.73       100\n",
      "          20       0.77      0.84      0.80       100\n",
      "          21       0.82      0.70      0.76       100\n",
      "          22       0.85      0.72      0.78       100\n",
      "          23       0.46      0.06      0.11       100\n",
      "          24       0.86      0.76      0.81       100\n",
      "          25       0.70      0.49      0.58       100\n",
      "          26       0.00      0.00      0.00       100\n",
      "          27       0.00      0.00      0.00       100\n",
      "          28       0.00      0.00      0.00       100\n",
      "          29       0.00      0.00      0.00       100\n",
      "          30       0.65      0.50      0.56       100\n",
      "          31       0.86      0.56      0.68       100\n",
      "          32       0.00      0.00      0.00       100\n",
      "          33       0.00      0.00      0.00       100\n",
      "          34       0.69      0.59      0.63       100\n",
      "          35       0.34      0.44      0.38       100\n",
      "          36       0.87      0.26      0.40       100\n",
      "          37       0.00      0.00      0.00       100\n",
      "          38       0.00      0.00      0.00       100\n",
      "          39       0.83      0.71      0.76       100\n",
      "          40       0.00      0.00      0.00       100\n",
      "          41       0.69      0.72      0.70       100\n",
      "          42       0.00      0.00      0.00       100\n",
      "          43       0.00      0.00      0.00       100\n",
      "          44       0.00      0.00      0.00       100\n",
      "          45       0.00      0.00      0.00       100\n",
      "          46       0.00      0.00      0.00       100\n",
      "          47       0.00      0.00      0.00       100\n",
      "          48       0.87      0.78      0.82       100\n",
      "          49       0.42      0.89      0.57       100\n",
      "          50       0.00      0.00      0.00       100\n",
      "          51       0.68      0.80      0.73       100\n",
      "          52       0.30      0.80      0.43       100\n",
      "          53       0.87      0.81      0.84       100\n",
      "          54       0.74      0.77      0.75       100\n",
      "          55       0.00      0.00      0.00       100\n",
      "          56       0.71      0.81      0.76       100\n",
      "          57       0.81      0.38      0.52       100\n",
      "          58       0.82      0.64      0.72       100\n",
      "          59       0.25      0.02      0.04       100\n",
      "          60       0.00      0.00      0.00       100\n",
      "          61       0.00      0.00      0.00       100\n",
      "          62       0.58      0.80      0.67       100\n",
      "          63       1.00      0.08      0.15       100\n",
      "          64       0.00      0.00      0.00       100\n",
      "          65       0.00      0.00      0.00       100\n",
      "          66       0.00      0.00      0.00       100\n",
      "          67       0.38      0.40      0.39       100\n",
      "          68       0.69      0.11      0.19       100\n",
      "          69       0.63      0.71      0.67       100\n",
      "          70       1.00      0.03      0.06       100\n",
      "          71       0.48      0.15      0.23       100\n",
      "          72       0.37      0.26      0.31       100\n",
      "          73       0.44      0.74      0.55       100\n",
      "          74       0.00      0.00      0.00       100\n",
      "          75       0.00      0.00      0.00       100\n",
      "          76       0.00      0.00      0.00       100\n",
      "          77       0.00      0.00      0.00       100\n",
      "          78       0.60      0.66      0.63       100\n",
      "          79       0.01      0.69      0.03       100\n",
      "          80       0.00      0.00      0.00       100\n",
      "          81       0.00      0.00      0.00       100\n",
      "          82       0.75      0.92      0.83       100\n",
      "          83       0.50      0.34      0.40       100\n",
      "          84       0.00      0.00      0.00       100\n",
      "          85       0.33      0.01      0.02       100\n",
      "          86       0.61      0.70      0.65       100\n",
      "          87       0.00      0.00      0.00       100\n",
      "          88       0.00      0.00      0.00       100\n",
      "          89       0.50      0.17      0.25       100\n",
      "          90       0.00      0.00      0.00       100\n",
      "          91       0.44      0.71      0.55       100\n",
      "          92       0.81      0.52      0.63       100\n",
      "          93       0.88      0.23      0.37       100\n",
      "          94       0.88      0.43      0.58       100\n",
      "          95       0.47      0.66      0.55       100\n",
      "          96       0.00      0.00      0.00       100\n",
      "          97       0.88      0.23      0.37       100\n",
      "          98       0.00      0.00      0.00       100\n",
      "          99       0.78      0.28      0.41       100\n",
      "\n",
      "    accuracy                           0.30     10000\n",
      "   macro avg       0.37      0.30      0.29     10000\n",
      "weighted avg       0.37      0.30      0.29     10000\n",
      "\n",
      "0.2968\n",
      "took 4328.22517824173\n",
      "\n",
      "8\n",
      "(5000, 2048) (5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       100\n",
      "           1       0.67      0.69      0.68       100\n",
      "           2       0.00      0.00      0.00       100\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.00      0.00      0.00       100\n",
      "           5       0.00      0.00      0.00       100\n",
      "           6       0.70      0.35      0.47       100\n",
      "           7       0.50      0.02      0.04       100\n",
      "           8       0.84      0.64      0.73       100\n",
      "           9       0.02      0.81      0.04       100\n",
      "          10       0.00      0.00      0.00       100\n",
      "          11       0.44      0.16      0.24       100\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13       0.60      0.55      0.57       100\n",
      "          14       0.00      0.00      0.00       100\n",
      "          15       0.00      0.00      0.00       100\n",
      "          16       0.00      0.00      0.00       100\n",
      "          17       0.43      0.03      0.06       100\n",
      "          18       0.00      0.00      0.00       100\n",
      "          19       0.73      0.75      0.74       100\n",
      "          20       0.76      0.91      0.83       100\n",
      "          21       0.81      0.70      0.75       100\n",
      "          22       0.72      0.85      0.78       100\n",
      "          23       0.65      0.34      0.45       100\n",
      "          24       0.84      0.76      0.80       100\n",
      "          25       0.83      0.05      0.09       100\n",
      "          26       0.00      0.00      0.00       100\n",
      "          27       0.00      0.00      0.00       100\n",
      "          28       0.00      0.00      0.00       100\n",
      "          29       1.00      0.01      0.02       100\n",
      "          30       0.62      0.57      0.59       100\n",
      "          31       0.00      0.00      0.00       100\n",
      "          32       0.50      0.02      0.04       100\n",
      "          33       0.63      0.19      0.29       100\n",
      "          34       0.81      0.66      0.73       100\n",
      "          35       0.00      0.00      0.00       100\n",
      "          36       0.67      0.58      0.62       100\n",
      "          37       0.00      0.00      0.00       100\n",
      "          38       0.00      0.00      0.00       100\n",
      "          39       0.80      0.72      0.76       100\n",
      "          40       0.00      0.00      0.00       100\n",
      "          41       0.90      0.57      0.70       100\n",
      "          42       0.00      0.00      0.00       100\n",
      "          43       0.00      0.00      0.00       100\n",
      "          44       0.20      0.02      0.04       100\n",
      "          45       0.00      0.00      0.00       100\n",
      "          46       0.62      0.21      0.31       100\n",
      "          47       0.29      0.42      0.34       100\n",
      "          48       0.77      0.79      0.78       100\n",
      "          49       0.56      0.79      0.66       100\n",
      "          50       0.50      0.11      0.18       100\n",
      "          51       0.77      0.79      0.78       100\n",
      "          52       0.32      0.80      0.46       100\n",
      "          53       0.75      0.89      0.81       100\n",
      "          54       0.72      0.82      0.77       100\n",
      "          55       0.00      0.00      0.00       100\n",
      "          56       0.78      0.75      0.77       100\n",
      "          57       0.93      0.53      0.68       100\n",
      "          58       0.59      0.80      0.68       100\n",
      "          59       0.67      0.02      0.04       100\n",
      "          60       0.00      0.00      0.00       100\n",
      "          61       0.00      0.00      0.00       100\n",
      "          62       0.55      0.81      0.65       100\n",
      "          63       0.00      0.00      0.00       100\n",
      "          64       0.00      0.00      0.00       100\n",
      "          65       0.00      0.00      0.00       100\n",
      "          66       0.00      0.00      0.00       100\n",
      "          67       0.29      0.02      0.04       100\n",
      "          68       0.78      0.07      0.13       100\n",
      "          69       0.00      0.00      0.00       100\n",
      "          70       0.78      0.54      0.64       100\n",
      "          71       0.00      0.00      0.00       100\n",
      "          72       0.00      0.00      0.00       100\n",
      "          73       0.41      0.65      0.51       100\n",
      "          74       0.00      0.00      0.00       100\n",
      "          75       0.00      0.00      0.00       100\n",
      "          76       0.00      0.00      0.00       100\n",
      "          77       0.00      0.00      0.00       100\n",
      "          78       0.44      0.72      0.54       100\n",
      "          79       0.00      0.00      0.00       100\n",
      "          80       0.54      0.26      0.35       100\n",
      "          81       0.07      0.74      0.13       100\n",
      "          82       0.80      0.88      0.84       100\n",
      "          83       0.53      0.63      0.58       100\n",
      "          84       0.00      0.00      0.00       100\n",
      "          85       0.60      0.52      0.56       100\n",
      "          86       0.82      0.60      0.69       100\n",
      "          87       1.00      0.14      0.25       100\n",
      "          88       0.00      0.00      0.00       100\n",
      "          89       0.00      0.00      0.00       100\n",
      "          90       0.20      0.01      0.02       100\n",
      "          91       0.75      0.60      0.67       100\n",
      "          92       0.25      0.50      0.34       100\n",
      "          93       0.40      0.02      0.04       100\n",
      "          94       0.00      0.00      0.00       100\n",
      "          95       0.56      0.60      0.58       100\n",
      "          96       0.00      0.00      0.00       100\n",
      "          97       0.49      0.53      0.51       100\n",
      "          98       0.28      0.79      0.41       100\n",
      "          99       0.64      0.42      0.51       100\n",
      "\n",
      "    accuracy                           0.30     10000\n",
      "   macro avg       0.36      0.30      0.28     10000\n",
      "weighted avg       0.36      0.30      0.28     10000\n",
      "\n",
      "0.2955\n",
      "took 4319.437481403351\n",
      "\n",
      "9\n",
      "(5000, 2048) (5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwya/screen_understanding/screen_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.78      0.45      0.57       100\n",
      "           3       0.08      0.01      0.02       100\n",
      "           4       0.00      0.00      0.00       100\n",
      "           5       0.57      0.55      0.56       100\n",
      "           6       0.77      0.61      0.68       100\n",
      "           7       0.66      0.43      0.52       100\n",
      "           8       0.85      0.63      0.72       100\n",
      "           9       0.02      0.93      0.03       100\n",
      "          10       0.00      0.00      0.00       100\n",
      "          11       0.37      0.61      0.46       100\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13       0.53      0.59      0.56       100\n",
      "          14       0.65      0.55      0.59       100\n",
      "          15       0.50      0.01      0.02       100\n",
      "          16       0.00      0.00      0.00       100\n",
      "          17       0.00      0.00      0.00       100\n",
      "          18       0.00      0.00      0.00       100\n",
      "          19       0.67      0.75      0.71       100\n",
      "          20       0.76      0.89      0.82       100\n",
      "          21       0.70      0.78      0.74       100\n",
      "          22       0.82      0.84      0.83       100\n",
      "          23       0.00      0.00      0.00       100\n",
      "          24       0.81      0.78      0.80       100\n",
      "          25       0.67      0.02      0.04       100\n",
      "          26       0.00      0.00      0.00       100\n",
      "          27       0.00      0.00      0.00       100\n",
      "          28       0.00      0.00      0.00       100\n",
      "          29       0.00      0.00      0.00       100\n",
      "          30       0.58      0.62      0.60       100\n",
      "          31       0.00      0.00      0.00       100\n",
      "          32       0.00      0.00      0.00       100\n",
      "          33       0.54      0.28      0.37       100\n",
      "          34       0.75      0.62      0.68       100\n",
      "          35       0.53      0.47      0.50       100\n",
      "          36       0.46      0.69      0.55       100\n",
      "          37       0.00      0.00      0.00       100\n",
      "          38       0.66      0.45      0.54       100\n",
      "          39       0.89      0.71      0.79       100\n",
      "          40       0.00      0.00      0.00       100\n",
      "          41       0.66      0.75      0.70       100\n",
      "          42       0.00      0.00      0.00       100\n",
      "          43       0.00      0.00      0.00       100\n",
      "          44       0.00      0.00      0.00       100\n",
      "          45       0.00      0.00      0.00       100\n",
      "          46       0.00      0.00      0.00       100\n",
      "          47       0.39      0.50      0.44       100\n",
      "          48       0.88      0.74      0.80       100\n",
      "          49       0.60      0.62      0.61       100\n",
      "          50       0.00      0.00      0.00       100\n",
      "          51       0.75      0.80      0.78       100\n",
      "          52       0.40      0.60      0.48       100\n",
      "          53       0.77      0.89      0.83       100\n",
      "          54       0.72      0.81      0.76       100\n",
      "          55       0.25      0.02      0.04       100\n",
      "          56       0.81      0.73      0.77       100\n",
      "          57       0.62      0.66      0.64       100\n",
      "          58       0.79      0.41      0.54       100\n",
      "          59       0.25      0.55      0.35       100\n",
      "          60       0.00      0.00      0.00       100\n",
      "          61       0.00      0.00      0.00       100\n",
      "          62       0.67      0.70      0.69       100\n",
      "          63       0.27      0.03      0.05       100\n",
      "          64       0.00      0.00      0.00       100\n",
      "          65       0.00      0.00      0.00       100\n",
      "          66       0.00      0.00      0.00       100\n",
      "          67       0.44      0.04      0.07       100\n",
      "          68       0.54      0.47      0.50       100\n",
      "          69       0.77      0.66      0.71       100\n",
      "          70       0.00      0.00      0.00       100\n",
      "          71       0.00      0.00      0.00       100\n",
      "          72       1.00      0.01      0.02       100\n",
      "          73       0.46      0.62      0.53       100\n",
      "          74       0.00      0.00      0.00       100\n",
      "          75       0.00      0.00      0.00       100\n",
      "          76       0.00      0.00      0.00       100\n",
      "          77       0.00      0.00      0.00       100\n",
      "          78       0.00      0.00      0.00       100\n",
      "          79       1.00      0.01      0.02       100\n",
      "          80       0.00      0.00      0.00       100\n",
      "          81       0.00      0.00      0.00       100\n",
      "          82       0.85      0.84      0.84       100\n",
      "          83       0.67      0.60      0.63       100\n",
      "          84       0.00      0.00      0.00       100\n",
      "          85       1.00      0.01      0.02       100\n",
      "          86       0.63      0.66      0.65       100\n",
      "          87       0.49      0.36      0.42       100\n",
      "          88       0.00      0.00      0.00       100\n",
      "          89       0.54      0.15      0.23       100\n",
      "          90       0.25      0.01      0.02       100\n",
      "          91       0.00      0.00      0.00       100\n",
      "          92       1.00      0.01      0.02       100\n",
      "          93       0.00      0.00      0.00       100\n",
      "          94       0.50      0.01      0.02       100\n",
      "          95       0.60      0.59      0.60       100\n",
      "          96       0.00      0.00      0.00       100\n",
      "          97       0.69      0.43      0.53       100\n",
      "          98       0.00      0.00      0.00       100\n",
      "          99       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.28     10000\n",
      "   macro avg       0.36      0.28      0.28     10000\n",
      "weighted avg       0.36      0.28      0.28     10000\n",
      "\n",
      "0.2842\n",
      "took 4302.877927303314\n",
      "\n",
      "0.27086\n"
     ]
    }
   ],
   "source": [
    "master_seed = 42\n",
    "np.random.seed(master_seed)\n",
    "n_iter = 10\n",
    "seeds = np.random.randint(10000, size=n_iter)\n",
    "flat_clf = []\n",
    "n_trees = 300\n",
    "max_depth = 15\n",
    "accuracies = []\n",
    "for i in range(n_iter):\n",
    "    start = time.time()\n",
    "    seed =  seeds[i]\n",
    "    print(i)\n",
    "    X_train, _,  Y_train, _  = train_test_split(X, Y, test_size=0.90, random_state=seed)\n",
    "    print(X_train.shape, Y_train.shape)    \n",
    "    clf = UncertaintyForest(n_estimators = n_trees, max_depth=max_depth)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    flat_clf.append(clf)\n",
    "    pp = clf.predict(X_test_org)\n",
    "    print(classification_report(Y_test_org, pp))\n",
    "    accuracies.append(accuracy_score(Y_test_org, pp))\n",
    "    print(accuracies[-1])\n",
    "    print('took %s' %(time.time() - start))\n",
    "    print()\n",
    "\n",
    "with open('/home/weiwya/cirar_flat_10_20_run.p', 'wb') as handle:\n",
    "    pickle.dump((flat_clf, accuracies), handle)\n",
    "\n",
    "print(np.average(accuracies))\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat: average 0.27086, sdt_err:0.006749165874387737 \n"
     ]
    }
   ],
   "source": [
    "print(\"flat: average %s, sdt_err:%s \" %(np.average(accuracies), np.std(accuracies)/np.sqrt(n_iter) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
