{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook establishes baseline auc for CheXpert -to cheXphoto transfer rate\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acorn = 1234\n",
    "torch.manual_seed(acorn)\n",
    "np.random.seed(acorn)\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "    \n",
    "device = torch.device(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_files = 'CheXphoto-v1.0/train/natural/iphone/patient01595/study8/view1_frontal.jpg'\n",
    "\n",
    "#process data, filter out only frontal, ap, fillter out uncertainty in classes we care and fill in rest data\n",
    "def process_data(df):\n",
    "    \n",
    "    print('starting size %s' %len(df))\n",
    "    data = df\n",
    "    #only use frontal/AP data\n",
    "    data = data.loc[data['Frontal/Lateral'] == 'Frontal']\n",
    "    data = data.loc[data['AP/PA'] == 'AP']\n",
    "\n",
    "    \n",
    "    category_names = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "    \n",
    "    #filter out all uncertainty labels in classes we care about\n",
    "    data = data[category_names]\n",
    "    #tread all empty values in these selected cols as 0\n",
    "    data = data.fillna(0)\n",
    "    #filter out -1 (uncertain labels)\n",
    "    data = data.loc[(data.iloc[:, :] !=-1).all(axis=1)]\n",
    "    #row-idx of the data we care to keep\n",
    "    fly_list = data.index\n",
    "    #reselect from orginal of kept rows\n",
    "    data = df.iloc[fly_list]\n",
    "\n",
    "    #select the cols we care about\n",
    "    wanted_cols = [\"Path\", 'No Finding'] + category_names\n",
    "    data = data[wanted_cols]\n",
    "    \n",
    "    #filter out rows with no label values\n",
    "    data['sum']  = data.iloc[:, 1:].sum(axis=1)\n",
    "    fly_list = data.loc[data['sum']>0].index\n",
    "    data = df[wanted_cols].iloc[fly_list]\n",
    "    \n",
    "    print(len(data))\n",
    "    #filer out bad_files\n",
    "    fly_list = data.loc[data['Path'] != bad_files].index\n",
    "    data = df[wanted_cols].iloc[fly_list]\n",
    "    \n",
    "    \n",
    "    # fill all NA and uncertainty as 0     \n",
    "    data = data.fillna(0)\n",
    "    data = data.replace(-1,0)\n",
    "\n",
    "    print(\"final size %s\" %len(data))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting size 32521\n",
      "13734\n",
      "final size 13733\n",
      "starting size 702\n",
      "396\n",
      "final size 396\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXphoto-v1.0/valid/synthetic/digital/patient...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CheXphoto-v1.0/valid/synthetic/digital/patient...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheXphoto-v1.0/valid/synthetic/digital/patient...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CheXphoto-v1.0/valid/synthetic/digital/patient...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CheXphoto-v1.0/valid/synthetic/digital/patient...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  No Finding  Atelectasis  \\\n",
       "0  CheXphoto-v1.0/valid/synthetic/digital/patient...         0.0          0.0   \n",
       "3  CheXphoto-v1.0/valid/synthetic/digital/patient...         0.0          0.0   \n",
       "4  CheXphoto-v1.0/valid/synthetic/digital/patient...         1.0          0.0   \n",
       "5  CheXphoto-v1.0/valid/synthetic/digital/patient...         0.0          1.0   \n",
       "6  CheXphoto-v1.0/valid/synthetic/digital/patient...         0.0          1.0   \n",
       "\n",
       "   Cardiomegaly  Consolidation  Edema  Pleural Effusion  \n",
       "0           1.0            0.0    0.0               0.0  \n",
       "3           0.0            0.0    1.0               0.0  \n",
       "4           0.0            0.0    0.0               0.0  \n",
       "5           0.0            0.0    0.0               1.0  \n",
       "6           1.0            0.0    0.0               0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = '/home/data/CheXphoto/'\n",
    "train_df = pd.read_csv('%s/CheXphoto-v1.0/train.csv'%data_root)\n",
    "test_df = pd.read_csv('%s/CheXphoto-v1.0/valid.csv' %data_root)\n",
    "\n",
    "train_df = process_data(train_df)\n",
    "test_df = process_data(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform, data_root):\n",
    "        #TODO::put something here that perserves aspect ratio\n",
    "        self.class_names = ['No Finding', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "        self.image_dir = data_root\n",
    "        self.transform = transform\n",
    "        self.total = len(df)\n",
    "        self.image_names = df['Path'].to_list()\n",
    "        self.labels = df[self.class_names].to_numpy()\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image_name = self.image_names[idx]\n",
    "            image_path = os.path.join(self.image_dir, image_name)\n",
    "            image = self.transform(Image.open(image_path).convert('RGB'))\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n",
    "        except:\n",
    "            print (self.image_names[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (320, 320)\n",
    "resnet_mean = [0.485, 0.456, 0.406]\n",
    "resnet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "#Creating a Transformation Object\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    torchvision.transforms.Resize(size=image_size),\n",
    "    torchvision.transforms.RandomHorizontalFlip(), #A RandomHorizontalFlip to augment our data\n",
    "    torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "    #Normalizing the data to the data that the ResNet18 was trained on\n",
    "    torchvision.transforms.Normalize(mean = resnet_mean ,\n",
    "                                    std = resnet_std) \n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "#Creating a Transformation Object\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    torchvision.transforms.Resize(size=image_size),\n",
    "    # We don't do data augmentation in the test/val set    \n",
    "    torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "    torchvision.transforms.Normalize(mean = resnet_mean,\n",
    "                                    std = resnet_std) \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smaples: 13733, batches: 859,  classes: 6\n",
      "smaples: 396, batches: 25,  classes: 6\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ChestXRayDataset(train_df, train_transform, data_root)\n",
    "test_dataset = ChestXRayDataset(test_df, test_transform, data_root)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print('smaples: %s, batches: %s,  classes: %s' %( len(train_dataset), len(dl_train), len(train_dataset.class_names) ))\n",
    "print('smaples: %s, batches: %s,  classes: %s' %( len(test_dataset), len(dl_test), len(test_dataset.class_names) ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnext50(torch.nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        resnet.fc = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(in_features=resnet.fc.in_features, out_features=n_classes)\n",
    "        )\n",
    "        self.base_model = resnet\n",
    "        self.sigm = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigm(self.base_model(x))\n",
    "\n",
    "# Initialize the model\n",
    "chexpert_model = Resnext50(6)\n",
    "optimizer = torch.optim.Adam(chexpert_model.parameters(), lr=5e-5)\n",
    "\n",
    "checkpt = torch.load('CheXpert_0_resnet50')\n",
    "chexpert_model.load_state_dict(checkpt['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpt['optimizer_state_dict'])\n",
    "\n",
    "chexpert_model.to(device)\n",
    "loss_fn = torch.nn.BCELoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model (model, dl, verbose=True):\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    total_loss = 0\n",
    "    class_lookup = dl.dataset.class_names\n",
    "    n_class = len(class_lookup)\n",
    "\n",
    "    for val_step, (images, labels) in enumerate(dl):\n",
    "\n",
    "        imagesGPU, labelsGPU = images.to(device), labels.to(device)        \n",
    "        outputs = model(imagesGPU)\n",
    "        loss = loss_fn(outputs, labelsGPU.type(torch.float))       \n",
    "        total_loss += loss.item()               \n",
    "        outputs = torch.Tensor.cpu(outputs)\n",
    "        predicts.append(outputs.detach().numpy())\n",
    "        targets.append(labels)\n",
    "\n",
    "    predicts = np.vstack(predicts)\n",
    "    targets = np.vstack(targets)\n",
    "    loss = total_loss/len(dl)\n",
    "    \n",
    "    res = {}\n",
    "    total_auc = 0\n",
    "    total_counts = 0\n",
    "    for idx in range(n_class):\n",
    "        truth  = targets[:, idx]\n",
    "        pp = predicts[:,idx]\n",
    "        fpr, tpr, thresholds = roc_curve(truth, pp)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        res[class_lookup[idx]] = auc_score\n",
    "        counts = np.sum(truth)\n",
    "        #A hack to skip no-funding in auc caclualtion\n",
    "        if idx != 0 :\n",
    "            total_auc += auc_score * counts\n",
    "            total_counts += counts\n",
    "    avg_auc = total_auc / total_counts\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        for k, v in res.items():\n",
    "            print(k, v)\n",
    "        print()\n",
    "        print('loss:%s, avg_auc:%s' %(loss, avg_auc))\n",
    "        \n",
    "    return avg_auc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No Finding 0.942283950617284\n",
      "Atelectasis 0.7592549834526283\n",
      "Cardiomegaly 0.7602245184334736\n",
      "Consolidation 0.8103819444444444\n",
      "Edema 0.8681020876142826\n",
      "Pleural Effusion 0.8776007593832578\n",
      "\n",
      "loss:0.6042515885829925, avg_auc:0.8088138950374034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8088138950374034, 0.6042515885829925)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(chexpert_model, dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No Finding 0.8696857470404071\n",
      "Atelectasis 0.6367356250139212\n",
      "Cardiomegaly 0.8134791446105784\n",
      "Consolidation 0.6859232952856652\n",
      "Edema 0.7662576161983433\n",
      "Pleural Effusion 0.8477130800962663\n",
      "\n",
      "loss:0.40971196079420685, avg_auc:0.7779290823063768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7779290823063768, 0.40971196079420685)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(chexpert_model, dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXphoto-v1.0/train/synthetic/digital/patient...</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXphoto-v1.0/train/synthetic/digital/patient...</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CheXphoto-v1.0/train/synthetic/digital/patient...</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CheXphoto-v1.0/train/synthetic/digital/patient...</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheXphoto-v1.0/train/synthetic/digital/patient...</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path     Sex  Age  \\\n",
       "0  CheXphoto-v1.0/train/synthetic/digital/patient...  Female   20   \n",
       "1  CheXphoto-v1.0/train/synthetic/digital/patient...  Female   20   \n",
       "2  CheXphoto-v1.0/train/synthetic/digital/patient...  Female   46   \n",
       "3  CheXphoto-v1.0/train/synthetic/digital/patient...  Female   46   \n",
       "4  CheXphoto-v1.0/train/synthetic/digital/patient...  Female   50   \n",
       "\n",
       "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
       "0         Frontal    PA         1.0                         0.0           NaN   \n",
       "1         Lateral   NaN         1.0                         0.0           NaN   \n",
       "2         Frontal    PA         NaN                         NaN           NaN   \n",
       "3         Lateral   NaN         NaN                         NaN           NaN   \n",
       "4         Frontal    AP         NaN                         NaN           1.0   \n",
       "\n",
       "   Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
       "0           NaN          NaN    NaN            0.0        NaN          NaN   \n",
       "1           NaN          NaN    NaN            0.0        NaN          NaN   \n",
       "2           NaN          1.0    NaN            NaN        NaN          NaN   \n",
       "3           NaN          1.0    NaN            NaN        NaN          NaN   \n",
       "4           1.0          1.0    NaN            NaN        NaN          1.0   \n",
       "\n",
       "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \n",
       "0           NaN               0.0            NaN       NaN              NaN  \n",
       "1           NaN               0.0            NaN       NaN              NaN  \n",
       "2           0.0               NaN            NaN       NaN              NaN  \n",
       "3           0.0               NaN            NaN       NaN              NaN  \n",
       "4           1.0               1.0            NaN       NaN              0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv('%s/CheXphoto-v1.0/train.csv'%data_root)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
