{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook establishes baseline auc for CheXpert, using Resnet18 as backbone and 100%% train data\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acorn = 1234\n",
    "torch.manual_seed(acorn)\n",
    "np.random.seed(acorn)\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "    \n",
    "device = torch.device(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process data, filter out only frontal, ap, fillter out uncertainty in classes we care and fill in rest data\n",
    "def process_data(df):\n",
    "    \n",
    "    print('starting size %s' %len(df))\n",
    "    data = df\n",
    "    #only use frontal/AP data\n",
    "    data = data.loc[data['Frontal/Lateral'] == 'Frontal']\n",
    "    data = data.loc[data['AP/PA'] == 'AP']\n",
    "\n",
    "    \n",
    "    category_names = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "    \n",
    "    #filter out all uncertainty labels in classes we care about\n",
    "    data = data[category_names]\n",
    "    #tread all empty values in these selected cols as 0\n",
    "    data = data.fillna(0)\n",
    "    #filter out -1 (uncertain labels)\n",
    "    data = data.loc[(data.iloc[:, :] !=-1).all(axis=1)]\n",
    "    #row-idx of the data we care to keep\n",
    "    fly_list = data.index\n",
    "    #reselect from orginal of kept rows\n",
    "    data = df.iloc[fly_list]\n",
    "\n",
    "    #select the cols we care about\n",
    "    wanted_cols = [\"Path\", 'No Finding'] + category_names\n",
    "    data = data[wanted_cols]\n",
    "    \n",
    "    #filter out rows with no label values\n",
    "    data['sum']  = data.iloc[:, 1:].sum(axis=1)\n",
    "    fly_list = data.loc[data['sum']>0].index\n",
    "\n",
    "    \n",
    "    data = df[wanted_cols].iloc[fly_list]\n",
    "    # fill all NA and uncertainty as 0     \n",
    "    data = data.fillna(0)\n",
    "    data = data.replace(-1,0)\n",
    "\n",
    "    print(\"final size %s\" %len(data))\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting size 223414\n",
      "final size 92771\n",
      "starting size 234\n",
      "final size 132\n",
      "Train_size 88132, valid_size 4639 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61712</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient14892/study18...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91899</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient22063/study1/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140062</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient33631/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216267</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient58974/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81089</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient19481/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Path  No Finding  \\\n",
       "61712   CheXpert-v1.0-small/train/patient14892/study18...         0.0   \n",
       "91899   CheXpert-v1.0-small/train/patient22063/study1/...         1.0   \n",
       "140062  CheXpert-v1.0-small/train/patient33631/study1/...         0.0   \n",
       "216267  CheXpert-v1.0-small/train/patient58974/study1/...         0.0   \n",
       "81089   CheXpert-v1.0-small/train/patient19481/study1/...         0.0   \n",
       "\n",
       "        Atelectasis  Cardiomegaly  Consolidation  Edema  Pleural Effusion  \n",
       "61712           1.0           0.0            1.0    0.0               0.0  \n",
       "91899           0.0           0.0            0.0    0.0               0.0  \n",
       "140062          0.0           1.0            0.0    0.0               0.0  \n",
       "216267          0.0           0.0            0.0    0.0               1.0  \n",
       "81089           1.0           1.0            0.0    1.0               0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = '/home/data/'\n",
    "train = pd.read_csv('%s/CheXpert-v1.0-small/train.csv'%data_root)\n",
    "test = pd.read_csv('%s/CheXpert-v1.0-small/valid.csv' %data_root)\n",
    "\n",
    "train = process_data(train)\n",
    "test = process_data(test)\n",
    "\n",
    "\n",
    "train.head()\n",
    "\n",
    "train, valid = train_test_split(train, test_size=0.05, random_state=42, shuffle=True)\n",
    "print('Train_size %s, valid_size %s ' %(len(train), len(valid)))\n",
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform, data_root):\n",
    "        #TODO::put something here that perserves aspect ratio\n",
    "        self.class_names = ['No Finding', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "        self.image_dir = data_root\n",
    "        self.transform = transform\n",
    "        self.total = len(df)\n",
    "        self.image_names = df['Path'].to_list()\n",
    "        self.labels = df[self.class_names].to_numpy()\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_names[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = self.transform(Image.open(image_path).convert('RGB'))\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (320, 320)\n",
    "resnet_mean = [0.485, 0.456, 0.406]\n",
    "resnet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "#Creating a Transformation Object\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    torchvision.transforms.Resize(size=image_size),\n",
    "    torchvision.transforms.RandomHorizontalFlip(), #A RandomHorizontalFlip to augment our data\n",
    "    torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "    #Normalizing the data to the data that the ResNet18 was trained on\n",
    "    torchvision.transforms.Normalize(mean = resnet_mean ,\n",
    "                                    std = resnet_std) \n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "#Creating a Transformation Object\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    torchvision.transforms.Resize(size=image_size),\n",
    "    # We don't do data augmentation in the test/val set    \n",
    "    torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "    torchvision.transforms.Normalize(mean = resnet_mean,\n",
    "                                    std = resnet_std) \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smaples: 88132, batches: 5509,  classes: 6\n",
      "smaples: 132, batches: 9,  classes: 6\n",
      "smaples: 4639, batches: 290,  classes: 6\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ChestXRayDataset(train, train_transform, data_root)\n",
    "test_dataset = ChestXRayDataset(test, test_transform, data_root)\n",
    "valid_dataset = ChestXRayDataset(valid, test_transform, data_root)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dl_valid = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print('smaples: %s, batches: %s,  classes: %s' %( len(train_dataset), len(dl_train), len(train_dataset.class_names) ))\n",
    "print('smaples: %s, batches: %s,  classes: %s' %( len(test_dataset), len(dl_test), len(test_dataset.class_names) ))\n",
    "print('smaples: %s, batches: %s,  classes: %s' %( len(valid_dataset), len(dl_valid), len(valid_dataset.class_names) ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnext50(torch.nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        resnet.fc = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(in_features=resnet.fc.in_features, out_features=n_classes)\n",
    "        )\n",
    "        self.base_model = resnet\n",
    "        self.sigm = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigm(self.base_model(x))\n",
    "\n",
    "# Initialize the model\n",
    "model = Resnext50(len(train_dataset.class_names))\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model (model, dl, verbose=True):\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    total_loss = 0\n",
    "    class_lookup = dl.dataset.class_names\n",
    "    n_class = len(class_lookup)\n",
    "\n",
    "    for val_step, (images, labels) in enumerate(dl):\n",
    "\n",
    "        imagesGPU, labelsGPU = images.to(device), labels.to(device)        \n",
    "        outputs = model(imagesGPU)\n",
    "        loss = loss_fn(outputs, labelsGPU.type(torch.float))       \n",
    "        total_loss += loss.item()               \n",
    "        outputs = torch.Tensor.cpu(outputs)\n",
    "        predicts.append(outputs.detach().numpy())\n",
    "        targets.append(labels)\n",
    "\n",
    "    predicts = np.vstack(predicts)\n",
    "    targets = np.vstack(targets)\n",
    "    loss = total_loss/len(dl)\n",
    "    \n",
    "    res = {}\n",
    "    total_auc = 0\n",
    "    total_counts = 0\n",
    "    for idx in range(n_class):\n",
    "        truth  = targets[:, idx]\n",
    "        pp = predicts[:,idx]\n",
    "        fpr, tpr, thresholds = roc_curve(truth, pp)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        res[class_lookup[idx]] = auc_score\n",
    "        counts = np.sum(truth)\n",
    "        #A hack to skip no-funding in auc caclualtion\n",
    "        if idx != 0 :\n",
    "            total_auc += auc_score * counts\n",
    "            total_counts += counts\n",
    "    avg_auc = total_auc / total_counts\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        for k, v in res.items():\n",
    "            print(k, v)\n",
    "        print()\n",
    "        print('loss:%s, avg_auc:%s' %(loss, avg_auc))\n",
    "        \n",
    "    return avg_auc, loss\n",
    "\n",
    "\n",
    "def train_model(epochs, model, dl_train, dl_test, check_pt = './chexpert_full_checkpt/'):\n",
    "    print('Starting training..')\n",
    "    prev_auc = 0.\n",
    "    for e in range(0, epochs):\n",
    "        train_loss = 0.        \n",
    "        model.train() # set model to training phase\n",
    "        with tqdm(dl_train, unit=\"batch\") as tepoch:\n",
    "            for images, labels in tepoch:\n",
    "                images, targets = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, targets.type(torch.float))\n",
    "\n",
    "                #Once we get the loss we need to take a gradient step\n",
    "                loss.backward() #Back propogation\n",
    "                optimizer.step() #Completes the gradient step by updating all the parameter values(We are using all parameters)\n",
    "                train_loss += loss.item() #Loss is a tensor which can't be added to train_loss so .item() converts it to float                \n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "        \n",
    "        print('ave_train_loss %s ' %(train_loss / len(dl_train)))\n",
    "        print('test...')\n",
    "        test_auc, test_loss = eval_model(model, dl_test)\n",
    "        print('valid...')\n",
    "        valid_acu, valid_loss = eval_model(model, dl_valid)\n",
    "        \n",
    "        torch.save(model, 'CheXpert_full_%s_resnet50' %(e) )\n",
    "        if test_auc > prev_auc:\n",
    "            prev_auc = test_auc\n",
    "            \n",
    "        print('done %s' %e)\n",
    "    print('Training complete..')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5509 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2013/5509 [08:01<12:46,  4.56batch/s, loss=0.339]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(10, model, dl_train, dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
