{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve, auc\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.utils.data as data_utils\n",
    "from collections import defaultdict\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_transform_cifar100(label_noise=0.0, seed=1234):\n",
    "    training_data = datasets.CIFAR100(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "    )\n",
    "\n",
    "    test_data = datasets.CIFAR100(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "    )    \n",
    "        \n",
    "    \n",
    "    if label_noise > 0:\n",
    "        np.random.seed(seed)\n",
    "        size = int(label_noise * len(training_data))\n",
    "        noise_idx = set(np.random.choice(len(training_data), size, replace=False))\n",
    "        print('injecting noise ...%s' %len(noise_idx))\n",
    "        targets = []\n",
    "        for idx, t in enumerate(training_data.targets):\n",
    "            if idx in noise_idx:\n",
    "                targets.append(np.random.randint(100))\n",
    "            else:\n",
    "                targets.append(t)\n",
    "                \n",
    "        training_data.targets = targets\n",
    "    \n",
    "    \n",
    "        \n",
    "    image_size = (128, 128)\n",
    "    resnet_mean = [0.485, 0.456, 0.406]\n",
    "    resnet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    #Creating a Transformation Object\n",
    "    data_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(size=image_size),\n",
    "        torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "        torchvision.transforms.Normalize(mean = resnet_mean,\n",
    "                                        std = resnet_std) \n",
    "    ])\n",
    "    training_data.transform = data_transform\n",
    "    test_data.transform = data_transform\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(training_data, test_data, filter_by_coarse=False, \n",
    "                coarse_label=None, coarse_to_fine=None, valid_size=0.1, batch_size=64, data_fraction=1.0, seed=1234):\n",
    "    \"\"\"Filters datasets by coarse label if needed and split to train and validation subsets\"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    size = int(data_fraction * len(training_data))\n",
    "    sample_idx = np.random.choice(len(training_data), size, replace=False)\n",
    "    print('sampling data ...%s' %len(sample_idx))\n",
    "    \n",
    "    if filter_by_coarse:\n",
    "        labels = coarse_to_fine[coarse_label]\n",
    "        indices = [idx for idx,v in enumerate(training_data.targets) if v in labels and idx in sample_idx]\n",
    "        indices_test = [idx for idx,v in enumerate(test_data.targets) if v in labels]     \n",
    "    else:\n",
    "        indices = sample_idx\n",
    "        indices_test = [i for i in range(len(test_data.targets))]\n",
    "\n",
    "        \n",
    "    \n",
    "    validate_len = int(len(indices)*valid_size)\n",
    "    validate_filter_indices = random.sample(range(0,len(indices)), validate_len)\n",
    "    indices_val = [indices[i] for i in validate_filter_indices]  \n",
    "    indices_train = [v for i,v in enumerate(indices) if i not in validate_filter_indices]    \n",
    "        \n",
    "    train = data_utils.Subset(training_data, indices_train)\n",
    "    validate = data_utils.Subset(training_data, indices_val)\n",
    "    test = data_utils.Subset(test_data, indices_test)\n",
    "    \n",
    "    train_dl = DataLoader(train,  batch_size=batch_size, shuffle=True)\n",
    "    validate_dl = DataLoader(validate, batch_size=batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(test,  batch_size=batch_size, shuffle=True)\n",
    "    return train_dl, validate_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnext50(torch.nn.Module):\n",
    "    def __init__(self, n_classes, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        resnet = torchvision.models.resnext50_32x4d(pretrained=True, progress=True)\n",
    "        resnet.fc = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(in_features=resnet.fc.in_features, out_features=n_classes)\n",
    "        )\n",
    "        self.base_model = resnet\n",
    "        self.soft = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.soft(self.base_model(x))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, mode=\"flat\", lookup=[], fine_to_coarse={}, batch_size=64):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    counter = 0\n",
    "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "        counter += 1\n",
    "        for X_cpu, y_cpu in tepoch:\n",
    "            if mode == \"fine\":\n",
    "                y_cpu = torch.tensor([lookup.index(i) for i in y_cpu])\n",
    "            elif mode == \"coarse\":\n",
    "                y_cpu = torch.tensor([fine_to_coarse[int(target)] for target in y_cpu])\n",
    "            X, y = X_cpu.to(device), y_cpu.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = loss_fn(outputs, y.type(torch.long))\n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            train_loss += loss.item() \n",
    "            avg_loss = train_loss / (counter * batch_size)\n",
    "            tepoch.set_postfix(loss=avg_loss)\n",
    "    return avg_loss\n",
    "    \n",
    "    \n",
    "def eval_model(dataloader, model, mode=\"flat\", lookup=[], fine_to_coarse={}, return_probab=False):\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    for counter, (images, labels) in enumerate(dataloader):\n",
    "        if mode == \"fine\":\n",
    "            labels = [lookup.index(i) for i in labels]\n",
    "        elif mode == \"coarse\":\n",
    "            labels = [fine_to_coarse[int(i)] for i in labels]\n",
    "        imageGPU = images.to(device)\n",
    "        \n",
    "        outputs = torch.Tensor.cpu(model(imageGPU))\n",
    "        predicts.append(outputs.detach().numpy())\n",
    "        targets.append(labels)\n",
    "        \n",
    "    predicts = np.vstack(predicts)\n",
    "    targets = np.hstack(targets)\n",
    "    if return_probab:\n",
    "        return predicts, targets\n",
    "    else:\n",
    "        predicts = np.argmax(predicts, axis=1)\n",
    "        return accuracy_score(targets, predicts)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(epochs, model, loss_fn, optimizer, train_dl, val_dl, test_dl, \n",
    "                       mode=\"flat\", fine_to_coarse={}, coarse_label=None, lookup=[], model_path = None):\n",
    "    if model_path is None:\n",
    "        model_path = '/models/%s.pth' %model.name\n",
    "    min_loss= 1000\n",
    "    max_acc = 0\n",
    "    for t in range(epochs):\n",
    "        if mode == \"fine\":\n",
    "            print(f\"Coarse label {coarse_label} Epoch {t+1}\\n-------------------------------\")\n",
    "        else:\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = train_loop(train_dl, model, loss_fn, optimizer, mode=mode, fine_to_coarse=fine_to_coarse, lookup=lookup)\n",
    "        val_acc = eval_model(val_dl, model, mode=mode, fine_to_coarse=fine_to_coarse, lookup=lookup)\n",
    "        if train_loss < min_loss:\n",
    "            max_acc = val_acc\n",
    "            min_loss = train_loss\n",
    "            torch.save(model, model_path)\n",
    "        elif train_loss == min_loss and val_acc>max_acc:\n",
    "            max_acc = val_acc\n",
    "            min_loss = train_loss\n",
    "            torch.save(model, model_path)\n",
    "        print(\"validation acc %s and loss %s\" %(val_acc, train_loss))\n",
    "        test_acc = eval_model(test_dl, model, mode=mode, fine_to_coarse=fine_to_coarse, lookup=lookup)\n",
    "        print(\"done epoch %s : test_acc %s\" %(t, test_acc))\n",
    "    print(\"Done! Saved model with validation accuracy %s and loss %s\" %(max_acc, min_loss))\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "acorn = 1234\n",
    "torch.manual_seed(acorn)\n",
    "np.random.seed(acorn)\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "    \n",
    "device = torch.device(dev)  \n",
    "\n",
    "batch_size = 64\n",
    "valid_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "sampling data ...5000\n"
     ]
    }
   ],
   "source": [
    "training_data, test_data=load_and_transform_cifar100(seed=acorn)\n",
    "train_dl, validate_dl, test_dl = filter_data(training_data, test_data, valid_size=valid_size, batch_size=batch_size, data_fraction=0.1, seed=acorn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "learning_rate = 1e-4\n",
    "\n",
    "epochs = 15\n",
    "model = Resnext50(100, name=\"base_model_Resnext50_01fraction\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n",
      "100%|██████████| 71/71 [00:23<00:00,  2.99batch/s, loss=4.83] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.274 and loss 4.8287646025419235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 0 : test_acc 0.2973\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:23<00:00,  2.96batch/s, loss=4.71] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.348 and loss 4.706890903413296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 1 : test_acc 0.3751\n",
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:25<00:00,  2.84batch/s, loss=4.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.46 and loss 4.5815234668552876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 2 : test_acc 0.4586\n",
      "Epoch 4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:25<00:00,  2.77batch/s, loss=4.48] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.496 and loss 4.475729037076235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 3 : test_acc 0.503\n",
      "Epoch 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:25<00:00,  2.78batch/s, loss=4.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.552 and loss 4.40021987259388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 4 : test_acc 0.5527\n",
      "Epoch 6\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:25<00:00,  2.81batch/s, loss=4.33] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.548 and loss 4.329530216753483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 5 : test_acc 0.5727\n",
      "Epoch 7\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:24<00:00,  2.92batch/s, loss=4.3]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.596 and loss 4.295083165168762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 6 : test_acc 0.5788\n",
      "Epoch 8\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:23<00:00,  3.01batch/s, loss=4.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.606 and loss 4.258895222097635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 7 : test_acc 0.5988\n",
      "Epoch 9\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:23<00:00,  3.01batch/s, loss=4.23] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.59 and loss 4.234858490526676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 8 : test_acc 0.5911\n",
      "Epoch 10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:23<00:00,  3.01batch/s, loss=4.22] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.582 and loss 4.216897733509541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 9 : test_acc 0.6022\n",
      "Epoch 11\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:23<00:00,  3.03batch/s, loss=4.2]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.604 and loss 4.202101480215788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 10 : test_acc 0.6051\n",
      "Epoch 12\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.11batch/s, loss=4.18] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.622 and loss 4.18312881141901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 11 : test_acc 0.6147\n",
      "Epoch 13\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.11batch/s, loss=4.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.588 and loss 4.164789229631424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 12 : test_acc 0.6139\n",
      "Epoch 14\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.10batch/s, loss=4.15] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.652 and loss 4.148059573024511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/71 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done epoch 13 : test_acc 0.6135\n",
      "Epoch 15\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:22<00:00,  3.11batch/s, loss=4.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc 0.634 and loss 4.135930623859167\n",
      "done epoch 14 : test_acc 0.6248\n",
      "Done! Saved model with validation accuracy 0.634 and loss 4.135930623859167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6248"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = train_and_validate(epochs, model, loss_fn, optimizer, train_dl, validate_dl, test_dl, \n",
    "                                                    mode=\"flat\", \n",
    "                                                    model_path = 'models/base/%s.pth' %model.name )\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.897"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
