{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tasksim import *\n",
    "\n",
    "from graspologic.embed import AdjacencySpectralEmbed as ASE\n",
    "from graspologic.cluster import GaussianCluster as GMM\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "from sklearn.metrics import adjusted_rand_score as ARI\n",
    "\n",
    "from proglearn import LifelongClassificationForest as l2f\n",
    "import torchvision\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, file='cifar_100_Bit_m-r101x1_embd.p', train=True, classes=[]):\n",
    "        if train:\n",
    "            if file == 'data/cifar_100_Bit_m-r101x1_embd.p':\n",
    "                self.data = pickle.load(open(file, 'rb'))[0][0]\n",
    "                self.targets = np.concatenate(pickle.load(open(file, 'rb'))[0][1])\n",
    "        else:\n",
    "            if file == 'data/cifar_100_Bit_m-r101x1_embd.p':\n",
    "                self.data = pickle.load(open(file, 'rb'))[1][0]\n",
    "                self.targets = np.concatenate(pickle.load(open(file, 'rb'))[1][1])\n",
    "        \n",
    "        self.classes = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "file = 'data/cifar_100_Bit_m-r101x1_embd.p'\n",
    "\n",
    "cif100 = torchvision.datasets.CIFAR100(root='./data', train=True, download=True)\n",
    "trainset = Dataset(file, classes=cif100.classes)\n",
    "testset = Dataset(file, train=False, classes=cif100.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dimension=2048\n",
    "\n",
    "if data_dimension < trainset.data.shape[1]:\n",
    "    pca = PCA(n_components=data_dimension)\n",
    "    pca.fit(trainset.data)\n",
    "    trainset.data = pca.transform(trainset.data)\n",
    "    testset.data = pca.transform(testset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clusters(f, truth, preds, calculate_random=False, n_mc=500, acorn=None):\n",
    "    eval_pred = f(truth, preds)\n",
    "    \n",
    "    if not calculate_random:\n",
    "        return eval_pred\n",
    "    \n",
    "    eval_random = np.zeros(n_mc)\n",
    "    for i in range(n_mc):\n",
    "        shuffled_preds = np.random.choice(preds, size=len(preds), replace=False)\n",
    "        eval_random[i] = f(truth, shuffled_preds)\n",
    "        \n",
    "    return eval_pred, np.mean(eval_random)\n",
    "\n",
    "def evaluate_accuracy(data, labels, truth, preds, n_trees_coarse=25, n_trees_fine=10, train_flat=True,\n",
    "                     test_data=None, test_labels=None, max_depth=5,\n",
    "                     acorn=None):\n",
    "    classes = np.unique(labels)\n",
    "    \n",
    "    forests_dict = {\n",
    "            'coarse_truth': None, \n",
    "            'fine_truth': {c: None for c in np.unique(truth)},\n",
    "            'coarse_preds': None,\n",
    "            'fine_preds': {c: None for c in np.unique(preds)}, \n",
    "            'flat': None\n",
    "    }\n",
    "    \n",
    "    # Coarse forest\n",
    "    coarse_forest_truth = l2f(default_n_estimators=n_trees_coarse,\n",
    "                        default_max_depth=max_depth)\n",
    "    \n",
    "    coarse_forest_truth.add_task(data, truth[labels])\n",
    "    forests_dict['coarse_truth'] = coarse_forest_truth\n",
    "    \n",
    "    coarse_forest_preds = l2f(default_n_estimators=n_trees_coarse,\n",
    "                        default_max_depth=max_depth)\n",
    "    \n",
    "    coarse_forest_preds.add_task(data, preds[labels])\n",
    "    forests_dict['coarse_preds'] = coarse_forest_preds\n",
    "    \n",
    "    \n",
    "    # Flat forest\n",
    "    n_trees_flat = n_trees_coarse + len(np.unique(truth))*n_trees_fine\n",
    "    \n",
    "    if train_flat:\n",
    "        flat_forest_truth = l2f(default_n_estimators=n_trees_flat,\n",
    "                            default_max_depth=max_depth)\n",
    "        flat_forest_truth.add_task(data, labels)\n",
    "        forests_dict['flat'] = flat_forest_truth\n",
    "        \n",
    "    # Fine forest\n",
    "    for j, parent_class in enumerate(np.unique(truth)):\n",
    "        temp_fine_indices = np.where(truth[labels] == parent_class)[0]\n",
    "        \n",
    "        \n",
    "        fine_forest_truth = l2f(default_n_estimators=n_trees_fine, \n",
    "                               default_max_depth=max_depth\n",
    "                              )\n",
    "        fine_forest_truth.add_task(data[temp_fine_indices], labels[temp_fine_indices])\n",
    "        forests_dict['fine_truth'][j] = fine_forest_truth\n",
    "        \n",
    "    for j, parent_class in enumerate(np.unique(preds)):\n",
    "        temp_fine_indices = np.where(preds[labels] == parent_class)[0]\n",
    "        \n",
    "        fine_forest_preds = l2f(default_n_estimators=n_trees_fine, \n",
    "                               default_max_depth=max_depth\n",
    "                              )\n",
    "        fine_forest_preds.add_task(data[temp_fine_indices], labels[temp_fine_indices])\n",
    "        forests_dict['fine_preds'][j] = fine_forest_preds\n",
    "        \n",
    "        \n",
    "    # Now, calculate accuracies\n",
    "    accuracies = np.zeros(3)\n",
    "    \n",
    "    if test_data is None:\n",
    "        raise ValueError\n",
    "        \n",
    "    n_test, d_test = test_data.shape\n",
    "                \n",
    "    hierarchical_posteriors_truth = np.zeros((n_test, len(classes)))\n",
    "    hierarchical_posteriors_preds = np.zeros((n_test, len(classes)))\n",
    "    \n",
    "    coarse_posteriors_truth = forests_dict['coarse_truth'].predict_proba(test_data, 0)\n",
    "    coarse_posteriors_preds = forests_dict['coarse_preds'].predict_proba(test_data, 0)\n",
    "        \n",
    "    # Hierarchical posteriors & prediction\n",
    "    for j, parent_class in enumerate(np.unique(truth)):\n",
    "        temp_fine_label_indices = np.where(truth == parent_class)[0]\n",
    "        \n",
    "        temp_fine_posteriors = forests_dict['fine_truth'][j].predict_proba(test_data, 0)\n",
    "        hierarchical_posteriors_truth[:, temp_fine_label_indices] = np.multiply(coarse_posteriors_truth[:, j],\n",
    "                                                                     temp_fine_posteriors.T\n",
    "                                                                    ).T\n",
    "        \n",
    "    for j, parent_class in enumerate(np.unique(preds)):\n",
    "        temp_fine_label_indices = np.where(preds == parent_class)[0]\n",
    "\n",
    "        \n",
    "        temp_fine_posteriors = forests_dict['fine_preds'][j].predict_proba(test_data, 0)\n",
    "        hierarchical_posteriors_preds[:, temp_fine_label_indices] = np.multiply(coarse_posteriors_preds[:, j],\n",
    "                                                                     temp_fine_posteriors.T\n",
    "                                                                    ).T\n",
    "        \n",
    "    yhat_hc = np.argmax(hierarchical_posteriors_truth, axis=1)\n",
    "    accuracies[0] = np.mean(yhat_hc == np.array(test_labels))\n",
    "    \n",
    "    yhat_hc = np.argmax(hierarchical_posteriors_preds, axis=1)\n",
    "    accuracies[1] = np.mean(yhat_hc == np.array(test_labels))\n",
    "    \n",
    "    \n",
    "    # Flat posteriors & prediction\n",
    "    if train_flat:\n",
    "        flat_posteriors = forests_dict['flat'].predict_proba(test_data, 0)\n",
    "        yhat_flat = np.argmax(flat_posteriors, axis=1)\n",
    "        accuracies[2] = np.mean(yhat_flat == np.array(test_labels))\n",
    "    \n",
    "    return accuracies[:, np.newaxis].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(X, y, coarse_labels, n_trees_coarse=25, n_trees_fine=10,\n",
    "                      X_test=None, y_test=None, \n",
    "                      max_depth=5,\n",
    "                      acorn=None):\n",
    "    \n",
    "    coarse_classes = np.unique(coarse_labels)\n",
    "    n_coarse = len(coarse_classes)\n",
    "    n_fine = len(coarse_labels)\n",
    "    \n",
    "    \n",
    "    # Coarse forest\n",
    "    coarse_forest = l2f(default_n_estimators=n_trees_coarse,\n",
    "                        default_max_depth=max_depth)\n",
    "    \n",
    "    coarse_forest.add_task(X, coarse_labels[y])\n",
    "        \n",
    "    # Fine forest\n",
    "    if n_trees_fine is not None:\n",
    "        fine_forests = {}\n",
    "        for j, coarse_class in enumerate(coarse_classes):\n",
    "            temp_fine_indices = np.where(coarse_labels[y] == coarse_class)[0]\n",
    "\n",
    "            fine_forests[coarse_class] = l2f(default_n_estimators=n_trees_fine, \n",
    "                                   default_max_depth=max_depth\n",
    "                                  )\n",
    "            fine_forests[coarse_class].add_task(X[temp_fine_indices], y[temp_fine_indices])\n",
    "            \n",
    "    n_test, d_test = X_test.shape\n",
    "                \n",
    "    posteriors = np.zeros((n_test, n_fine))\n",
    "    \n",
    "    coarse_posteriors = coarse_forest.predict_proba(X_test, 0)\n",
    "        \n",
    "    # Hierarchical posteriors & prediction\n",
    "    \n",
    "    if n_trees_fine is not None:\n",
    "        for j, coarse_class in enumerate(coarse_classes):\n",
    "            temp_fine_label_indices = np.where(coarse_labels == coarse_class)[0]\n",
    "            \n",
    "            temp_fine_posteriors = fine_forests[coarse_class].predict_proba(X_test, 0)\n",
    "            \n",
    "            posteriors[:, temp_fine_label_indices] = np.multiply(coarse_posteriors[:, j],\n",
    "                                                                         temp_fine_posteriors.T\n",
    "                                                                        ).T\n",
    "    else:\n",
    "        posteriors = coarse_posteriors\n",
    "\n",
    "    predictions = np.argmax(posteriors, axis=1)\n",
    "    \n",
    "    return np.mean(predictions == np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(X, y, X_test, y_test,\n",
    "                    acc_kwargs,\n",
    "                    eval_kwargs=None):\n",
    "    \n",
    "    acc_kwargs['test_data'] = X_test\n",
    "    acc_kwargs['test_labels'] = y_test\n",
    "    \n",
    "    del X_test\n",
    "    del y_test\n",
    "    \n",
    "    accs = evaluate_accuracy(X, y, **acc_kwargs)\n",
    "    \n",
    "    if eval_kwargs is not None:\n",
    "        evals = evaluate_clusters(**eval_kwargs)\n",
    "        return np.array(evals)[:, np.newaxis].T, accs\n",
    "    \n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(idx_by_label, p=0.1, replace=False):\n",
    "    return np.concatenate([np.random.choice(ibl, size=int(max([1, p * len(ibl)])), replace=replace) for ibl in idx_by_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_to_fine_map = {\n",
    "'aquatic_mammals': ['beaver', 'dolphin', 'otter', 'seal', 'whale'],\n",
    "'fish': ['aquarium_fish', 'flatfish', 'ray', 'shark', 'trout'],\n",
    "'flowers': ['orchid', 'poppy', 'rose', 'sunflower', 'tulip'],\n",
    "'food_containers': ['bottle', 'bowl', 'can', 'cup', 'plate'],\n",
    "'fruit_and_vegetables': ['apple', 'mushroom', 'orange', 'pear', 'sweet_pepper'],\n",
    "'household_electrical_devices': ['clock', 'keyboard', 'lamp', 'telephone', 'television'],\n",
    "'household_furniture': ['bed', 'chair', 'couch', 'table', 'wardrobe'],\n",
    "'insects': ['bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach'],\n",
    "'large_carnivores': ['bear', 'leopard', 'lion', 'tiger', 'wolf'],\n",
    "'large_man-made_outdoor_things': ['bridge', 'castle', 'house', 'road', 'skyscraper'],\n",
    "'large_natural_outdoor_scenes': ['cloud', 'forest', 'mountain', 'plain', 'sea'],\n",
    "'large_omnivores_and_herbivores': ['camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo'],\n",
    "'medium-sized_mammals': ['fox', 'porcupine', 'possum', 'raccoon', 'skunk'],\n",
    "'non-insect_invertebrates': ['crab', 'lobster', 'snail', 'spider', 'worm'],\n",
    "'people': ['baby', 'boy', 'girl', 'man', 'woman'],\n",
    "'reptiles': ['crocodile', 'dinosaur', 'lizard', 'snake', 'turtle'],\n",
    "'small mammals': ['hamster', 'mouse', 'rabbit', 'shrew', 'squirrel'],\n",
    "'trees': ['maple_tree', 'oak_tree', 'palm_tree', 'pine_tree', 'willow_tree'],\n",
    "'vehicles_1': ['bicycle', 'bus', 'motorcycle', 'pickup_truck', 'train'],\n",
    "'vehicles_2': ['lawn_mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
    "}\n",
    "\n",
    "coarse_number_to_coarse_name = {i: name for i, name in enumerate(coarse_to_fine_map)}\n",
    "\n",
    "def fine_to_coarse(coarse_to_fine):\n",
    "    fine_to_coarse_map = {}\n",
    "    for key in coarse_to_fine:\n",
    "        fines = coarse_to_fine[key]\n",
    "        for f in fines:\n",
    "            fine_to_coarse_map[f] = key\n",
    "            \n",
    "    return fine_to_coarse_map\n",
    "\n",
    "fine_to_coarse_map = fine_to_coarse(coarse_to_fine_map)\n",
    "\n",
    "fine_number_to_fine_name = {i: name for i, name in enumerate(trainset.classes)}\n",
    "fine_name_to_fine_number = {name: i for i, name in fine_number_to_fine_name.items()}\n",
    "\n",
    "for i in range(100):\n",
    "    fine_to_coarse_map[fine_number_to_fine_name[i]]\n",
    "    \n",
    "coarse_name_to_coarse_number = {name: i for i, name in enumerate(coarse_to_fine_map)}\n",
    "\n",
    "coarse_targets = np.array([coarse_name_to_coarse_number[fine_to_coarse_map[fine_number_to_fine_name[y]]] for y in trainset.targets])\n",
    "idx_by_coarse = np.array([np.where(coarse_targets == y)[0] for y in range(20)])\n",
    "idx_by_fine = np.array([np.where(trainset.targets == y)[0] for y in range(100)])\n",
    "\n",
    "\n",
    "test_coarse_targets = np.array([coarse_name_to_coarse_number[fine_to_coarse_map[fine_number_to_fine_name[y]]] for y in testset.targets])\n",
    "test_idx_by_coarse = np.array([np.where(test_coarse_targets == y)[0] for y in range(20)])\n",
    "\n",
    "\n",
    "coarse_names = np.array(list(coarse_name_to_coarse_number.keys()))\n",
    "\n",
    "fine_number_to_coarse_number = {fn: coarse_name_to_coarse_number[\n",
    "                                        fine_to_coarse_map[\n",
    "                                            fine_number_to_fine_name[fn]\n",
    "                                        ]\n",
    "                                    ] for fn in range(100)}\n",
    "\n",
    "\n",
    "fine_by_coarse = [np.where(np.array(list(fine_number_to_coarse_number.values())) == i)[0] for i in range(20)]\n",
    "all_fine = np.concatenate(fine_by_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mc=10\n",
    "n_cores=10\n",
    "\n",
    "clusters = [all_fine for i in range(n_mc)]\n",
    "np.random.seed(2)\n",
    "\n",
    "accuracy_tuples = []\n",
    "n_props = [0.1]\n",
    "\n",
    "n_trees_coarse=20*50 + 500\n",
    "n_trees_fine=None\n",
    "max_depth=10\n",
    "\n",
    "for i, prop in enumerate(n_props):\n",
    "    for j in range(n_mc):\n",
    "        inds = stratified_sample(idx_by_fine, p=prop, replace=False)\n",
    "        accuracy_tuples.append((inds,\n",
    "                                  clusters[i*len(n_props) + j], \n",
    "                                  n_trees_coarse, \n",
    "                                  n_trees_fine, \n",
    "                                  max_depth\n",
    "                              ))\n",
    "        \n",
    "\n",
    "condensed_func_accuracy = lambda x: evaluate_accuracy(trainset.data[x[0]], trainset.targets[x[0]],\n",
    "                                                     *x[1:-1],\n",
    "                                                      testset.data, testset.targets,\n",
    "                                                     x[-1])\n",
    "\n",
    "\n",
    "\n",
    "accuracies = np.array(Parallel(n_jobs=n_cores)(delayed(condensed_func_accuracy)(tuple_) for tuple_ in accuracy_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01003, 0.0038404426828166564)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies), np.std(accuracies, ddof=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hc",
   "language": "python",
   "name": "hc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
