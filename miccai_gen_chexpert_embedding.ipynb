{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from graspologic.cluster import GaussianCluster as GMM\n",
    "from collections import defaultdict\n",
    "from proglearn.forest import UncertaintyForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acorn = 1234\n",
    "torch.manual_seed(acorn)\n",
    "np.random.seed(acorn)\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "    \n",
    "device = torch.device(dev)  \n",
    "\n",
    "n_iter = 10\n",
    "seeds = np.random.randint(10000, size=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process data, filter out only frontal, ap, fillter out uncertainty in classes we care and fill in rest data\n",
    "def process_data(df):\n",
    "    \n",
    "    print('starting size %s' %len(df))\n",
    "    data = df\n",
    "    #only use frontal/AP data\n",
    "    data = data.loc[data['Frontal/Lateral'] == 'Frontal']\n",
    "    data = data.loc[data['AP/PA'] == 'AP']\n",
    "\n",
    "    \n",
    "    category_names = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "    \n",
    "    #filter out all uncertainty labels in classes we care about\n",
    "    data = data[category_names]\n",
    "    #tread all empty values in these selected cols as 0\n",
    "    data = data.fillna(0)\n",
    "    #filter out -1 (uncertain labels)\n",
    "    data = data.loc[(data.iloc[:, :] !=-1).all(axis=1)]\n",
    "    #row-idx of the data we care to keep\n",
    "    fly_list = data.index\n",
    "    #reselect from orginal of kept rows\n",
    "    data = df.iloc[fly_list]\n",
    "\n",
    "    #select the cols we care about\n",
    "    wanted_cols = [\"Path\", 'No Finding'] + category_names\n",
    "    data = data[wanted_cols]\n",
    "    \n",
    "    #filter out rows with no label values\n",
    "    data['sum']  = data.iloc[:, 1:].sum(axis=1)\n",
    "    fly_list = data.loc[data['sum']>0].index\n",
    "\n",
    "    \n",
    "    data = df[wanted_cols].iloc[fly_list]\n",
    "    # fill all NA and uncertainty as 0     \n",
    "    data = data.fillna(0)\n",
    "    data = data.replace(-1,0)\n",
    "\n",
    "    print(\"final size %s\" %len(data))\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting size 234\n",
      "final size 132\n",
      "starting size 223414\n",
      "final size 92771\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00006/study1/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study2/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Path  No Finding  \\\n",
       "0   CheXpert-v1.0-small/train/patient00001/study1/...         1.0   \n",
       "4   CheXpert-v1.0-small/train/patient00003/study1/...         0.0   \n",
       "11  CheXpert-v1.0-small/train/patient00006/study1/...         1.0   \n",
       "12  CheXpert-v1.0-small/train/patient00007/study1/...         0.0   \n",
       "13  CheXpert-v1.0-small/train/patient00007/study2/...         0.0   \n",
       "\n",
       "    Atelectasis  Cardiomegaly  Consolidation  Edema  Pleural Effusion  \n",
       "0           0.0           0.0            0.0    0.0               0.0  \n",
       "4           0.0           0.0            0.0    1.0               0.0  \n",
       "11          0.0           0.0            0.0    0.0               0.0  \n",
       "12          1.0           1.0            0.0    0.0               0.0  \n",
       "13          1.0           0.0            0.0    0.0               0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = '/home/weiwya/teamdrive_bak/weiwei_temp_data'\n",
    "test_df = pd.read_csv('%s/CheXpert-v1.0-small/valid.csv' %data_root)\n",
    "test_df = process_data(test_df)\n",
    "\n",
    "train_full = pd.read_csv('%s/CheXpert-v1.0-small/train.csv' %data_root)\n",
    "train_full = process_data(train_full)\n",
    "\n",
    "train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform, data_root):\n",
    "        #TODO::put something here that perserves aspect ratio\n",
    "        self.class_names = ['No Finding', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "        self.image_dir = data_root\n",
    "        self.transform = transform\n",
    "        self.total = len(df)\n",
    "        self.image_names = df['Path'].to_list()\n",
    "        self.labels = df[self.class_names].to_numpy()\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_names[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = self.transform(Image.open(image_path).convert('RGB'))\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    \n",
    "image_size = (320, 320)\n",
    "resnet_mean = [0.485, 0.456, 0.406]\n",
    "resnet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "#Creating a Transformation Object\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    torchvision.transforms.Resize(size=image_size),\n",
    "    torchvision.transforms.RandomHorizontalFlip(), #A RandomHorizontalFlip to augment our data\n",
    "    torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "    #Normalizing the data to the data that the ResNet18 was trained on\n",
    "    torchvision.transforms.Normalize(mean = resnet_mean ,\n",
    "                                    std = resnet_std) \n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "#Creating a Transformation Object\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    torchvision.transforms.Resize(size=image_size),\n",
    "    # We don't do data augmentation in the test/val set    \n",
    "    torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "    torchvision.transforms.Normalize(mean = resnet_mean,\n",
    "                                    std = resnet_std) \n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take any model, use its penultimate layer as output features\n",
    "def extract_fetures_targets(model, dl):    \n",
    "    tt = model.base_model\n",
    "    modules=list(tt.children())[:-1]\n",
    "    feature_extractor = torch.nn.Sequential(*modules)\n",
    "    for p in feature_extractor.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    feature_extractor.to(device)\n",
    "    features = []\n",
    "    targets = []\n",
    "    for val_step, (images, labels) in enumerate(dl):\n",
    "        imagesGPU = images.to(device)      \n",
    "        outputs = feature_extractor(imagesGPU)        \n",
    "        outputs = torch.Tensor.cpu(outputs)\n",
    "        outputs = outputs.detach().numpy()\n",
    "        features.append(outputs)\n",
    "        targets.append(labels)\n",
    "        \n",
    "    features = np.vstack(features)\n",
    "    targets = np.vstack(targets)\n",
    "    dim = features.shape[1]\n",
    "    features= features.reshape(len(dl.dataset), dim)\n",
    "    torch.cuda.empty_cache()\n",
    "    return features, targets\n",
    "\n",
    "\n",
    "#build model using Resnet50 as backbone\n",
    "class Resnext50(torch.nn.Module):\n",
    "    def __init__(self, n_classes, name):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        resnet.fc = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(in_features=resnet.fc.in_features, out_features=n_classes)\n",
    "        )\n",
    "        self.base_model = resnet\n",
    "        self.sigm = torch.nn.Sigmoid()\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigm(self.base_model(x))\n",
    "\n",
    "def eval_model (model, loss_fn, dl, verbose=True):\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    total_loss = 0\n",
    "    class_lookup = dl.dataset.class_names\n",
    "    n_class = len(class_lookup)\n",
    "\n",
    "    for val_step, (images, labels) in enumerate(dl):\n",
    "\n",
    "        imagesGPU, labelsGPU = images.to(device), labels.to(device)        \n",
    "        outputs = model(imagesGPU)\n",
    "        loss = loss_fn(outputs, labelsGPU.type(torch.float))       \n",
    "        total_loss += loss.item()               \n",
    "        outputs = torch.Tensor.cpu(outputs)\n",
    "        predicts.append(outputs.detach().numpy())\n",
    "        targets.append(labels)\n",
    "\n",
    "    predicts = np.vstack(predicts)\n",
    "    targets = np.vstack(targets)\n",
    "    loss = total_loss/len(dl)\n",
    "    \n",
    "    res = {}\n",
    "    total_auc = 0\n",
    "    total_counts = 0\n",
    "    for idx in range(n_class):\n",
    "        truth  = targets[:, idx]\n",
    "        pp = predicts[:,idx]\n",
    "        fpr, tpr, thresholds = roc_curve(truth, pp)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        res[class_lookup[idx]] = auc_score\n",
    "        counts = np.sum(truth)\n",
    "        total_auc += auc_score * counts\n",
    "        total_counts += counts\n",
    "    avg_auc = total_auc / total_counts\n",
    "    \n",
    "    if verbose:\n",
    "        for k, v in res.items():\n",
    "            print(k, v)\n",
    "        print()\n",
    "        print('loss:%s, avg_auc:%s' %(loss, avg_auc))\n",
    "        \n",
    "    return avg_auc, loss\n",
    "\n",
    "def eval_fine_model(model, loss_fn, dl, verbose=True):\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    total_loss = 0\n",
    "    class_lookup = dl.dataset.class_names\n",
    "\n",
    "    with tqdm(dl, unit=\"batch\") as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            imagesGPU, labelsGPU = images.to(device), labels.to(device)        \n",
    "            outputs = model(imagesGPU)\n",
    "            loss = loss_fn(outputs, labelsGPU.type(torch.float))       \n",
    "            total_loss += loss.item()               \n",
    "            outputs = torch.Tensor.cpu(outputs)\n",
    "            predicts.append(outputs.detach().numpy())\n",
    "            targets.append(labels)\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "    predicts = np.vstack(predicts)\n",
    "    targets = np.vstack(targets)\n",
    "    loss = total_loss/len(dl)\n",
    "    \n",
    "    n_samples = len(targets)\n",
    "    n_actual_classes = len(dl.dataset.class_names)\n",
    "    n_fine_classes = targets.shape[1]\n",
    "    \n",
    "    \n",
    "    lookup = dl.dataset.fine_to_org\n",
    "    coarse_predict = np.zeros((n_samples, n_actual_classes))\n",
    "    coarse_target = np.zeros((n_samples, n_actual_classes))\n",
    "    \n",
    "    res = {}\n",
    "    total_auc = 0\n",
    "    total_counts = 0\n",
    "    class_lookup = dl.dataset.class_names\n",
    "    \n",
    "    #add all fine class predictions to their proper coarse label\n",
    "    for idx in range(n_fine_classes):\n",
    "        coarse_idx = lookup[idx]\n",
    "        coarse_predict[:, coarse_idx] += predicts[:, idx]\n",
    "        coarse_target[:, coarse_idx] += targets[:, idx]\n",
    "    \n",
    "    \n",
    "    for idx in range(n_actual_classes): \n",
    "        truth  = coarse_target[:, idx]        \n",
    "        pp = coarse_predict[:,idx]\n",
    "        \n",
    "        truth = np.clip(truth, 0, 1.0)\n",
    "        pp = np.clip(pp, 0, 1.0)\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(truth, pp)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        res[class_lookup[idx]] = auc_score\n",
    "        counts = np.sum(truth)\n",
    "        total_auc += auc_score * counts\n",
    "        total_counts += counts\n",
    "    \n",
    "    avg_auc = total_auc / total_counts\n",
    "    \n",
    "    if verbose:\n",
    "        for k, v in res.items():\n",
    "            print(k, v)\n",
    "        print()\n",
    "        print('loss:%s, avg_auc:%s' %(loss, avg_auc))\n",
    "        \n",
    "    return avg_auc, loss\n",
    "\n",
    "def train_model(epochs, train_model, train_loss_fn, train_optimizer, dl_train, dl_validate, dl_test, eval_fn=None):\n",
    "    for e in range(0, epochs):\n",
    "        train_loss = 0.        \n",
    "        train_model.train() \n",
    "        with tqdm(dl_train, unit=\"batch\") as tepoch:\n",
    "            for images, labels in tepoch:\n",
    "                images, targets = images.to(device), labels.to(device)\n",
    "                train_optimizer.zero_grad()\n",
    "                outputs = train_model(images)\n",
    "                loss = train_loss_fn(outputs, targets.type(torch.float))\n",
    "\n",
    "                #Once we get the loss we need to take a gradient step\n",
    "                loss.backward() #Back propogation\n",
    "                train_optimizer.step() #Completes the gradient step by updating all the parameter values(We are using all parameters)\n",
    "                train_loss += loss.item() #Loss is a tensor which can't be added to train_loss so .item() converts it to float                \n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "        \n",
    "        print('train_loss %s ' %(train_loss / len(dl_train)))\n",
    "        if eval_fn is not None:\n",
    "            if dl_validate is not None:\n",
    "                eval_fn(train_model, dl_validate)\n",
    "            if dl_test is not None:\n",
    "                eval_fn(train_model, dl_test)\n",
    "                \n",
    "        print('done %s' %e)\n",
    "    print('Training complete..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn a item:list(classes) into a 1-hot-labels\n",
    "def make_vector_label(lookup, n_classes):\n",
    "    n_samples = len(lookup)\n",
    "    labels = np.zeros( (n_samples, n_classes))\n",
    "    for idx, v in lookup.items():\n",
    "        for vv in v:\n",
    "            labels[idx][vv] = 1.0\n",
    "    return labels\n",
    "\n",
    "#1st cluster within a label\n",
    "#then cluster means of each cluster to generate coarse label\n",
    "#return new label in for each feature in coarse, fine and also a fine to orignal lookup\n",
    "def gen_coarse_fine_labels(features, labels, n_cluster_min=5, n_cluster_max=8):\n",
    "    fine_clfs = []\n",
    "    conditional_means = []\n",
    "    n_features = labels.shape[1]\n",
    "    idx_to_fine_labels = defaultdict(list)\n",
    "    curr = 0\n",
    "    fine_to_org ={}\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        ll = labels[:, i]\n",
    "        selected_idx = np.where(ll==1.0)[0]\n",
    "        xx = features[selected_idx]\n",
    "        \n",
    "        \n",
    "        clf = GMM(min_components=n_cluster_min, max_components=n_cluster_max, reg_covar=1e-3).fit(xx) \n",
    "        pp = clf.predict(xx) + curr\n",
    "        curr += clf.n_components_\n",
    "\n",
    "        unique_y = np.unique(pp)\n",
    "        for y in unique_y:\n",
    "            fine_to_org[y] = i\n",
    "            \n",
    "        means = np.array([\n",
    "            np.mean(features[np.where(pp == c)[0]], axis=0) for c in unique_y])\n",
    "        conditional_means.append(means)\n",
    "        fine_clfs.append(clf)\n",
    "        \n",
    "        #add fine labels to item lookup\n",
    "        for idx, p in zip(selected_idx, pp):\n",
    "            idx_to_fine_labels[idx].append(p)\n",
    "            \n",
    "    conditional_means = np.vstack(conditional_means)\n",
    "    total_fine_labels = conditional_means.shape[0]\n",
    "\n",
    "    coarse_clf  = GMM(min_components=n_cluster_min, max_components=n_cluster_max, reg_covar=1e-3)\n",
    "    coarse_clf.fit(conditional_means)\n",
    "    total_coarse_labels = coarse_clf.n_components_\n",
    "    \n",
    "    pc = coarse_clf.predict(conditional_means)\n",
    "    \n",
    "    #lookup for which coarse cluster a fine lable belongs\n",
    "    \n",
    "    fine_to_coarse = {}\n",
    "    for idx, p in enumerate(pc):\n",
    "        fine_to_coarse[idx] = p\n",
    "\n",
    "    idx_to_coarse_labels = defaultdict(set)\n",
    "\n",
    "    for idx, fine_label in idx_to_fine_labels.items():\n",
    "        for f in fine_label:\n",
    "            coarse_label = fine_to_coarse[f]\n",
    "            idx_to_coarse_labels[idx].add(coarse_label)\n",
    "        \n",
    "    return (idx_to_coarse_labels, total_coarse_labels), (idx_to_fine_labels, total_fine_labels), fine_to_org   \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take any model, use its penultimate layer as output features\n",
    "def get_feature_extractor(model):    \n",
    "    tt = model.base_model\n",
    "    modules=list(tt.children())[:-1]\n",
    "    feature_extractor = torch.nn.Sequential(*modules)\n",
    "    for p in feature_extractor.parameters():\n",
    "        p.requires_grad = False\n",
    "    feature_extractor.to(device)\n",
    "    return feature_extractor\n",
    "\n",
    "\n",
    "def gen_fine_clf(features, labels, n_cluster_min=5, n_cluster_max=8):\n",
    "    fine_clfs = []\n",
    "    n_features = labels.shape[1]\n",
    "    curr = 0\n",
    "    fine_to_org ={}\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        ll = labels[:, i]\n",
    "        selected_idx = np.where(ll==1.0)[0]\n",
    "        xx = features[selected_idx]\n",
    "           \n",
    "        clf = GMM(min_components=n_cluster_min, max_components=n_cluster_max, reg_covar=1e-3).fit(xx) \n",
    "        pp = clf.predict(xx) + curr\n",
    "        curr += clf.n_components_\n",
    "\n",
    "        unique_y = np.unique(pp)\n",
    "        for y in unique_y:\n",
    "            fine_to_org[y] = i\n",
    "            \n",
    "        fine_clfs.append(clf)\n",
    "        \n",
    "    return fine_clfs, fine_to_org, curr\n",
    "\n",
    "\n",
    "def make_fine_labels(features, org_labels, fine_clfs, n_fine_classes):\n",
    "\n",
    "    fine_labels = np.zeros(n_fine_classes)\n",
    "    curr = 0\n",
    "    for i in range(org_labels.shape[1]):\n",
    "        ll = org_labels[0, i]\n",
    "        fine_clf = fine_clfs[i]\n",
    "        if ll == 1:\n",
    "            pp = fine_clf.predict(features) + curr\n",
    "            fine_labels[pp[0]] = 1.\n",
    "        curr += fine_clf.n_components_\n",
    "        \n",
    "    return fine_labels\n",
    "        \n",
    "        \n",
    "    \n",
    "def extract_features(feature_extractor, tensor):\n",
    "    (channel, w, h ) = tensor.shape\n",
    "\n",
    "    tt = tensor.reshape(1, channel, w, h)\n",
    "    tensor_gpu = tt.to(device)\n",
    "    outputs = feature_extractor(tensor_gpu)        \n",
    "    outputs = torch.Tensor.cpu(outputs)\n",
    "    outputs = outputs.detach().numpy()\n",
    "    dim = outputs.shape[1]\n",
    "    outputs = outputs.reshape(1, dim)\n",
    "    return outputs\n",
    "    \n",
    "\n",
    "#load data, and convert into features to inferr finelabels\n",
    "class ChestXRayFineLabelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform, data_root, embd_model, fine_clfs, fine_to_org, n_fine_classes):\n",
    "        self.class_names = ['No Finding', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "        self.image_dir = data_root\n",
    "        self.transform = transform\n",
    "        self.total = len(df)\n",
    "        self.image_names = df['Path'].to_list()\n",
    "        self.org_labels = df[self.class_names].to_numpy()\n",
    "        self.embd_model = embd_model\n",
    "        self.fine_clfs = fine_clfs\n",
    "        self.fine_to_org = fine_to_org\n",
    "        self.n_fine_classes = n_fine_classes\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_names[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = self.transform(Image.open(image_path).convert('RGB'))\n",
    "        features = extract_features(self.embd_model, image)\n",
    "        org_label = self.org_labels[idx]\n",
    "        org_label = org_label.reshape(1, -1)\n",
    "        fine_labels = make_fine_labels(features, org_label, self.fine_clfs, self.n_fine_classes)\n",
    "        return image, fine_labels\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 train_size: 580, validate_size: 5219, test_size: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 580/580 [01:05<00:00,  8.84batch/s, loss=0.342]\n",
      "  0%|          | 1/580 [00:00<01:02,  9.23batch/s, loss=0.457]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.4504555628731333 \n",
      "done 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 580/580 [01:05<00:00,  8.82batch/s, loss=0.482]\n",
      "  0%|          | 1/580 [00:00<01:05,  8.78batch/s, loss=0.466]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.3972012645211713 \n",
      "done 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 580/580 [01:05<00:00,  8.80batch/s, loss=0.499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.36601697781990317 \n",
      "done 2\n",
      "Training complete..\n",
      "done training embedding NN\n",
      "No Finding 0.878394719834715\n",
      "Atelectasis 0.6426463175664262\n",
      "Cardiomegaly 0.7976199428752782\n",
      "Consolidation 0.6868671329459131\n",
      "Edema 0.7852854908501798\n",
      "Pleural Effusion 0.8450003130656759\n",
      "\n",
      "loss:0.4157215267916616, avg_auc:0.7877470713201711\n",
      "No Finding 0.9590277777777778\n",
      "Atelectasis 0.7497113830524128\n",
      "Cardiomegaly 0.7407577497129736\n",
      "Consolidation 0.7815625000000002\n",
      "Edema 0.8657196462074511\n",
      "Pleural Effusion 0.8616947587162318\n",
      "\n",
      "loss:0.6032717194822099, avg_auc:0.801258798005651\n",
      "done eval base model 0.7877470713201711 0.801258798005651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 580/580 [02:49<00:00,  3.42batch/s, loss=0.127]\n",
      "  0%|          | 1/580 [00:00<01:51,  5.20batch/s, loss=0.132]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.19548038623199382 \n",
      "done 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 580/580 [02:48<00:00,  3.44batch/s, loss=0.132] \n",
      "  0%|          | 1/580 [00:00<01:53,  5.11batch/s, loss=0.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.12600955631712388 \n",
      "done 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 580/580 [03:00<00:00,  3.21batch/s, loss=0.121] \n",
      "  0%|          | 1/5219 [00:00<13:08,  6.62batch/s, loss=0.125]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.11453343814816969 \n",
      "done 2\n",
      "Training complete..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5219/5219 [27:40<00:00,  3.14batch/s, loss=0.137] \n",
      " 11%|█         | 1/9 [00:00<00:01,  6.70batch/s, loss=0.178]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Finding 0.8829033031076466\n",
      "Atelectasis 0.6281528700292486\n",
      "Cardiomegaly 0.7912816993135563\n",
      "Consolidation 0.6614969913652327\n",
      "Edema 0.7884240718325894\n",
      "Pleural Effusion 0.8351047930870747\n",
      "\n",
      "loss:0.11645048056001246, avg_auc:0.7811151883996941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:02<00:00,  4.46batch/s, loss=0.214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Finding 0.9284722222222223\n",
      "Atelectasis 0.6719002539829139\n",
      "Cardiomegaly 0.7657864523536166\n",
      "Consolidation 0.7740625\n",
      "Edema 0.8555347091932458\n",
      "Pleural Effusion 0.8621565458323712\n",
      "\n",
      "loss:0.17233473559220633, avg_auc:0.7839048811175049\n",
      "done-iterations 0\n",
      " val: 0.7877470713201711 test: 0.801258798005651\n",
      " our_val:0.7811151883996941 our_test [0.7839048811175049]\n",
      "iteration: 1 train_size: 580, validate_size: 5219, test_size: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 580/580 [01:05<00:00,  8.80batch/s, loss=0.434]\n",
      "  0%|          | 1/580 [00:00<01:02,  9.31batch/s, loss=0.311]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.45574991728725106 \n",
      "done 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 580/580 [01:05<00:00,  8.82batch/s, loss=0.463]\n",
      "  0%|          | 1/580 [00:00<01:05,  8.85batch/s, loss=0.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.4030348360024649 \n",
      "done 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 580/580 [01:05<00:00,  8.84batch/s, loss=0.284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.37189876432048863 \n",
      "done 2\n",
      "Training complete..\n",
      "done training embedding NN\n",
      "No Finding 0.8781969484323571\n",
      "Atelectasis 0.6410196746102139\n",
      "Cardiomegaly 0.807075313094683\n",
      "Consolidation 0.6899493543244206\n",
      "Edema 0.7789961404686648\n",
      "Pleural Effusion 0.8421822056750534\n",
      "\n",
      "loss:0.41146207949877195, avg_auc:0.7860148126212773\n",
      "No Finding 0.9618055555555556\n",
      "Atelectasis 0.6305703070884322\n",
      "Cardiomegaly 0.7848450057405282\n",
      "Consolidation 0.8034375\n",
      "Edema 0.860895202358617\n",
      "Pleural Effusion 0.8688524590163935\n",
      "\n",
      "loss:0.6420648429128859, avg_auc:0.7848715856020674\n",
      "done eval base model 0.7860148126212773 0.7848715856020674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 580/580 [03:05<00:00,  3.13batch/s, loss=0.126]\n",
      "  0%|          | 0/580 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.20070785420208143 \n",
      "done 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 25/580 [00:07<02:45,  3.35batch/s, loss=0.129]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ec9b27d00819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mfine_loss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fine_lost\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mfine_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfine_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfine_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfine_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfine_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_fine_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_validate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mfine_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfine_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ce179b71fbf0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, train_model, train_loss_fn, train_optimizer, dl_train, dl_validate, dl_test, eval_fn)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtepoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtepoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mtrain_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/screen_understanding/screen_env/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/screen_understanding/screen_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/screen_understanding/screen_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/screen_understanding/screen_env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/screen_understanding/screen_env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-53cc02e16f45>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mimage_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membd_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0morg_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/screen_understanding/screen_env/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    891\u001b[0m         \"\"\"\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/screen_understanding/screen_env/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_size = 0.1\n",
    "#generate n_iter times of train/validate split\n",
    "trains, validates = [],[]\n",
    "for i in range(n_iter):\n",
    "    train, validate = train_test_split(train_full, test_size=1-train_size, random_state=seeds[i], shuffle=True)\n",
    "    trains.append(train)\n",
    "    validates.append(validate)\n",
    "    \n",
    "    \n",
    "batch_size = 16\n",
    "coarse_models = []\n",
    "fine_models = [] \n",
    "\n",
    "base_test_auc = []\n",
    "base_validate_auc = []\n",
    "ours_test_auc = []\n",
    "ours_validate_auc = []\n",
    "\n",
    "train_epoch= 3\n",
    "\n",
    "for iteration in range(n_iter):\n",
    "    \n",
    "    train_df, validate_df = trains[iteration], validates[iteration]\n",
    "    train_dataset = ChestXRayDataset(train_df, train_transform, data_root)\n",
    "    valid_dataset = ChestXRayDataset(validate_df, test_transform, data_root)\n",
    "    test_dataset = ChestXRayDataset(test_df, test_transform, data_root)\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    dl_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dl_validate = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dl_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    print('iteration: %i train_size: %i, validate_size: %i, test_size: %i' \n",
    "              %(iteration, len(dl_train), len(dl_validate), len(dl_test) ))\n",
    "    \n",
    "    # Initialize the model\n",
    "    c_model = Resnext50(len(train_dataset.class_names), 'coarse_nn')\n",
    "    c_model.to(device)\n",
    "    c_loss_fn = torch.nn.BCELoss().to(device)\n",
    "    c_optimizer = torch.optim.Adam(c_model.parameters(), lr=5e-5)\n",
    "    \n",
    "    \n",
    "    train_model(train_epoch, c_model, c_loss_fn, c_optimizer, dl_train, dl_validate, dl_test, eval_fn=None)\n",
    "    coarse_models.append(c_model)\n",
    "    print('done training embedding NN')\n",
    "    \n",
    "    #these will be the base we measure improvements\n",
    "    valid_auc, _ = eval_model(c_model, c_loss_fn, dl_validate)\n",
    "    test_auc, _  = eval_model(c_model, c_loss_fn, dl_test)\n",
    "    base_validate_auc.append(valid_auc)\n",
    "    base_test_auc.append(test_auc)\n",
    "    print('done eval base model %s %s' %(valid_auc, test_auc))\n",
    "    \n",
    "    #do our thingy\n",
    "    embd_model = get_feature_extractor(c_model)\n",
    "    train_features, train_targets = extract_fetures_targets(c_model, dl_train)\n",
    "    fine_clfs, fine_to_org, n_fine_classes = gen_fine_clf(train_features, train_targets)\n",
    "\n",
    "    train_fine_dataset = ChestXRayFineLabelDataset(train_df, train_transform, data_root, embd_model, fine_clfs, fine_to_org, n_fine_classes)\n",
    "    test_fine_dataset = ChestXRayFineLabelDataset (test_df, test_transform, data_root, embd_model, fine_clfs, fine_to_org, n_fine_classes)\n",
    "    validate_fine_dataset = ChestXRayFineLabelDataset (validate_df, test_transform, data_root, embd_model, fine_clfs, fine_to_org, n_fine_classes)\n",
    "    \n",
    "                                                       \n",
    "    dl_fine_train = torch.utils.data.DataLoader(train_fine_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dl_fine_test = torch.utils.data.DataLoader(test_fine_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dl_fine_valid = torch.utils.data.DataLoader(validate_fine_dataset, batch_size=batch_size, shuffle=True)\n",
    "                                                       \n",
    "                                                       \n",
    "    fine_model = Resnext50(n_fine_classes, 'fine_model')\n",
    "    fine_model.to(device)\n",
    "    fine_loss_fn = torch.nn.BCELoss().to(device)\n",
    "    fine_loss_fn.name=\"fine_lost\"\n",
    "    fine_optimizer = torch.optim.Adam(fine_model.parameters(), lr=5e-5)\n",
    "    train_model(train_epoch, fine_model, fine_loss_fn, fine_optimizer, dl_fine_train, dl_validate=None, dl_test=None, eval_fn=None)\n",
    "    fine_models.append(fine_model)\n",
    "                                                       \n",
    "    #these will be the base we measure improvements\n",
    "    our_valid_auc, _ = eval_fine_model(fine_model, fine_loss_fn, dl_fine_valid)\n",
    "    our_test_auc, _  = eval_fine_model(fine_model, fine_loss_fn, dl_fine_test)\n",
    "    ours_validate_auc.append(our_valid_auc)\n",
    "    ours_test_auc.append(our_test_auc)\n",
    "    print('done-iterations %s\\n val: %s test: %s\\n our_val:%s our_test %s' \n",
    "          %(iteration, valid_auc, test_auc, our_valid_auc, ours_test_auc))\n",
    "             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_stuff, fine_stuff, lookup_dic = gen_coarse_fine_labels(train_features, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_targets = extract_fetures_targets(c_model, dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Finding 0.9088632874866905\n",
      "Atelectasis 0.8317360268701492\n"
     ]
    }
   ],
   "source": [
    "class_wise_clfs = []\n",
    "aucs = []\n",
    "counts = 0\n",
    "for idx in range(6):\n",
    "    target = train_targets[:, idx]\n",
    "    clf = UncertaintyForest(n_estimators=100, max_depth=10)\n",
    "    clf.fit(train_features, target)\n",
    "    pp = clf.predict(train_features)\n",
    "    fpr, tpr, thresholds = roc_curve(target, pp)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    if idx != 0:\n",
    "        aucs.append(auc_score * sum(target))\n",
    "        counts+= sum(target)\n",
    "    class_wise_clfs.append(clf)\n",
    "    print (train_dataset.class_names[idx], auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pleural Effusion 0.8041666666666666\n",
      "Pleural Effusion 0.5517201570076196\n",
      "Pleural Effusion 0.5391504018369689\n",
      "Pleural Effusion 0.5625\n",
      "Pleural Effusion 0.7736531760922004\n",
      "Pleural Effusion 0.7338951743246364\n",
      "0.6324620323422943\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "counts = 0\n",
    "for i in range(6):\n",
    "    target = test_targets[:, i]\n",
    "    pp = class_wise_clfs[i].predict(test_features)\n",
    "    fpr, tpr, thresholds = roc_curve(target, pp)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    if idx != 0:\n",
    "        aucs.append(auc_score * sum(target))\n",
    "        counts+= sum(target)\n",
    "    \n",
    "    print (train_dataset.class_names[i], auc_score) \n",
    "print(sum(aucs)/counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7932935296733508"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
